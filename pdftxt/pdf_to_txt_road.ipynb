{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./pdttotxt/txt/A_Survey_on_Expert_Recommendation_in_Community_Que.pdf.txt\", 'r')\n",
    "data = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./pdttotxt/txt/A_Survey_on_Expert_Recommendation_in_Community_Que.pdf.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8\\n',\n",
       " '1\\n',\n",
       " '0\\n',\n",
       " '2\\n',\n",
       " '\\n',\n",
       " ' \\n',\n",
       " 'l\\n',\n",
       " 'u\\n',\n",
       " 'J\\n',\n",
       " ' \\n',\n",
       " '\\n',\n",
       " '5\\n',\n",
       " '1\\n',\n",
       " '\\n',\n",
       " ' \\n',\n",
       " ' \\n',\n",
       " ']\\n',\n",
       " 'I\\n',\n",
       " 'S\\n',\n",
       " '.\\n',\n",
       " 's\\n',\n",
       " 'c\\n',\n",
       " '[\\n',\n",
       " ' \\n',\n",
       " ' \\n',\n",
       " '\\n',\n",
       " '1\\n',\n",
       " 'v\\n',\n",
       " '0\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '5\\n',\n",
       " '0\\n',\n",
       " '\\n',\n",
       " '.\\n',\n",
       " '\\n',\n",
       " '7\\n',\n",
       " '0\\n',\n",
       " '8\\n',\n",
       " '1\\n',\n",
       " ':\\n',\n",
       " 'v\\n',\n",
       " 'i\\n',\n",
       " 'X\\n',\n",
       " 'r\\n',\n",
       " 'a\\n',\n",
       " '\\n',\n",
       " 'Wang X, Huang C, Yao L et al. A survey on expert recommendation in community question answering. JOURNAL OF\\n',\n",
       " 'COMPUTER SCIENCE AND TECHNOLOGY 33(1): 1–29 January 2018. DOI 10.1007/s11390-015-0000-0\\n',\n",
       " '\\n',\n",
       " 'A Survey on Expert Recommendation in Community Question\\n',\n",
       " 'Answering\\n',\n",
       " '\\n',\n",
       " 'Xianzhi Wang1, Member, ACM, IEEE, Chaoran Huang2, Lina Yao2, Member, ACM, IEEE,\\n',\n",
       " 'Boualem Benatallah2, Member, IEEE, and Manqing Dong2, Student Member, ACM, IEEE\\n',\n",
       " '\\n',\n",
       " '1 School of Software, University of Technology Sydney, NSW 2007, Australia\\n',\n",
       " '2 School of Computer Science and Engineering, University of New South Wales, Sydney, 2052 NSW, Australia\\n',\n",
       " 'E-mail: xzwang@smu.edu.sg, {chaoran.huang, lina.yao, b.benatallah, manqing.dong}@unsw.edu.au\\n',\n",
       " '\\n',\n",
       " 'Received July 15, 2018; revised October 14, 2018.\\n',\n",
       " '\\n',\n",
       " 'Abstract\\n',\n",
       " 'Community question answering (CQA) represents the type of Web applications where people can exchange\\n',\n",
       " 'knowledge via asking and answering questions. One signiﬁcant challenge of most real-world CQA systems is the lack of\\n',\n",
       " 'eﬀective matching between questions and the potential good answerers, which adversely aﬀects the eﬃcient knowledge\\n',\n",
       " 'acquisition and circulation. On the one hand, a requester might experience many low-quality answers without receiving a\\n',\n",
       " 'quality response in a brief time; on the other hand, an answerer might face numerous new questions without being able to\\n',\n",
       " 'identify their questions of interest quickly. Under this situation, expert recommendation emerges as a promising technique\\n',\n",
       " 'to address the above issues. Instead of passively waiting for users to browse and ﬁnd their questions of interest, an expert\\n',\n",
       " 'recommendation method raises the attention of users to the appropriate questions actively and promptly. The past few\\n',\n",
       " 'years have witnessed considerable eﬀorts that address the expert recommendation problem from diﬀerent perspectives.\\n',\n",
       " 'These methods all have their issues that need to be resolved before the advantages of expert recommendation can be\\n',\n",
       " 'fully embraced. In this survey, we ﬁrst present an overview of the research eﬀorts and state-of-the-art techniques for the\\n',\n",
       " 'expert recommendation in CQA. We next summarize and compare the existing methods concerning their advantages and\\n',\n",
       " 'shortcomings, followed by discussing the open issues and future research directions.\\n',\n",
       " '\\n',\n",
       " 'Keywords\\n',\n",
       " '\\n',\n",
       " 'community question answering, expert recommendation, challenges, solutions, future directions\\n',\n",
       " '\\n',\n",
       " '1 Introduction\\n',\n",
       " '\\n',\n",
       " 'The prosperity of crowdsourcing and web 2.0 has\\n',\n",
       " 'fostered numerous online communities featuring ques-\\n',\n",
       " 'tion answering (Q&A) activities. Such communities ex-\\n',\n",
       " 'ist in various forms such as dedicated websites, online\\n',\n",
       " 'forums, and discussion boards. They provide a venue\\n',\n",
       " 'for people to share and obtain knowledge by asking\\n',\n",
       " 'and answering questions, known as community ques-\\n',\n",
       " 'tion answering (CQA) [1]. While traditional online in-\\n',\n",
       " 'formation seeking approaches (e.g., search engines) re-\\n',\n",
       " 'trieve information from existing information reposito-\\n',\n",
       " 'ries based on keywords, they face several challenges.\\n',\n",
       " 'First, answers to some questions may not exist in the\\n',\n",
       " 'previously answered questions [2] and thus cannot be re-\\n',\n",
       " 'trieved from existing repositories directly. Second, most\\n',\n",
       " 'real-world questions are written in complicated natu-\\n',\n",
       " '\\n',\n",
       " 'ral languages that require certain human intelligence\\n',\n",
       " 'to be understood. Third, some questions inherently\\n',\n",
       " 'seek people’s opinions and can only be answered by hu-\\n',\n",
       " 'mans. While machines ﬁnd diﬃcult to handle the above\\n',\n",
       " 'cases, CQA can leverage the “wisdom of crowds” and\\n',\n",
       " 'obtain answers from multiple people simultaneously.\\n',\n",
       " 'Typical Q&A websites include Yahoo! Answers (an-\\n',\n",
       " 'swers.yahoo.com), Quora (www.quora.com), and Stack\\n',\n",
       " 'Overﬂow (stackoverﬂow.com). The ﬁrst two websites\\n',\n",
       " 'cover a wide range of topics, while the last only focuses\\n',\n",
       " 'on the topic of computer programming.\\n',\n",
       " '\\n',\n",
       " 'Though advantages over the traditional information\\n',\n",
       " 'seeking approaches, CQA faces several unique chal-\\n',\n",
       " 'lenges. First, a CQA website may have tens of thou-\\n',\n",
       " 'sands of questions posed every day, let alone the mil-\\n',\n",
       " 'lions of questions that already exist on the website. The\\n',\n",
       " 'huge volume of questions makes it diﬃcult for a gen-\\n',\n",
       " '\\n',\n",
       " 'Survey\\n',\n",
       " '©2018 Springer Science + Business Media, LLC & Science Press, China\\n',\n",
       " '\\n',\n",
       " '\\x0c2\\n',\n",
       " '\\n',\n",
       " 'J. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n',\n",
       " '\\n',\n",
       " 'eral answerer to ﬁnd the appropriate questions to an-\\n',\n",
       " 'swer [3]. Second, answerers usually have varying inter-\\n',\n",
       " 'est and expertise in diﬀerent topics and knowledge do-\\n',\n",
       " 'mains. Thus, they may give answers of varying quality\\n',\n",
       " 'to diﬀerent questions. The time required for preparing\\n',\n",
       " 'answers [4] and the intention of answering also aﬀect the\\n',\n",
       " 'quality of their responses. An extreme case is that an-\\n',\n",
       " 'swerers may give irrelevant answers that distract other\\n',\n",
       " 'users [5] without serious thinking. All the above situa-\\n',\n",
       " 'tions cause additional eﬀorts of an information seeker\\n',\n",
       " 'in obtaining good answers. Third, instead of receiving\\n',\n",
       " 'an answer instantly, users in CQA may need to wait a\\n',\n",
       " 'long time until a satisfactory answer appears. Previ-\\n',\n",
       " 'ous studies [6] show that many questions on real-world\\n',\n",
       " 'CQA websites cannot be resolved adequately, meaning\\n',\n",
       " 'the requesters recognize no best answers to their ques-\\n',\n",
       " 'tions within 24 hours.\\n',\n",
       " '\\n',\n",
       " 'Fortunately, several studies [7–9] have shown that\\n',\n",
       " 'some core answerers are the primary drivers of answer\\n',\n",
       " 'production in the many communities. Recent work\\n',\n",
       " 'on Stack Overﬂow and Quora [10] further indicates that\\n',\n",
       " 'these sites consist of a set of highly dedicated domain\\n',\n",
       " 'experts who aim at satisfying requesters’ query but\\n',\n",
       " 'more importantly at providing answers with high last-\\n',\n",
       " 'ing value to a broader audience. All these studies sug-\\n',\n",
       " 'gest the needs for recommending a small group of most\\n',\n",
       " 'competent answerers, or experts to answer the new\\n',\n",
       " 'questions.\\n',\n",
       " 'In fact, the long-tail phenomena in many\\n',\n",
       " 'real-world communities, from the statistic perspective,\\n',\n",
       " 'lays the ground of the rationale of expert recommenda-\\n',\n",
       " 'tion in CQA [11], as most answers and knowledge in the\\n',\n",
       " 'communities come from only a minority of users [11;12].\\n',\n",
       " 'As an eﬀective means of addressing the practical chal-\\n',\n",
       " 'lenges of traditional information seeking approaches,\\n',\n",
       " 'expert recommendation methods bring up the attention\\n',\n",
       " 'of only a small number of experts, i.e., the users who\\n',\n",
       " 'are most likely to provide high-quality answers, to an-\\n',\n",
       " 'swer a given question [13]. Since expert recommendation\\n',\n",
       " 'inherently encourages fast acquisition of higher-quality\\n',\n",
       " 'answers, it potentially increases the participation rates\\n',\n",
       " 'of users, improves the visibility of experts, as well as\\n',\n",
       " 'fosters stronger communities in CQA.\\n',\n",
       " '\\n',\n",
       " 'Given the advantages of expert recommendation\\n',\n",
       " 'and related topics such as question routing [6;14] and\\n',\n",
       " 'question recommendation [15] in the domains of Natu-\\n',\n",
       " 'ral Language Processing (NLP) and Information Re-\\n',\n",
       " 'trieval (IR), we aim to present a comprehensive survey\\n',\n",
       " 'on the expert recommendation in CQA. On the one\\n',\n",
       " 'hand, considerable eﬀorts have been conducted on the\\n',\n",
       " 'expert recommendation and have delivered fruitful re-\\n',\n",
       " '\\n',\n",
       " 'sults. Therefore, it is necessary to review the related\\n',\n",
       " 'methods and techniques to gain a timely and better\\n',\n",
       " 'understanding of state of the art. On the other hand,\\n',\n",
       " 'despite the active research in CQA, expert recommen-\\n',\n",
       " 'dation remains a challenging task. For example, the\\n',\n",
       " 'sparsity of historical question and answer records, low\\n',\n",
       " 'participation rates of users, lack of personalization in\\n',\n",
       " 'recommendation results, the migration of users in or\\n',\n",
       " 'out of communities, and lack of comprehensive consid-\\n',\n",
       " 'eration of diﬀerent clues in modeling users expertise are\\n',\n",
       " 'all regarded as challenging issues in literature. Given\\n',\n",
       " 'the diverse existing methods, it is crucial to develop a\\n',\n",
       " 'general framework to evaluate these methods and ana-\\n',\n",
       " 'lyze their shortcomings, as well as to point out promis-\\n',\n",
       " 'ing future research directions.\\n',\n",
       " '\\n',\n",
       " 'To the best of our knowledge, this is the ﬁrst com-\\n',\n",
       " 'prehensive survey that focuses on the expert recommen-\\n',\n",
       " 'dation issue in CQA. The remainder of the article is or-\\n',\n",
       " 'ganized as follows. We overview the expert recommen-\\n',\n",
       " 'dation problem in Section 2 and its current applications\\n',\n",
       " 'in CQA in Section 3. In Section 4, we present the clas-\\n',\n",
       " 'siﬁcation and introduction of state of the art expert rec-\\n',\n",
       " 'ommendation methods. In Section 5, we compare the\\n',\n",
       " 'investigated expert recommendation methods on vari-\\n',\n",
       " 'ous aspects and discuss their advantages and pitfalls.\\n',\n",
       " 'In Section 6, we highlight several promising research\\n',\n",
       " 'directions. Finally, we oﬀer some concluding remarks\\n',\n",
       " 'in Section 7.\\n',\n",
       " '\\n',\n",
       " '2 Expert Recommendation Problem\\n',\n",
       " '\\n',\n",
       " 'The expert recommendation issue is also known as\\n',\n",
       " 'the question routing or expert ﬁnding problem. The\\n',\n",
       " 'basic inputs of an expert recommendation problem in-\\n',\n",
       " 'clude users (i.e., requesters and answerers) and user-\\n',\n",
       " 'generated content (i.e., the questions raised by re-\\n',\n",
       " 'questers and the answers provided by answerers). More\\n',\n",
       " 'inputs might be available depending on the applica-\\n',\n",
       " 'tion scenarios. Typically, they include user proﬁles\\n',\n",
       " '(e.g., badges, reputation scores, and links to external\\n',\n",
       " 'resources such as Web pages), users’ feedback on ques-\\n',\n",
       " 'tions and answers (e.g., textual comments and votings),\\n',\n",
       " 'and question details (e.g., the categories of questions\\n',\n",
       " 'and duplication relations among questions). The rela-\\n',\n",
       " 'tionship among the diﬀerent types of inputs of an ex-\\n',\n",
       " 'pert recommendation problem is described in the class\\n',\n",
       " 'diagram shown in Fig. 1.\\n',\n",
       " '\\n',\n",
       " 'Question answering websites usually organize infor-\\n',\n",
       " 'mation in the form of threads. Each thread is led by a\\n',\n",
       " 'single question, which is replied to with none, one, or\\n',\n",
       " '\\n',\n",
       " '\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n',\n",
       " '\\n',\n",
       " '3\\n',\n",
       " '\\n',\n",
       " 'Fig.1. Elements of expert recommendation in CQA.\\n',\n",
       " '\\n',\n",
       " 'multiple answers. Each question or answer is provided\\n',\n",
       " 'by a single user, called a requester or an answerer, re-\\n',\n",
       " 'spectively. A requester may ask multiple questions, and\\n',\n",
       " 'each answerer may answer various questions. A user\\n',\n",
       " 'can be either a requester or an answerer, or both at the\\n',\n",
       " 'same time in the same CQA website, and all users are\\n',\n",
       " 'free to provide diﬀerent types of feedback on the posted\\n',\n",
       " 'questions and answers. For example, in Stack Overﬂow,\\n',\n",
       " 'any registered user can comment and vote (by giving\\n',\n",
       " 'a thumb up or thumb down) on an answer posted for\\n',\n",
       " 'any question, and the requester has the authority to\\n',\n",
       " 'mark one from the posted answers as the best answer.\\n',\n",
       " 'In case that the requester has not designated the best\\n',\n",
       " 'answer within a speciﬁed period, the system will auto-\\n',\n",
       " 'matically mark the response that received the highest\\n',\n",
       " 'voting score as the best answer.\\n',\n",
       " '\\n',\n",
       " 'The objective of the expert recommendation prob-\\n',\n",
       " 'lem is to raise the attention of experts, i.e., a small num-\\n',\n",
       " 'ber of users who are most likely to provide high-quality\\n',\n",
       " 'answers, to the given question based on the above prob-\\n',\n",
       " 'lem inputs. Despite the various possible types of inputs,\\n',\n",
       " 'only a subset of them might be available in a speciﬁc\\n',\n",
       " 'application scenario. Therefore, researchers may deﬁne\\n',\n",
       " 'the expert recommendation problem diﬀerently accord-\\n',\n",
       " 'ing to the inputs. Besides, researchers may take into\\n',\n",
       " 'account diﬀerent concerns and expect diﬀerent types\\n',\n",
       " 'of outputs from their methods. Generally, topical rel-\\n',\n",
       " 'evance and expertise are the two most considered as-\\n',\n",
       " 'pects of concerns by the existing research. While some\\n',\n",
       " 'researchers develop methods to ﬁnd a group of high-\\n',\n",
       " 'quality answerers, other researchers aim to deliver a\\n',\n",
       " 'ranked list, where the users are ranked according to\\n',\n",
       " 'their potential to provide the best answer. We will\\n',\n",
       " 'elaborate the variations in the problem deﬁnition in\\n',\n",
       " 'Section 5.\\n',\n",
       " '\\n',\n",
       " 'Generally, it is only necessary to recommend experts\\n',\n",
       " 'when the new question is signiﬁcantly diﬀerent from\\n',\n",
       " 'any previous questions with best answers, meaning that\\n',\n",
       " '\\n',\n",
       " 'no satisfactory answers are readily available within the\\n',\n",
       " 'archive of best answers to the earlier questions. Expert\\n',\n",
       " 'recommendation generally brings about the following\\n',\n",
       " 'advantages to CQA: i) users usually prefer answers from\\n',\n",
       " 'experts, who are supposed to have suﬃcient motiva-\\n',\n",
       " 'tion and knowledge to answer the given questions and\\n',\n",
       " 'therefore more likely to provide high-quality answers\\n',\n",
       " 'promptly; ii) expert recommendations can potentially\\n',\n",
       " 'reduce the waiting time of requesters in ﬁnding satis-\\n',\n",
       " 'factory answers as well as the time of experts in ﬁnd-\\n',\n",
       " 'ing their questions of interests; iii) by bridging the gap\\n',\n",
       " 'between requesters and answerers, expert recommenda-\\n',\n",
       " 'tions can potentially promote their participation rates\\n',\n",
       " 'and thus foster stronger communities. Since experts\\n',\n",
       " 'are recommended with questions that ﬁt their exper-\\n',\n",
       " 'tise, their visibility is expected to be improved as well.\\n',\n",
       " '\\n',\n",
       " '3 Current Applications in CQA\\n',\n",
       " '\\n',\n",
       " 'Currently, there exist various Q&A websites where\\n',\n",
       " 'expert recommendation techniques are applied or can\\n',\n",
       " 'be potentially applied. Due to the large number of\\n',\n",
       " 'Q&A websites that exist nowadays, we selectively list\\n',\n",
       " 'some typical Q&A websites by launch year in Table 1.\\n',\n",
       " 'In the following subsections, we will categorize and give\\n',\n",
       " 'further illustrations of several typical websites of each\\n',\n",
       " 'category.\\n',\n",
       " '\\n',\n",
       " '3.1 Early CQA Services\\n',\n",
       " '\\n',\n",
       " 'Most early-stage Q&A services (e.g., the ﬁrst four\\n',\n",
       " 'websites in Table 1) meet a requesters’ information\\n',\n",
       " 'needs by resorting to the opinions of experts rather than\\n',\n",
       " 'the crowd. These experts are acknowledged by either\\n',\n",
       " 'the websites or third-party authorities and are often\\n',\n",
       " 'limited in number. They usually have rich knowledge\\n',\n",
       " 'and experience in some domains but require a payment\\n',\n",
       " 'for the answers they provide. We introduce two of these\\n',\n",
       " 'websites as examples as follows:\\n',\n",
       " '\\n',\n",
       " '\\x0c4\\n',\n",
       " '\\n',\n",
       " 'J. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n',\n",
       " '\\n',\n",
       " 'Community\\n',\n",
       " '\\n',\n",
       " 'MedHelp\\n',\n",
       " '\\n',\n",
       " 'Mad Scientist Netwok\\n',\n",
       " '\\n',\n",
       " 'WebMD\\n',\n",
       " '\\n',\n",
       " 'Google Answers\\n',\n",
       " '\\n',\n",
       " 'Naver KiN\\n',\n",
       " '\\n',\n",
       " 'WikiAnswers\\n',\n",
       " '\\n',\n",
       " 'Answerbag\\n',\n",
       " '\\n',\n",
       " 'IAsk\\n',\n",
       " '\\n',\n",
       " 'Baidu Knows\\n',\n",
       " '\\n',\n",
       " 'Live QnA\\n',\n",
       " '\\n',\n",
       " 'TurboTax Live Community\\n',\n",
       " '\\n',\n",
       " 'Sogou Wenwen\\n',\n",
       " '\\n',\n",
       " 'Stack Overﬂow\\n',\n",
       " '\\n',\n",
       " 'Quora\\n',\n",
       " '\\n',\n",
       " 'Seasoned Advice\\n',\n",
       " '\\n',\n",
       " 'Table 1. Some Popular Question Answering Communities\\n',\n",
       " '\\n',\n",
       " 'Language\\n',\n",
       " '\\n',\n",
       " 'Specialized Domain\\n',\n",
       " '\\n',\n",
       " 'Launch Year\\n',\n",
       " '\\n',\n",
       " 'Still Active\\n',\n",
       " '\\n',\n",
       " 'Quality Guarantee\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'Multiple\\n',\n",
       " '\\n',\n",
       " 'Korean\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'Chinses\\n',\n",
       " '\\n',\n",
       " 'Chinese\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'Chinese\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'Medical\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Medical\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Tax\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Programming\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Cooking\\n',\n",
       " '\\n',\n",
       " '1994\\n',\n",
       " '\\n',\n",
       " '1995\\n',\n",
       " '\\n',\n",
       " '1996\\n',\n",
       " '\\n',\n",
       " '2002\\n',\n",
       " '\\n',\n",
       " '2002\\n',\n",
       " '\\n',\n",
       " '2002\\n',\n",
       " '\\n',\n",
       " '2003\\n',\n",
       " '\\n',\n",
       " '2005\\n',\n",
       " '\\n',\n",
       " '2005\\n',\n",
       " '\\n',\n",
       " '2006\\n',\n",
       " '\\n',\n",
       " '2007\\n',\n",
       " '\\n',\n",
       " '2007\\n',\n",
       " '\\n',\n",
       " '2008\\n',\n",
       " '\\n',\n",
       " '2010\\n',\n",
       " '\\n',\n",
       " '2010\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'Mad Scientist Network 1 : a famous ask-a-scientist\\n',\n",
       " 'web service where people ask questions by ﬁlling forms\\n',\n",
       " 'and moderators are responsible for reviewing the ques-\\n',\n",
       " 'tions and sending them to the appropriate members for\\n',\n",
       " 'answers. The moderators will also review the answers\\n',\n",
       " 'before making them public.\\n',\n",
       " '\\n',\n",
       " 'Google Answers 2 : a knowledge market service de-\\n',\n",
       " 'signed as an extension to Google’s search service. There\\n',\n",
       " 'were a group of answerers called Google Answers Re-\\n',\n",
       " 'searchers who are oﬃcially approved to answer ques-\\n',\n",
       " 'tions through an application process. Instead of pas-\\n',\n",
       " 'sively waiting for other people to moderate or answer\\n',\n",
       " 'their questions, people can actively ﬁnd the potential\\n',\n",
       " 'answerers by themselves and pay the answerers.\\n',\n",
       " '\\n',\n",
       " '3.2 General-purpose CQA Websites\\n',\n",
       " '\\n',\n",
       " 'The Q&A services that emerge in the past two\\n',\n",
       " 'decades are increasingly leveraging the “wisdom of the\\n',\n",
       " 'crowd” rather than a small number of experts to give\\n',\n",
       " 'answers. Websites following this philosophy allow any\\n',\n",
       " 'users to voluntarily answer any questions on their free\\n',\n",
       " 'will and most of them serve as general purpose plat-\\n',\n",
       " 'forms for knowledge sharing rather then domain fo-\\n',\n",
       " 'cused ones. We overview some typical general purpose\\n',\n",
       " 'websites as follows:\\n',\n",
       " '\\n',\n",
       " 'Quora: one of the largest existing Q&A website\\n',\n",
       " 'where users can ask and answer questions, rate and\\n',\n",
       " 'edit the answers posted by others.\\n',\n",
       " '\\n',\n",
       " 'Zhihu 3 : a Chinese Q&A website similar to Quora.\\n',\n",
       " 'It allows users to create and edit questions and answers,\\n',\n",
       " 'rate system, and tag questions. Also, users may also\\n',\n",
       " 'post blogs in Zhihu for sharing while others can view\\n',\n",
       " 'and comment on such posts.\\n',\n",
       " '\\n',\n",
       " 'Naver KiN 4 : a Korean CQA community, one of\\n',\n",
       " 'the earlier cases of expansion of search service using\\n',\n",
       " 'user-generated content.\\n',\n",
       " '\\n',\n",
       " 'WikiAnswers 5 : a wiki service that allows people\\n',\n",
       " 'to raise and answer questions, as well as edit existing\\n',\n",
       " 'answers to questions. It uses a so-called “alternates sys-\\n',\n",
       " 'tem” to automatically merge similar questions. Since\\n',\n",
       " 'an answer may be associated with multiple questions,\\n',\n",
       " 'duplicated entries can be avoided to some extent.\\n',\n",
       " '\\n',\n",
       " 'Answerbag 6 : a CQA community where users can\\n',\n",
       " 'ask and answer questions, give comments to answers,\\n',\n",
       " 'rate questions, rate answers, and suggest new cate-\\n',\n",
       " 'gories.\\n',\n",
       " '\\n',\n",
       " 'Live QnA 7 : also known as MSN QnA, was part of\\n',\n",
       " 'Microsoft MSN group services.\\n',\n",
       " 'In this system, users\\n',\n",
       " 'can ask and answer questions, tag them to speciﬁc top-\\n',\n",
       " 'ics, and gain points and reputations by answering ques-\\n',\n",
       " '\\n',\n",
       " '1 http://www.madsci.org/, May 2018.\\n',\n",
       " '2 http://answers.google.com/, May 2018.\\n',\n",
       " '3 http://www.zhihu.com/, May 2018.\\n',\n",
       " '4 http://kin.naver.com/, May 2018.\\n',\n",
       " '5 http://www.wikianswers.com/, May 2018.\\n',\n",
       " '6 http://www.answerbag.com/, May 2018.\\n',\n",
       " '7 http://qna.live.com/, May 2018.\\n',\n",
       " '\\n',\n",
       " '\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n',\n",
       " '\\n',\n",
       " '5\\n',\n",
       " '\\n',\n",
       " 'tions.\\n',\n",
       " '\\n',\n",
       " '4 Expert Recommendation Methods\\n',\n",
       " '\\n',\n",
       " '3.3 Domain-focused CQA Websites\\n',\n",
       " '\\n',\n",
       " 'Compared with those general purpose websites,\\n',\n",
       " 'each domain-focused Q&A website only covers limited\\n',\n",
       " 'topics or knowledge domains. The Stack Exchange net-\\n',\n",
       " 'works are probably the largest host of domain-focused\\n',\n",
       " 'Q&A websites nowadays. Some typical websites hosted\\n',\n",
       " 'by it include the following:\\n',\n",
       " '\\n',\n",
       " 'MathOverﬂow 8 : a Q&A website focused on math-\\n',\n",
       " '\\n',\n",
       " 'ematical problems.\\n',\n",
       " '\\n',\n",
       " 'AskUbuntu 9 : a website supporting Q&A activities\\n',\n",
       " '\\n',\n",
       " 'related to Ubuntu operation Systems.\\n',\n",
       " '\\n',\n",
       " 'StackOverﬂow : a Q&A website focused on com-\\n',\n",
       " '\\n',\n",
       " 'puter programming.\\n',\n",
       " '\\n',\n",
       " 'All these websites follow similar sets of styles and\\n',\n",
       " 'functions. Apart from the basic question answering\\n',\n",
       " 'features, they commonly use badges to recognize the\\n',\n",
       " 'achievement of answerers and grant badges to users\\n',\n",
       " 'based on their reputation points. Users can also un-\\n',\n",
       " 'lock more privileges with higher reputation points.\\n',\n",
       " '\\n',\n",
       " '3.4 Summary\\n',\n",
       " '\\n',\n",
       " 'In summary, despite the prevalence of diverse types\\n',\n",
       " 'of Q&A websites, few of them have incorporated any\\n',\n",
       " 'eﬀective expert recommendation techniques to bridge\\n',\n",
       " 'requesters and answers. To the best of our knowledge,\\n',\n",
       " 'currently, the only implementation of the idea of rout-\\n',\n",
       " 'ing questions to the appropriate users in Q&A is called\\n',\n",
       " '“Aardvark” [16]. However, the primary purpose of this\\n',\n",
       " 'system is to serve as an enhanced search engine, and\\n',\n",
       " 'the expert recommendation techniques it employs are\\n',\n",
       " 'still at a preliminary stage. Recently, Bayati et al. [17]\\n',\n",
       " 'design a framework for recommending security experts\\n',\n",
       " 'for software engineering projects. This framework oﬀers\\n',\n",
       " 'more strength to facilitate expert recommendation by\\n',\n",
       " 'considering multiple aspects of users such as program-\\n',\n",
       " 'ming language, location, and social proﬁles on domi-\\n',\n",
       " 'nant programming Q&A websites like StackOverﬂow.\\n',\n",
       " 'Since the Q&A systems can be regarded as a type of\\n',\n",
       " 'crowdsourcing systems [18], the expert recommendation\\n',\n",
       " 'methods for a Q&A system can potentially be gener-\\n',\n",
       " 'alized and applied to general crowdsourcing systems as\\n',\n",
       " 'well.\\n',\n",
       " '\\n',\n",
       " '8 http://mathoverﬂow.net/, May 2018.\\n',\n",
       " '9 http://askubuntu.com/, May 2018.\\n',\n",
       " '\\n',\n",
       " 'As the major technique to facilitate eﬀective CQA,\\n',\n",
       " 'considerable eﬀorts have been contributed to the ex-\\n',\n",
       " 'pert recommendation research from the information re-\\n',\n",
       " 'trieval (IR), machine learning, and social computing\\n',\n",
       " 'perspectives, and have delivered fruitful results. We\\n',\n",
       " 'classify the state of the art expert recommendation\\n',\n",
       " 'methods into eight categories and review the methods\\n',\n",
       " 'by category in the following subsections.\\n',\n",
       " '\\n',\n",
       " '4.1 Simple Methods\\n',\n",
       " '\\n',\n",
       " 'One of the most critical tasks of expert recommen-\\n',\n",
       " 'dation is to evaluate users. Given a new question to\\n',\n",
       " 'be answered, some methods use simple metrics such\\n',\n",
       " 'as counts of positive/negative votes, proportions of\\n',\n",
       " 'best answers, and the similarity between the new ques-\\n',\n",
       " 'tion and users’ previous answered questions to evaluate\\n',\n",
       " 'users’ ﬁtness to answer the questions. In the following,\\n',\n",
       " 'we introduce the methods that use the three metrics,\\n',\n",
       " 'respectively. For any of these methods, a higher score\\n',\n",
       " 'indicates a better answerer.\\n',\n",
       " '\\n',\n",
       " 'Votes: the method evaluates a user by the number\\n',\n",
       " 'of aﬃrmative votes minus the number of negative votes,\\n',\n",
       " 'combined with the total percentage of aﬃrmative votes\\n',\n",
       " 'that the user receives from other users averaged over\\n',\n",
       " 'all the answers the user have attempted.\\n',\n",
       " '\\n',\n",
       " 'Best answer proportion: this method ranks users by\\n',\n",
       " 'the fraction of best answers among all the answers at-\\n',\n",
       " 'tempted by an answerer. The best answers are either\\n',\n",
       " 'awarded by the requester of questions or by the ques-\\n',\n",
       " 'tion answering platform when requesters designate no\\n',\n",
       " 'best answers.\\n',\n",
       " '\\n',\n",
       " 'Textual similarity:\\n',\n",
       " '\\n',\n",
       " 'the most famous method for\\n',\n",
       " 'measuring textual similarity is to compute the cosine\\n',\n",
       " 'similarity based on the term frequency-inverse docu-\\n',\n",
       " 'ment frequency (TF-IDF) model, a classic vector space\\n',\n",
       " 'model (VSM) [19] borrowed from the information re-\\n',\n",
       " 'trieval domain. VSM is readily applicable to computing\\n',\n",
       " 'the similarity of an answerer’s proﬁle to a given ques-\\n',\n",
       " 'tion. Therefore, it can be directly used for the expert\\n',\n",
       " 'recommendation by relating a new question to the an-\\n',\n",
       " 'swerers who have previously answered the most relevant\\n',\n",
       " 'questions to the given question.\\n',\n",
       " '\\n',\n",
       " '\\x0c6\\n',\n",
       " '\\n',\n",
       " 'J. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n',\n",
       " '\\n',\n",
       " '4.2 Language Models\\n',\n",
       " '\\n',\n",
       " 'Despite the simplicity, VSM adopts the “bag-of-\\n',\n",
       " 'words” assumption and thus brings the high-dimension\\n',\n",
       " 'document representation issue.\\n',\n",
       " 'In contrast, language\\n',\n",
       " 'models use a generative approach to compute the word-\\n',\n",
       " 'based relevance of a user’s previous activities to the\\n',\n",
       " 'given question, and in turn, to predict the possibility\\n',\n",
       " 'of a user answering the question. Such models can,\\n',\n",
       " 'to some extent alleviate the high dimension issue. In a\\n',\n",
       " 'language model, the users whose proﬁles are most likely\\n',\n",
       " 'to generate the given question are believed to have to\\n',\n",
       " 'highest probability to answer the given question. The\\n',\n",
       " 'model ﬁnally returns a ranked list of users according to\\n',\n",
       " 'their likelihood of answering the given question.\\n',\n",
       " '\\n',\n",
       " 'The language model-based methods include proﬁle-\\n',\n",
       " 'based methods and document-based methods. The for-\\n',\n",
       " 'mer [20] models the knowledge of each user with the as-\\n',\n",
       " 'sociated documents and ranks the candidate experts\\n',\n",
       " 'for a given topic based on the relevance scores between\\n',\n",
       " 'their proﬁles and the given question. The latter [20]\\n',\n",
       " 'ﬁnds related documents for a given topic and ranks\\n',\n",
       " 'candidates based on mentions of the candidates in the\\n',\n",
       " 'related documents.\\n',\n",
       " '\\n',\n",
       " '4.2.1 QLL and Basic Variants\\n',\n",
       " '\\n',\n",
       " 'Among the methods of this category, query likeli-\\n',\n",
       " 'hood language (QLL) model [21] is the most popular\\n',\n",
       " 'technique. QLL calculates a probability that user pro-\\n',\n",
       " 'ﬁles will generate terms of the routed question. The\\n',\n",
       " 'traditional language models often suﬀer the mismatch\\n',\n",
       " 'between the question and user proﬁles caused by the\\n',\n",
       " 'co-occurrence of random words in user proﬁles or ques-\\n',\n",
       " 'tions resulting from data sparseness. Translation mod-\\n',\n",
       " 'els [22] overcomes data sparseness by employing statis-\\n',\n",
       " 'tical machine translation and can diﬀerentiate between\\n',\n",
       " 'exact matched words and translated semantically re-\\n',\n",
       " 'lated ones. A typical work [23] using this method views\\n',\n",
       " 'the problem as an IR problem.\\n',\n",
       " 'It considers the new\\n',\n",
       " 'question as a query and the expert proﬁles as docu-\\n',\n",
       " 'ments.\\n',\n",
       " 'It next estimates an answerer’s expertise by\\n',\n",
       " 'combining its previously answered questions, and re-\\n',\n",
       " 'gards experts as the users who have answered the most\\n',\n",
       " 'similar questions in the past.\\n',\n",
       " '\\n',\n",
       " 'Besides the basic models, many variants of QLL\\n',\n",
       " 'have also emerged as alternatives or enhancements. For\\n',\n",
       " 'example, Liu et al. propose two variants of the ba-\\n',\n",
       " 'sic language model, namely relevance-based language\\n',\n",
       " 'model [24] and cluster-based language model [25] to rank\\n',\n",
       " 'user proﬁles. Petkova and Croft [26] propose a hierarchi-\\n',\n",
       " 'cal language model which uses a ﬁner-grained approach\\n',\n",
       " '\\n',\n",
       " 'with a linear combination of the language models built\\n',\n",
       " 'on subcollections of documents.\\n',\n",
       " '\\n',\n",
       " '4.2.2 Category-sensitive QLL\\n',\n",
       " '\\n',\n",
       " 'Considering the availability of categories in many\\n',\n",
       " 'Q&A websites, Li et al. [27] propose a category-sensitive\\n',\n",
       " 'QLL model to exploit the hierarchical category infor-\\n',\n",
       " 'mation presented with questions in Yahoo! Answers.\\n',\n",
       " 'Once a question gets categorized, the task is to ﬁnd the\\n',\n",
       " 'users who are most likely to answer that question within\\n',\n",
       " 'its category. Their experiments over the Yahoo! An-\\n',\n",
       " 'swers dataset show that taking categories into account\\n',\n",
       " 'improves the recommendation performance. A limita-\\n',\n",
       " 'tion of the category-sensitive model is that categories\\n',\n",
       " 'need to be well predeﬁned and some questions might\\n',\n",
       " 'be closely related to multiple categories due to the ex-\\n',\n",
       " 'istence of similar categories that share the same con-\\n',\n",
       " 'texts. A possible solution to address this limitation is\\n',\n",
       " 'the transferred category-sensitive QLL model [27], which\\n',\n",
       " 'additionally builds and considers the relevance between\\n',\n",
       " 'categories.\\n',\n",
       " '\\n',\n",
       " '4.2.3 Expertise-aware QLL\\n',\n",
       " '\\n',\n",
       " 'Zheng et al. [28] linearly combine two aspects, user\\n',\n",
       " 'relevance (computed based on the QLL) and answer\\n',\n",
       " 'quality (estimated using a maximum entropy model),\\n',\n",
       " 'using the simple weighted sum method to represent\\n',\n",
       " 'user expertise on a given question. Besides the rele-\\n',\n",
       " 'vance and quality aspects, Li et al. [6] further consider\\n',\n",
       " 'the availability of users and use the weighted sum of\\n',\n",
       " 'the three aspects to represent user expertise on a given\\n',\n",
       " 'question. In particular, the relevance is estimated us-\\n',\n",
       " 'ing the QLL model, the answer quality is estimated as\\n',\n",
       " 'the weighted average of previous answer quality incor-\\n',\n",
       " 'porated with the Jelinek-Mercer smoothing [29] method,\\n',\n",
       " 'and users’ availability to answer a given question during\\n',\n",
       " 'a given period is predicted by an autoregressive model.\\n',\n",
       " 'Compared with most existing methods, this method ex-\\n',\n",
       " 'ploits not only time series availability information of\\n',\n",
       " 'users but also multiple metadata features such as an-\\n',\n",
       " 'swer length, question-answer length, number of answers\\n',\n",
       " 'for this question, the answerer’s total points, and the\\n',\n",
       " 'answerer’s best answer ratio. These features have rarely\\n',\n",
       " 'been used by the existing research.\\n',\n",
       " '\\n',\n",
       " '4.3 Topic Models\\n',\n",
       " '\\n',\n",
       " 'Since language models are based on exact word\\n',\n",
       " 'matching, they are most eﬀective when they are used\\n',\n",
       " 'within the same topic. Besides, they are not able to\\n',\n",
       " '\\n',\n",
       " '\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n',\n",
       " '\\n',\n",
       " '7\\n',\n",
       " '\\n',\n",
       " 'capture more advanced semantics and solve the prob-\\n',\n",
       " 'lem of the lexical gap between a question and user pro-\\n',\n",
       " 'ﬁles. In contrast, topic models do not require the word\\n',\n",
       " 'to appear in the user proﬁle, as it measures their re-\\n',\n",
       " 'lationship in the topic space rather than in the word\\n',\n",
       " 'space. It can, therefore, alleviate the lexical gap prob-\\n',\n",
       " 'lem and previous experimental evaluations have con-\\n',\n",
       " 'ﬁrmed the better performance of many topic models\\n',\n",
       " 'over language models [30;31]. Here, we focus on review-\\n',\n",
       " 'ing two most widely used topic models, Probabilistic\\n',\n",
       " 'Latent Semantic Analysis (PLSA) and Latent Dirichlet\\n',\n",
       " 'Allocation (LDA), as well as their variants and a few\\n',\n",
       " 'other models.\\n',\n",
       " '\\n',\n",
       " '4.3.1 PLSA and Its Variants\\n',\n",
       " '\\n',\n",
       " 'Probabilistic Latent Semantic\\n',\n",
       " '\\n',\n",
       " 'Probabilistic Latent Semantic Analysis (PLSA)\\n',\n",
       " 'a.k.a.\\n',\n",
       " 'Indexing\\n',\n",
       " '(PLSI) [32] is developed based on Latent Semantic In-\\n',\n",
       " 'dexing (LSI) [33], which uses Singular Value Decomposi-\\n',\n",
       " 'tion to represent a document in a low-dimension space.\\n',\n",
       " 'Compared with LSI, which lacks semantic explanation,\\n',\n",
       " 'PLSA uses latent topics to represent documents and\\n',\n",
       " 'model the data generation process as a Bayesian net-\\n',\n",
       " 'work. In this way, it can leverage the semantic between\\n',\n",
       " 'words in documents to reduce the document representa-\\n',\n",
       " 'tion space dimension. There are generally two classes of\\n',\n",
       " 'PLSA-based methods that model users directly and in-\\n',\n",
       " 'directly, respectively. We brieﬂy review the two classes\\n',\n",
       " 'of methods as follows:\\n',\n",
       " '\\n',\n",
       " 'Direct User Model by PLSA. Methods of this class\\n',\n",
       " 'treat all the questions that a user accesses as one docu-\\n',\n",
       " 'ment. Then, PLSA is used directly to derive the topic\\n',\n",
       " 'information of the user using word distributions. A typ-\\n',\n",
       " 'ical method of this class [15] would identify the under-\\n',\n",
       " 'lying topics of questions to match users’ interest and\\n',\n",
       " 'thereby help the capable users locate the right ques-\\n',\n",
       " 'tions to answer. The Expectation Maximization (EM)\\n',\n",
       " 'algorithm is generally used to ﬁnd a local maximum of\\n',\n",
       " 'the log-likelihood of the question collection and to learn\\n',\n",
       " 'model parameters.\\n',\n",
       " '\\n',\n",
       " 'Indirect User Model by PLSA. A typical method of\\n',\n",
       " 'this class is proposed in [34]. This work presents an\\n',\n",
       " 'incremental automatic expert recommendation frame-\\n',\n",
       " 'work based on PLSA. It considers both users’ interests\\n',\n",
       " 'and feedback and takes questions as documents. It fur-\\n',\n",
       " 'ther uses PLSA to model the question to gain its distri-\\n',\n",
       " 'bution on topics, followed by representing users as the\\n',\n",
       " 'average of topic distributions of all the questions that\\n',\n",
       " 'he accesses to facilitate recommendation.\\n',\n",
       " '\\n',\n",
       " 'A most important variant of PLSA is probably the\\n',\n",
       " 'Dual Role Model (DRM) proposed by Xu et al. [35].\\n',\n",
       " 'Instead of combining the consideration of a user as\\n',\n",
       " 'a requester and an answerer, DRM separately mod-\\n',\n",
       " 'els users’ roles as requesters and as answerers and de-\\n',\n",
       " 'rive the corresponding probabilistic models based on\\n',\n",
       " 'PLSA. Depending on the modeling approach of user’s\\n',\n",
       " 'role, DRM diverges into independent DRM, a type of\\n',\n",
       " 'method modeling user role indirectly, and dependent\\n',\n",
       " 'DRM, a method which learns the role model directly.\\n',\n",
       " 'In particular, the independent DRM assumes all users\\n',\n",
       " 'are independent of each other and models each user\\n',\n",
       " 'individually.\\n',\n",
       " 'In contrast, dependent DRM considers\\n',\n",
       " 'the dependence between users. Besides modeling users’\\n',\n",
       " 'topic distribution as requesters and answerers, it addi-\\n',\n",
       " 'tionally models the relationship between answerers and\\n',\n",
       " 'requesters for better performance.\\n',\n",
       " '\\n',\n",
       " '4.3.2 LDA and Its Variants\\n',\n",
       " '\\n',\n",
       " 'The Latent Dirichlet Allocation (LDA) model [36] is\\n',\n",
       " 'probably the most widely used topic model among all\\n',\n",
       " 'existing topic models developed.\\n',\n",
       " 'In LDA, the topic\\n',\n",
       " 'mixture is drawn from a conjugate Dirichlet prior that\\n',\n",
       " 'remains the same for all users. More speciﬁcally, LDA\\n',\n",
       " 'assumes a certain generative process for data. To gener-\\n',\n",
       " 'ate a user proﬁle, LDA assumes that for each user pro-\\n',\n",
       " 'ﬁle a distribution over topics is sampled from a Dirich-\\n',\n",
       " 'let distribution. In the next step, for each word in the\\n',\n",
       " 'user proﬁle, a single topic is chosen according to this\\n',\n",
       " 'topic distribution. Finally, each word is sampled from\\n',\n",
       " 'a multinomial distribution over words speciﬁc to the\\n',\n",
       " 'sampled topic. Here, we brieﬂy review two important\\n',\n",
       " 'classes of LDA variants that have been applied for the\\n',\n",
       " 'expert recommendation in CQA:\\n',\n",
       " '\\n',\n",
       " 'Segmented Topic Model (STM) [37]. This is a topic\\n',\n",
       " 'model that discovers the hierarchical structure of top-\\n',\n",
       " 'ics by using the two-parameter Poisson Dirichlet pro-\\n',\n",
       " 'cess [38]. As a four-level probabilistic model, STM con-\\n',\n",
       " 'tains two levels of topic proportions and shows supe-\\n',\n",
       " 'riority over traditional models. Instead of grouping all\\n',\n",
       " 'the questions of a user under a single topic distribution,\\n',\n",
       " 'it allows each question to have a diﬀerent and separate\\n',\n",
       " 'distribution over the topics. A user proﬁle is considered\\n',\n",
       " 'a document that contains questions (segments). The\\n',\n",
       " 'above distributions cover the expertise set of a user,\\n',\n",
       " 'the topics of each question in the proﬁle, as well as the\\n',\n",
       " 'correlation between each proﬁle and its questions.\\n',\n",
       " '\\n',\n",
       " 'TagLDA [39]. This method uses only tag informa-\\n',\n",
       " 'tion to infer users’ topical interest. It is more eﬃciently,\\n',\n",
       " '\\n',\n",
       " '\\x0c8\\n',\n",
       " '\\n',\n",
       " 'J. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n',\n",
       " '\\n',\n",
       " 'but the eﬀectiveness is dependent on the accuracy and\\n',\n",
       " 'availability of tags.\\n',\n",
       " '\\n',\n",
       " '4.3.3 Expertise-aware LDA\\n',\n",
       " '\\n',\n",
       " 'The work in [40] considers both the topical interest\\n',\n",
       " 'and expertise of a user relevant to the topics of the\\n',\n",
       " 'given question. It also uses LDA to identify topical in-\\n',\n",
       " 'terest from previous answers of the user, but additional\\n',\n",
       " 'compute the expertise level of users using collaborative\\n',\n",
       " 'voting mechanism. Sahu et al. [39] incorporate question\\n',\n",
       " 'tags and related voting information in LDA to compute\\n',\n",
       " 'user expertise, where user expertise is computed based\\n',\n",
       " 'on both the topical distribution of users and voting in-\\n',\n",
       " 'formation under the same question tags.\\n',\n",
       " '\\n',\n",
       " '4.3.4 Other Topic Models\\n',\n",
       " '\\n',\n",
       " 'Besides the famous QLL and LDA models, Zhou\\n',\n",
       " 'et al. [14] propose a method that groups threads (i.e.,\\n',\n",
       " 'a question and related answers) of similar content into\\n',\n",
       " 'clusters to build a cluster-based thread for each user.\\n',\n",
       " 'Each cluster represents a coherent topic and is associ-\\n',\n",
       " 'ated with users to indicate the relevance relationship.\\n',\n",
       " 'The ranking score for a user is then computed based\\n',\n",
       " 'on the aggregation of the relevance of the user to all\\n',\n",
       " 'clusters given a new question. Guo [3] proposes a user-\\n',\n",
       " 'centric and category-sensitive generative model for dis-\\n',\n",
       " 'covering topics, named User-Question-Answer (UQA).\\n',\n",
       " 'The work incorporates topics discovered by UQA model\\n',\n",
       " 'with term-level matching methods to recommend ex-\\n',\n",
       " 'perts and increase the participation rate of users in\\n',\n",
       " 'CQA. In this model, each user is considered as a pseudo-\\n',\n",
       " 'document which is a combination of all the questions\\n',\n",
       " 'the user has asked and all the answers the user has pro-\\n',\n",
       " 'vided in reply to other users’ questions. More methods\\n',\n",
       " 'can be derived based on this model as well as the com-\\n',\n",
       " 'binations of these methods.\\n',\n",
       " '\\n',\n",
       " '4.4 Network-based Methods\\n',\n",
       " '\\n',\n",
       " 'The network-based methods evaluate users’ author-\\n',\n",
       " 'itativeness in a user-user network formed by their\\n',\n",
       " 'asking-answering relations and recommend the most\\n',\n",
       " 'authoritative users as experts for a new question. The\\n',\n",
       " 'simplest network-based method uses Indegree [41] to\\n',\n",
       " 'rank and recommend users.\\n',\n",
       " 'In particular, an inde-\\n',\n",
       " 'gree score equals the number of other users a user has\\n',\n",
       " 'helped by answering their questions, represented by an\\n',\n",
       " 'arrow from the requester to the answerer in the user-\\n',\n",
       " 'user network. Since frequent posters tend to have a\\n',\n",
       " 'signiﬁcant interest in the topic and a larger degree of a\\n',\n",
       " '\\n',\n",
       " 'node usually correlates with answer quality [41;42], this\\n',\n",
       " 'method regards the users with higher degrees as better\\n',\n",
       " 'answerers for the recommendation. The mainstream of\\n',\n",
       " 'this category include three families of methods based\\n',\n",
       " 'on PageRank [43], HITS [44], and ExpertiseRank [41], re-\\n',\n",
       " 'spectively. We will also brieﬂy introduce several other\\n',\n",
       " 'network-based methods to gain a comprehensive view\\n',\n",
       " 'of the related techniques.\\n',\n",
       " '\\n',\n",
       " '4.4.1 PageRank and Its Variants\\n',\n",
       " '\\n',\n",
       " 'PageRank [45;46] uses nodes to represent users, and a\\n',\n",
       " 'directed edge to indicate one user (i.e., the source node)\\n',\n",
       " 'answers the questions of another user (i.e., the destina-\\n',\n",
       " 'tion node). It estimates the likelihood that a random\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8\\n1\\n0\\n2\\n\\n \\nl\\nu\\nJ\\n \\n\\n5\\n1\\n\\n \\n \\n]\\nI\\nS\\n.\\ns\\nc\\n[\\n \\n \\n\\n1\\nv\\n0\\n4\\n5\\n5\\n0\\n\\n.\\n\\n7\\n0\\n8\\n1\\n:\\nv\\ni\\nX\\nr\\na\\n\\nWang X, Huang C, Yao L et al. A survey on expert recommendation in community question answering. JOURNAL OF\\nCOMPUTER SCIENCE AND TECHNOLOGY 33(1): 1–29 January 2018. DOI 10.1007/s11390-015-0000-0\\n\\nA Survey on Expert Recommendation in Community Question\\nAnswering\\n\\nXianzhi Wang1, Member, ACM, IEEE, Chaoran Huang2, Lina Yao2, Member, ACM, IEEE,\\nBoualem Benatallah2, Member, IEEE, and Manqing Dong2, Student Member, ACM, IEEE\\n\\n1 School of Software, University of Technology Sydney, NSW 2007, Australia\\n2 School of Computer Science and Engineering, University of New South Wales, Sydney, 2052 NSW, Australia\\nE-mail: xzwang@smu.edu.sg, {chaoran.huang, lina.yao, b.benatallah, manqing.dong}@unsw.edu.au\\n\\nReceived July 15, 2018; revised October 14, 2018.\\n\\nAbstract\\nCommunity question answering (CQA) represents the type of Web applications where people can exchange\\nknowledge via asking and answering questions. One signiﬁcant challenge of most real-world CQA systems is the lack of\\neﬀective matching between questions and the potential good answerers, which adversely aﬀects the eﬃcient knowledge\\nacquisition and circulation. On the one hand, a requester might experience many low-quality answers without receiving a\\nquality response in a brief time; on the other hand, an answerer might face numerous new questions without being able to\\nidentify their questions of interest quickly. Under this situation, expert recommendation emerges as a promising technique\\nto address the above issues. Instead of passively waiting for users to browse and ﬁnd their questions of interest, an expert\\nrecommendation method raises the attention of users to the appropriate questions actively and promptly. The past few\\nyears have witnessed considerable eﬀorts that address the expert recommendation problem from diﬀerent perspectives.\\nThese methods all have their issues that need to be resolved before the advantages of expert recommendation can be\\nfully embraced. In this survey, we ﬁrst present an overview of the research eﬀorts and state-of-the-art techniques for the\\nexpert recommendation in CQA. We next summarize and compare the existing methods concerning their advantages and\\nshortcomings, followed by discussing the open issues and future research directions.\\n\\nKeywords\\n\\ncommunity question answering, expert recommendation, challenges, solutions, future directions\\n\\n1 Introduction\\n\\nThe prosperity of crowdsourcing and web 2.0 has\\nfostered numerous online communities featuring ques-\\ntion answering (Q&A) activities. Such communities ex-\\nist in various forms such as dedicated websites, online\\nforums, and discussion boards. They provide a venue\\nfor people to share and obtain knowledge by asking\\nand answering questions, known as community ques-\\ntion answering (CQA) [1]. While traditional online in-\\nformation seeking approaches (e.g., search engines) re-\\ntrieve information from existing information reposito-\\nries based on keywords, they face several challenges.\\nFirst, answers to some questions may not exist in the\\npreviously answered questions [2] and thus cannot be re-\\ntrieved from existing repositories directly. Second, most\\nreal-world questions are written in complicated natu-\\n\\nral languages that require certain human intelligence\\nto be understood. Third, some questions inherently\\nseek people’s opinions and can only be answered by hu-\\nmans. While machines ﬁnd diﬃcult to handle the above\\ncases, CQA can leverage the “wisdom of crowds” and\\nobtain answers from multiple people simultaneously.\\nTypical Q&A websites include Yahoo! Answers (an-\\nswers.yahoo.com), Quora (www.quora.com), and Stack\\nOverﬂow (stackoverﬂow.com). The ﬁrst two websites\\ncover a wide range of topics, while the last only focuses\\non the topic of computer programming.\\n\\nThough advantages over the traditional information\\nseeking approaches, CQA faces several unique chal-\\nlenges. First, a CQA website may have tens of thou-\\nsands of questions posed every day, let alone the mil-\\nlions of questions that already exist on the website. The\\nhuge volume of questions makes it diﬃcult for a gen-\\n\\nSurvey\\n©2018 Springer Science + Business Media, LLC & Science Press, China\\n\\n\\x0c2\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\neral answerer to ﬁnd the appropriate questions to an-\\nswer [3]. Second, answerers usually have varying inter-\\nest and expertise in diﬀerent topics and knowledge do-\\nmains. Thus, they may give answers of varying quality\\nto diﬀerent questions. The time required for preparing\\nanswers [4] and the intention of answering also aﬀect the\\nquality of their responses. An extreme case is that an-\\nswerers may give irrelevant answers that distract other\\nusers [5] without serious thinking. All the above situa-\\ntions cause additional eﬀorts of an information seeker\\nin obtaining good answers. Third, instead of receiving\\nan answer instantly, users in CQA may need to wait a\\nlong time until a satisfactory answer appears. Previ-\\nous studies [6] show that many questions on real-world\\nCQA websites cannot be resolved adequately, meaning\\nthe requesters recognize no best answers to their ques-\\ntions within 24 hours.\\n\\nFortunately, several studies [7–9] have shown that\\nsome core answerers are the primary drivers of answer\\nproduction in the many communities. Recent work\\non Stack Overﬂow and Quora [10] further indicates that\\nthese sites consist of a set of highly dedicated domain\\nexperts who aim at satisfying requesters’ query but\\nmore importantly at providing answers with high last-\\ning value to a broader audience. All these studies sug-\\ngest the needs for recommending a small group of most\\ncompetent answerers, or experts to answer the new\\nquestions.\\nIn fact, the long-tail phenomena in many\\nreal-world communities, from the statistic perspective,\\nlays the ground of the rationale of expert recommenda-\\ntion in CQA [11], as most answers and knowledge in the\\ncommunities come from only a minority of users [11;12].\\nAs an eﬀective means of addressing the practical chal-\\nlenges of traditional information seeking approaches,\\nexpert recommendation methods bring up the attention\\nof only a small number of experts, i.e., the users who\\nare most likely to provide high-quality answers, to an-\\nswer a given question [13]. Since expert recommendation\\ninherently encourages fast acquisition of higher-quality\\nanswers, it potentially increases the participation rates\\nof users, improves the visibility of experts, as well as\\nfosters stronger communities in CQA.\\n\\nGiven the advantages of expert recommendation\\nand related topics such as question routing [6;14] and\\nquestion recommendation [15] in the domains of Natu-\\nral Language Processing (NLP) and Information Re-\\ntrieval (IR), we aim to present a comprehensive survey\\non the expert recommendation in CQA. On the one\\nhand, considerable eﬀorts have been conducted on the\\nexpert recommendation and have delivered fruitful re-\\n\\nsults. Therefore, it is necessary to review the related\\nmethods and techniques to gain a timely and better\\nunderstanding of state of the art. On the other hand,\\ndespite the active research in CQA, expert recommen-\\ndation remains a challenging task. For example, the\\nsparsity of historical question and answer records, low\\nparticipation rates of users, lack of personalization in\\nrecommendation results, the migration of users in or\\nout of communities, and lack of comprehensive consid-\\neration of diﬀerent clues in modeling users expertise are\\nall regarded as challenging issues in literature. Given\\nthe diverse existing methods, it is crucial to develop a\\ngeneral framework to evaluate these methods and ana-\\nlyze their shortcomings, as well as to point out promis-\\ning future research directions.\\n\\nTo the best of our knowledge, this is the ﬁrst com-\\nprehensive survey that focuses on the expert recommen-\\ndation issue in CQA. The remainder of the article is or-\\nganized as follows. We overview the expert recommen-\\ndation problem in Section 2 and its current applications\\nin CQA in Section 3. In Section 4, we present the clas-\\nsiﬁcation and introduction of state of the art expert rec-\\nommendation methods. In Section 5, we compare the\\ninvestigated expert recommendation methods on vari-\\nous aspects and discuss their advantages and pitfalls.\\nIn Section 6, we highlight several promising research\\ndirections. Finally, we oﬀer some concluding remarks\\nin Section 7.\\n\\n2 Expert Recommendation Problem\\n\\nThe expert recommendation issue is also known as\\nthe question routing or expert ﬁnding problem. The\\nbasic inputs of an expert recommendation problem in-\\nclude users (i.e., requesters and answerers) and user-\\ngenerated content (i.e., the questions raised by re-\\nquesters and the answers provided by answerers). More\\ninputs might be available depending on the applica-\\ntion scenarios. Typically, they include user proﬁles\\n(e.g., badges, reputation scores, and links to external\\nresources such as Web pages), users’ feedback on ques-\\ntions and answers (e.g., textual comments and votings),\\nand question details (e.g., the categories of questions\\nand duplication relations among questions). The rela-\\ntionship among the diﬀerent types of inputs of an ex-\\npert recommendation problem is described in the class\\ndiagram shown in Fig. 1.\\n\\nQuestion answering websites usually organize infor-\\nmation in the form of threads. Each thread is led by a\\nsingle question, which is replied to with none, one, or\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n3\\n\\nFig.1. Elements of expert recommendation in CQA.\\n\\nmultiple answers. Each question or answer is provided\\nby a single user, called a requester or an answerer, re-\\nspectively. A requester may ask multiple questions, and\\neach answerer may answer various questions. A user\\ncan be either a requester or an answerer, or both at the\\nsame time in the same CQA website, and all users are\\nfree to provide diﬀerent types of feedback on the posted\\nquestions and answers. For example, in Stack Overﬂow,\\nany registered user can comment and vote (by giving\\na thumb up or thumb down) on an answer posted for\\nany question, and the requester has the authority to\\nmark one from the posted answers as the best answer.\\nIn case that the requester has not designated the best\\nanswer within a speciﬁed period, the system will auto-\\nmatically mark the response that received the highest\\nvoting score as the best answer.\\n\\nThe objective of the expert recommendation prob-\\nlem is to raise the attention of experts, i.e., a small num-\\nber of users who are most likely to provide high-quality\\nanswers, to the given question based on the above prob-\\nlem inputs. Despite the various possible types of inputs,\\nonly a subset of them might be available in a speciﬁc\\napplication scenario. Therefore, researchers may deﬁne\\nthe expert recommendation problem diﬀerently accord-\\ning to the inputs. Besides, researchers may take into\\naccount diﬀerent concerns and expect diﬀerent types\\nof outputs from their methods. Generally, topical rel-\\nevance and expertise are the two most considered as-\\npects of concerns by the existing research. While some\\nresearchers develop methods to ﬁnd a group of high-\\nquality answerers, other researchers aim to deliver a\\nranked list, where the users are ranked according to\\ntheir potential to provide the best answer. We will\\nelaborate the variations in the problem deﬁnition in\\nSection 5.\\n\\nGenerally, it is only necessary to recommend experts\\nwhen the new question is signiﬁcantly diﬀerent from\\nany previous questions with best answers, meaning that\\n\\nno satisfactory answers are readily available within the\\narchive of best answers to the earlier questions. Expert\\nrecommendation generally brings about the following\\nadvantages to CQA: i) users usually prefer answers from\\nexperts, who are supposed to have suﬃcient motiva-\\ntion and knowledge to answer the given questions and\\ntherefore more likely to provide high-quality answers\\npromptly; ii) expert recommendations can potentially\\nreduce the waiting time of requesters in ﬁnding satis-\\nfactory answers as well as the time of experts in ﬁnd-\\ning their questions of interests; iii) by bridging the gap\\nbetween requesters and answerers, expert recommenda-\\ntions can potentially promote their participation rates\\nand thus foster stronger communities. Since experts\\nare recommended with questions that ﬁt their exper-\\ntise, their visibility is expected to be improved as well.\\n\\n3 Current Applications in CQA\\n\\nCurrently, there exist various Q&A websites where\\nexpert recommendation techniques are applied or can\\nbe potentially applied. Due to the large number of\\nQ&A websites that exist nowadays, we selectively list\\nsome typical Q&A websites by launch year in Table 1.\\nIn the following subsections, we will categorize and give\\nfurther illustrations of several typical websites of each\\ncategory.\\n\\n3.1 Early CQA Services\\n\\nMost early-stage Q&A services (e.g., the ﬁrst four\\nwebsites in Table 1) meet a requesters’ information\\nneeds by resorting to the opinions of experts rather than\\nthe crowd. These experts are acknowledged by either\\nthe websites or third-party authorities and are often\\nlimited in number. They usually have rich knowledge\\nand experience in some domains but require a payment\\nfor the answers they provide. We introduce two of these\\nwebsites as examples as follows:\\n\\n\\x0c4\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\nCommunity\\n\\nMedHelp\\n\\nMad Scientist Netwok\\n\\nWebMD\\n\\nGoogle Answers\\n\\nNaver KiN\\n\\nWikiAnswers\\n\\nAnswerbag\\n\\nIAsk\\n\\nBaidu Knows\\n\\nLive QnA\\n\\nTurboTax Live Community\\n\\nSogou Wenwen\\n\\nStack Overﬂow\\n\\nQuora\\n\\nSeasoned Advice\\n\\nTable 1. Some Popular Question Answering Communities\\n\\nLanguage\\n\\nSpecialized Domain\\n\\nLaunch Year\\n\\nStill Active\\n\\nQuality Guarantee\\n\\nEnglish\\n\\nEnglish\\n\\nEnglish\\n\\nMultiple\\n\\nKorean\\n\\nEnglish\\n\\nEnglish\\n\\nChinses\\n\\nChinese\\n\\nEnglish\\n\\nEnglish\\n\\nChinese\\n\\nEnglish\\n\\nEnglish\\n\\nEnglish\\n\\nMedical\\n\\nVarious\\n\\nMedical\\n\\nVarious\\n\\nVarious\\n\\nVarious\\n\\nVarious\\n\\nVarious\\n\\nVarious\\n\\nVarious\\n\\nTax\\n\\nVarious\\n\\nProgramming\\n\\nVarious\\n\\nCooking\\n\\n1994\\n\\n1995\\n\\n1996\\n\\n2002\\n\\n2002\\n\\n2002\\n\\n2003\\n\\n2005\\n\\n2005\\n\\n2006\\n\\n2007\\n\\n2007\\n\\n2008\\n\\n2010\\n\\n2010\\n\\nY\\n\\nY\\n\\nY\\n\\nN\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nN\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nY\\n\\nN\\n\\nN\\n\\nN\\n\\nN\\n\\nN\\n\\nN\\n\\nN\\n\\nN\\n\\nN\\n\\nN\\n\\nN\\n\\nMad Scientist Network 1 : a famous ask-a-scientist\\nweb service where people ask questions by ﬁlling forms\\nand moderators are responsible for reviewing the ques-\\ntions and sending them to the appropriate members for\\nanswers. The moderators will also review the answers\\nbefore making them public.\\n\\nGoogle Answers 2 : a knowledge market service de-\\nsigned as an extension to Google’s search service. There\\nwere a group of answerers called Google Answers Re-\\nsearchers who are oﬃcially approved to answer ques-\\ntions through an application process. Instead of pas-\\nsively waiting for other people to moderate or answer\\ntheir questions, people can actively ﬁnd the potential\\nanswerers by themselves and pay the answerers.\\n\\n3.2 General-purpose CQA Websites\\n\\nThe Q&A services that emerge in the past two\\ndecades are increasingly leveraging the “wisdom of the\\ncrowd” rather than a small number of experts to give\\nanswers. Websites following this philosophy allow any\\nusers to voluntarily answer any questions on their free\\nwill and most of them serve as general purpose plat-\\nforms for knowledge sharing rather then domain fo-\\ncused ones. We overview some typical general purpose\\nwebsites as follows:\\n\\nQuora: one of the largest existing Q&A website\\nwhere users can ask and answer questions, rate and\\nedit the answers posted by others.\\n\\nZhihu 3 : a Chinese Q&A website similar to Quora.\\nIt allows users to create and edit questions and answers,\\nrate system, and tag questions. Also, users may also\\npost blogs in Zhihu for sharing while others can view\\nand comment on such posts.\\n\\nNaver KiN 4 : a Korean CQA community, one of\\nthe earlier cases of expansion of search service using\\nuser-generated content.\\n\\nWikiAnswers 5 : a wiki service that allows people\\nto raise and answer questions, as well as edit existing\\nanswers to questions. It uses a so-called “alternates sys-\\ntem” to automatically merge similar questions. Since\\nan answer may be associated with multiple questions,\\nduplicated entries can be avoided to some extent.\\n\\nAnswerbag 6 : a CQA community where users can\\nask and answer questions, give comments to answers,\\nrate questions, rate answers, and suggest new cate-\\ngories.\\n\\nLive QnA 7 : also known as MSN QnA, was part of\\nMicrosoft MSN group services.\\nIn this system, users\\ncan ask and answer questions, tag them to speciﬁc top-\\nics, and gain points and reputations by answering ques-\\n\\n1 http://www.madsci.org/, May 2018.\\n2 http://answers.google.com/, May 2018.\\n3 http://www.zhihu.com/, May 2018.\\n4 http://kin.naver.com/, May 2018.\\n5 http://www.wikianswers.com/, May 2018.\\n6 http://www.answerbag.com/, May 2018.\\n7 http://qna.live.com/, May 2018.\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n5\\n\\ntions.\\n\\n4 Expert Recommendation Methods\\n\\n3.3 Domain-focused CQA Websites\\n\\nCompared with those general purpose websites,\\neach domain-focused Q&A website only covers limited\\ntopics or knowledge domains. The Stack Exchange net-\\nworks are probably the largest host of domain-focused\\nQ&A websites nowadays. Some typical websites hosted\\nby it include the following:\\n\\nMathOverﬂow 8 : a Q&A website focused on math-\\n\\nematical problems.\\n\\nAskUbuntu 9 : a website supporting Q&A activities\\n\\nrelated to Ubuntu operation Systems.\\n\\nStackOverﬂow : a Q&A website focused on com-\\n\\nputer programming.\\n\\nAll these websites follow similar sets of styles and\\nfunctions. Apart from the basic question answering\\nfeatures, they commonly use badges to recognize the\\nachievement of answerers and grant badges to users\\nbased on their reputation points. Users can also un-\\nlock more privileges with higher reputation points.\\n\\n3.4 Summary\\n\\nIn summary, despite the prevalence of diverse types\\nof Q&A websites, few of them have incorporated any\\neﬀective expert recommendation techniques to bridge\\nrequesters and answers. To the best of our knowledge,\\ncurrently, the only implementation of the idea of rout-\\ning questions to the appropriate users in Q&A is called\\n“Aardvark” [16]. However, the primary purpose of this\\nsystem is to serve as an enhanced search engine, and\\nthe expert recommendation techniques it employs are\\nstill at a preliminary stage. Recently, Bayati et al. [17]\\ndesign a framework for recommending security experts\\nfor software engineering projects. This framework oﬀers\\nmore strength to facilitate expert recommendation by\\nconsidering multiple aspects of users such as program-\\nming language, location, and social proﬁles on domi-\\nnant programming Q&A websites like StackOverﬂow.\\nSince the Q&A systems can be regarded as a type of\\ncrowdsourcing systems [18], the expert recommendation\\nmethods for a Q&A system can potentially be gener-\\nalized and applied to general crowdsourcing systems as\\nwell.\\n\\n8 http://mathoverﬂow.net/, May 2018.\\n9 http://askubuntu.com/, May 2018.\\n\\nAs the major technique to facilitate eﬀective CQA,\\nconsiderable eﬀorts have been contributed to the ex-\\npert recommendation research from the information re-\\ntrieval (IR), machine learning, and social computing\\nperspectives, and have delivered fruitful results. We\\nclassify the state of the art expert recommendation\\nmethods into eight categories and review the methods\\nby category in the following subsections.\\n\\n4.1 Simple Methods\\n\\nOne of the most critical tasks of expert recommen-\\ndation is to evaluate users. Given a new question to\\nbe answered, some methods use simple metrics such\\nas counts of positive/negative votes, proportions of\\nbest answers, and the similarity between the new ques-\\ntion and users’ previous answered questions to evaluate\\nusers’ ﬁtness to answer the questions. In the following,\\nwe introduce the methods that use the three metrics,\\nrespectively. For any of these methods, a higher score\\nindicates a better answerer.\\n\\nVotes: the method evaluates a user by the number\\nof aﬃrmative votes minus the number of negative votes,\\ncombined with the total percentage of aﬃrmative votes\\nthat the user receives from other users averaged over\\nall the answers the user have attempted.\\n\\nBest answer proportion: this method ranks users by\\nthe fraction of best answers among all the answers at-\\ntempted by an answerer. The best answers are either\\nawarded by the requester of questions or by the ques-\\ntion answering platform when requesters designate no\\nbest answers.\\n\\nTextual similarity:\\n\\nthe most famous method for\\nmeasuring textual similarity is to compute the cosine\\nsimilarity based on the term frequency-inverse docu-\\nment frequency (TF-IDF) model, a classic vector space\\nmodel (VSM) [19] borrowed from the information re-\\ntrieval domain. VSM is readily applicable to computing\\nthe similarity of an answerer’s proﬁle to a given ques-\\ntion. Therefore, it can be directly used for the expert\\nrecommendation by relating a new question to the an-\\nswerers who have previously answered the most relevant\\nquestions to the given question.\\n\\n\\x0c6\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\n4.2 Language Models\\n\\nDespite the simplicity, VSM adopts the “bag-of-\\nwords” assumption and thus brings the high-dimension\\ndocument representation issue.\\nIn contrast, language\\nmodels use a generative approach to compute the word-\\nbased relevance of a user’s previous activities to the\\ngiven question, and in turn, to predict the possibility\\nof a user answering the question. Such models can,\\nto some extent alleviate the high dimension issue. In a\\nlanguage model, the users whose proﬁles are most likely\\nto generate the given question are believed to have to\\nhighest probability to answer the given question. The\\nmodel ﬁnally returns a ranked list of users according to\\ntheir likelihood of answering the given question.\\n\\nThe language model-based methods include proﬁle-\\nbased methods and document-based methods. The for-\\nmer [20] models the knowledge of each user with the as-\\nsociated documents and ranks the candidate experts\\nfor a given topic based on the relevance scores between\\ntheir proﬁles and the given question. The latter [20]\\nﬁnds related documents for a given topic and ranks\\ncandidates based on mentions of the candidates in the\\nrelated documents.\\n\\n4.2.1 QLL and Basic Variants\\n\\nAmong the methods of this category, query likeli-\\nhood language (QLL) model [21] is the most popular\\ntechnique. QLL calculates a probability that user pro-\\nﬁles will generate terms of the routed question. The\\ntraditional language models often suﬀer the mismatch\\nbetween the question and user proﬁles caused by the\\nco-occurrence of random words in user proﬁles or ques-\\ntions resulting from data sparseness. Translation mod-\\nels [22] overcomes data sparseness by employing statis-\\ntical machine translation and can diﬀerentiate between\\nexact matched words and translated semantically re-\\nlated ones. A typical work [23] using this method views\\nthe problem as an IR problem.\\nIt considers the new\\nquestion as a query and the expert proﬁles as docu-\\nments.\\nIt next estimates an answerer’s expertise by\\ncombining its previously answered questions, and re-\\ngards experts as the users who have answered the most\\nsimilar questions in the past.\\n\\nBesides the basic models, many variants of QLL\\nhave also emerged as alternatives or enhancements. For\\nexample, Liu et al. propose two variants of the ba-\\nsic language model, namely relevance-based language\\nmodel [24] and cluster-based language model [25] to rank\\nuser proﬁles. Petkova and Croft [26] propose a hierarchi-\\ncal language model which uses a ﬁner-grained approach\\n\\nwith a linear combination of the language models built\\non subcollections of documents.\\n\\n4.2.2 Category-sensitive QLL\\n\\nConsidering the availability of categories in many\\nQ&A websites, Li et al. [27] propose a category-sensitive\\nQLL model to exploit the hierarchical category infor-\\nmation presented with questions in Yahoo! Answers.\\nOnce a question gets categorized, the task is to ﬁnd the\\nusers who are most likely to answer that question within\\nits category. Their experiments over the Yahoo! An-\\nswers dataset show that taking categories into account\\nimproves the recommendation performance. A limita-\\ntion of the category-sensitive model is that categories\\nneed to be well predeﬁned and some questions might\\nbe closely related to multiple categories due to the ex-\\nistence of similar categories that share the same con-\\ntexts. A possible solution to address this limitation is\\nthe transferred category-sensitive QLL model [27], which\\nadditionally builds and considers the relevance between\\ncategories.\\n\\n4.2.3 Expertise-aware QLL\\n\\nZheng et al. [28] linearly combine two aspects, user\\nrelevance (computed based on the QLL) and answer\\nquality (estimated using a maximum entropy model),\\nusing the simple weighted sum method to represent\\nuser expertise on a given question. Besides the rele-\\nvance and quality aspects, Li et al. [6] further consider\\nthe availability of users and use the weighted sum of\\nthe three aspects to represent user expertise on a given\\nquestion. In particular, the relevance is estimated us-\\ning the QLL model, the answer quality is estimated as\\nthe weighted average of previous answer quality incor-\\nporated with the Jelinek-Mercer smoothing [29] method,\\nand users’ availability to answer a given question during\\na given period is predicted by an autoregressive model.\\nCompared with most existing methods, this method ex-\\nploits not only time series availability information of\\nusers but also multiple metadata features such as an-\\nswer length, question-answer length, number of answers\\nfor this question, the answerer’s total points, and the\\nanswerer’s best answer ratio. These features have rarely\\nbeen used by the existing research.\\n\\n4.3 Topic Models\\n\\nSince language models are based on exact word\\nmatching, they are most eﬀective when they are used\\nwithin the same topic. Besides, they are not able to\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n7\\n\\ncapture more advanced semantics and solve the prob-\\nlem of the lexical gap between a question and user pro-\\nﬁles. In contrast, topic models do not require the word\\nto appear in the user proﬁle, as it measures their re-\\nlationship in the topic space rather than in the word\\nspace. It can, therefore, alleviate the lexical gap prob-\\nlem and previous experimental evaluations have con-\\nﬁrmed the better performance of many topic models\\nover language models [30;31]. Here, we focus on review-\\ning two most widely used topic models, Probabilistic\\nLatent Semantic Analysis (PLSA) and Latent Dirichlet\\nAllocation (LDA), as well as their variants and a few\\nother models.\\n\\n4.3.1 PLSA and Its Variants\\n\\nProbabilistic Latent Semantic\\n\\nProbabilistic Latent Semantic Analysis (PLSA)\\na.k.a.\\nIndexing\\n(PLSI) [32] is developed based on Latent Semantic In-\\ndexing (LSI) [33], which uses Singular Value Decomposi-\\ntion to represent a document in a low-dimension space.\\nCompared with LSI, which lacks semantic explanation,\\nPLSA uses latent topics to represent documents and\\nmodel the data generation process as a Bayesian net-\\nwork. In this way, it can leverage the semantic between\\nwords in documents to reduce the document representa-\\ntion space dimension. There are generally two classes of\\nPLSA-based methods that model users directly and in-\\ndirectly, respectively. We brieﬂy review the two classes\\nof methods as follows:\\n\\nDirect User Model by PLSA. Methods of this class\\ntreat all the questions that a user accesses as one docu-\\nment. Then, PLSA is used directly to derive the topic\\ninformation of the user using word distributions. A typ-\\nical method of this class [15] would identify the under-\\nlying topics of questions to match users’ interest and\\nthereby help the capable users locate the right ques-\\ntions to answer. The Expectation Maximization (EM)\\nalgorithm is generally used to ﬁnd a local maximum of\\nthe log-likelihood of the question collection and to learn\\nmodel parameters.\\n\\nIndirect User Model by PLSA. A typical method of\\nthis class is proposed in [34]. This work presents an\\nincremental automatic expert recommendation frame-\\nwork based on PLSA. It considers both users’ interests\\nand feedback and takes questions as documents. It fur-\\nther uses PLSA to model the question to gain its distri-\\nbution on topics, followed by representing users as the\\naverage of topic distributions of all the questions that\\nhe accesses to facilitate recommendation.\\n\\nA most important variant of PLSA is probably the\\nDual Role Model (DRM) proposed by Xu et al. [35].\\nInstead of combining the consideration of a user as\\na requester and an answerer, DRM separately mod-\\nels users’ roles as requesters and as answerers and de-\\nrive the corresponding probabilistic models based on\\nPLSA. Depending on the modeling approach of user’s\\nrole, DRM diverges into independent DRM, a type of\\nmethod modeling user role indirectly, and dependent\\nDRM, a method which learns the role model directly.\\nIn particular, the independent DRM assumes all users\\nare independent of each other and models each user\\nindividually.\\nIn contrast, dependent DRM considers\\nthe dependence between users. Besides modeling users’\\ntopic distribution as requesters and answerers, it addi-\\ntionally models the relationship between answerers and\\nrequesters for better performance.\\n\\n4.3.2 LDA and Its Variants\\n\\nThe Latent Dirichlet Allocation (LDA) model [36] is\\nprobably the most widely used topic model among all\\nexisting topic models developed.\\nIn LDA, the topic\\nmixture is drawn from a conjugate Dirichlet prior that\\nremains the same for all users. More speciﬁcally, LDA\\nassumes a certain generative process for data. To gener-\\nate a user proﬁle, LDA assumes that for each user pro-\\nﬁle a distribution over topics is sampled from a Dirich-\\nlet distribution. In the next step, for each word in the\\nuser proﬁle, a single topic is chosen according to this\\ntopic distribution. Finally, each word is sampled from\\na multinomial distribution over words speciﬁc to the\\nsampled topic. Here, we brieﬂy review two important\\nclasses of LDA variants that have been applied for the\\nexpert recommendation in CQA:\\n\\nSegmented Topic Model (STM) [37]. This is a topic\\nmodel that discovers the hierarchical structure of top-\\nics by using the two-parameter Poisson Dirichlet pro-\\ncess [38]. As a four-level probabilistic model, STM con-\\ntains two levels of topic proportions and shows supe-\\nriority over traditional models. Instead of grouping all\\nthe questions of a user under a single topic distribution,\\nit allows each question to have a diﬀerent and separate\\ndistribution over the topics. A user proﬁle is considered\\na document that contains questions (segments). The\\nabove distributions cover the expertise set of a user,\\nthe topics of each question in the proﬁle, as well as the\\ncorrelation between each proﬁle and its questions.\\n\\nTagLDA [39]. This method uses only tag informa-\\ntion to infer users’ topical interest. It is more eﬃciently,\\n\\n\\x0c8\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\nbut the eﬀectiveness is dependent on the accuracy and\\navailability of tags.\\n\\n4.3.3 Expertise-aware LDA\\n\\nThe work in [40] considers both the topical interest\\nand expertise of a user relevant to the topics of the\\ngiven question. It also uses LDA to identify topical in-\\nterest from previous answers of the user, but additional\\ncompute the expertise level of users using collaborative\\nvoting mechanism. Sahu et al. [39] incorporate question\\ntags and related voting information in LDA to compute\\nuser expertise, where user expertise is computed based\\non both the topical distribution of users and voting in-\\nformation under the same question tags.\\n\\n4.3.4 Other Topic Models\\n\\nBesides the famous QLL and LDA models, Zhou\\net al. [14] propose a method that groups threads (i.e.,\\na question and related answers) of similar content into\\nclusters to build a cluster-based thread for each user.\\nEach cluster represents a coherent topic and is associ-\\nated with users to indicate the relevance relationship.\\nThe ranking score for a user is then computed based\\non the aggregation of the relevance of the user to all\\nclusters given a new question. Guo [3] proposes a user-\\ncentric and category-sensitive generative model for dis-\\ncovering topics, named User-Question-Answer (UQA).\\nThe work incorporates topics discovered by UQA model\\nwith term-level matching methods to recommend ex-\\nperts and increase the participation rate of users in\\nCQA. In this model, each user is considered as a pseudo-\\ndocument which is a combination of all the questions\\nthe user has asked and all the answers the user has pro-\\nvided in reply to other users’ questions. More methods\\ncan be derived based on this model as well as the com-\\nbinations of these methods.\\n\\n4.4 Network-based Methods\\n\\nThe network-based methods evaluate users’ author-\\nitativeness in a user-user network formed by their\\nasking-answering relations and recommend the most\\nauthoritative users as experts for a new question. The\\nsimplest network-based method uses Indegree [41] to\\nrank and recommend users.\\nIn particular, an inde-\\ngree score equals the number of other users a user has\\nhelped by answering their questions, represented by an\\narrow from the requester to the answerer in the user-\\nuser network. Since frequent posters tend to have a\\nsigniﬁcant interest in the topic and a larger degree of a\\n\\nnode usually correlates with answer quality [41;42], this\\nmethod regards the users with higher degrees as better\\nanswerers for the recommendation. The mainstream of\\nthis category include three families of methods based\\non PageRank [43], HITS [44], and ExpertiseRank [41], re-\\nspectively. We will also brieﬂy introduce several other\\nnetwork-based methods to gain a comprehensive view\\nof the related techniques.\\n\\n4.4.1 PageRank and Its Variants\\n\\nPageRank [45;46] uses nodes to represent users, and a\\ndirected edge to indicate one user (i.e., the source node)\\nanswers the questions of another user (i.e., the destina-\\ntion node). It estimates the likelihood that a random\\nwalk following links (and occasional random jumps) will\\nvisit a node. Each edge is associated with an aﬃnity\\nweight that measures the times that the answerer has\\nreplied to the requesters’ questions. Two users are con-\\nnected if their aﬃnity weight is greater than 0, and\\nthe transition probabilities between nodes are obtained\\nby normalizing the aﬃnity weights. Now, the algorithm\\nhas been extended to bias the jump probability for par-\\nticular topics [47] and many others static web ranking\\ntasks. Choetkiertikul et al. [48] also use PageRank, but\\nthey measure the weights diﬀerently, i.e., evaluating the\\nnumber of users’ tags and activity times in common as\\nweights between the users who have asking-answering\\nrelations.\\n\\nThe main variants of PageRank include SALSA [49],\\nEntityRank [50], TwitterRank [51], and AuthorRank [52].\\nThey diﬀer from the above PageRank-based methods\\nin focusing on some speciﬁc application domains. How-\\never, they still have the potential to be generalized to\\nbroader scenarios.\\n\\n4.4.2 HITS and Its Variants\\n\\nDiﬀerent from PageRank, which does not distin-\\nguish between hub and authority nodes, the HITS al-\\ngorithm is based on the observation that there are two\\ntypes of nodes: (1) hubs, which links to authoritative\\nnodes; (2) authorities, which provide useful information\\non the given topics. HITS assigns each node two scores:\\nhub score and authority score. A hub score represents\\nthe quality of outgoing links from the nodes while au-\\nthority represents the quality of information located on\\nthat nodes. A typical work based on HITS is proposed\\nby Jurczyk et al. [45;46]. Instead of the times of the an-\\nswerer replying to the requester’s questions, this work\\nmodels the weights of edges to indicate answer quality\\nin HITS, based on users’ explicit feedback, e.g., thumb\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n9\\n\\nup/down from users, and whether the answer is the best\\nanswer. The results show that the HITS algorithm out-\\nperforms the methods based on simple graph measures\\nsuch as in-degree.\\n\\nAn important variant of HITS is proposed by\\nShahriari et al. [53].\\nInstead of considering the entire\\nuser-user network as a single community, this method\\nregards the network as the combination of multiple\\nuser communities. Thereby,\\nit detects overlapping\\ncommunities [54] and diﬀerentiate the impact of intra-\\ncommunity and inter-community users to other users\\nin the user-user network.\\n\\n4.4.3 Expertise-aware Network-based Methods\\n\\nZhang et al. [41] propose ExpertiseRank based on\\nthe intuition that an answerer whore replies to a ques-\\ntion usually has superior expertise than the requester\\non the speciﬁc topic. Their experimental results indi-\\ncate that for a closed domain such as the Java devel-\\noper forum, ExpertiseRank performs better than gen-\\neral graph-based algorithms like PageRank and HITS.\\nExpertiseRank considers not only how many other users\\na user has helped but also which other users the user\\nhas helped. It propagates the expertise scores of users\\nthrough the question-answer relationship in a user-user\\nnetwork. The intuition behind ExpertiseRank is that\\none should get more credit for answering the questions\\nof a user with higher expertise rather than the questions\\nof a user with lower expertise.\\n\\nThe ExpertiseRank computation ﬁnally derives a\\nscore for each user, called z-score, based on which\\nto quantify their authoritativeness. Z-score [41] com-\\nbines users’ asking and replying patterns to measure\\nhow many standard deviations above or below the ex-\\npected ‘random’ value a user lies. The more questions\\na user has answered and the fewer questions the user\\nhas asked, the higher the Z-score of this user. There-\\nfore, this method recommends users with the highest z-\\nscores as experts. The experts obtained by this method\\nshould answer many questions and ask very few ques-\\ntions.\\n\\nBesides ExpertiseRank, Jurczyk et al. [45] incorpo-\\nrate users’ authoritativeness on a given question (esti-\\nmated by the tags of users’ posts) and users’ answer\\nquality (predicted based on their past answer activi-\\nties); the method in [55] diﬀers in determining user qual-\\nity by the number of best answers they provide. Zhou\\net al. [14] use the post content of users to compute user\\nexpertise and reply frequencies of users computed by\\nPageRank to re-rank users. They further use inverted\\n\\nindexes and threshold algorithm [56] to store and re-\\ntrieve pre-computed intermediate scores to accelerate\\nthe computation. The ﬁnal score of a user takes the\\nproduct of the results of language model and the re-\\nsults of PageRank.\\n\\n4.4.4 Other Network-based Methods\\n\\nHere, we review some typical enhancement or ex-\\ntension of the traditional link analysis methods as fol-\\nlows: Zhu et al. [57;58] additionally consider the cate-\\ngory relevance of questions and rank user authority in\\nan extended category link graph; Liu et al. [59] compre-\\nhensively utilize multiple types of relationships between\\nrequesters and answerers, and between the best answer-\\ners and other answerers to ﬁnd expert users; rather\\nthan leveraging the asking-answering interactions, Lai\\net al. [60] employ the endorsement relationship among\\nusers to form user reputation graphs, based on which\\nto recommend experts. Similarly, Lin et al. [61]compute\\nuser reputation based on their trust relationship in a\\nuser-user network. By assuming each question has a\\nknown category and theme, they cluster users based\\non their reputation scores on each question theme and\\nevaluate users based on their theme-speciﬁc reputation.\\nLiu et al. [62] incorporate user-subject relevance (com-\\nputed by cosine similarity) and user reputation with\\nusers’ category-speciﬁc authoritativeness obtained from\\nlink analysis for the expert recommendation.\\n\\nThe latest network-based method is proposed by Liu\\net al. [63]. This work routs questions to potential an-\\nswerers from the viewpoint of knowledge graph embed-\\nding and integrates topic representations with network\\nstructure into a uniﬁed question routing framework.\\nThe framework takes into account various types of re-\\nlationships among users and questions.\\nIt is demon-\\nstrated to increase the answer rates of questions by us-\\ning the recommended experts.\\n\\n4.5 Classiﬁcation Methods\\n\\nWhen regarding experts as a particular class of users\\namong all users, the problem of identifying the experts\\ncan be easily transformed into a classiﬁcation problem\\nthat aims to distinguish such a particular class of expert\\nusers from the other users. Compared with the other\\nmethods, classiﬁcation methods can easily apply multi-\\nple aspects of features from the user, question, answer,\\nor user-user interaction’s perspectives, to the expert\\nrecommendation problem. For example, Pal et al. [64]\\nuse three classes of features and train a binary classiﬁer\\n\\n\\x0c10\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\nto distinguish experts from ordinary users. These fea-\\ntures include question features (e.g., question length,\\nword n-gram), user features (e.g., number of answers\\nand number of best answers provided by a user), and\\nuser feedback on answers (e.g., user votes and com-\\nments to the answers),\\n\\nSupport Vector Machine (SVM) is the most used\\nclassiﬁcation method for distinguishing expert from\\nthose non-experts. Beside diverse methods, the clas-\\nsiﬁcation methods have used diﬀerent features besides\\nthe basic question and user features, such as part-of-\\nspeech features, graph features to trains their models.\\nFor example, Pal et al. [65] extract features by model-\\ning users’ motivation and ability to help others and use\\nSVM and C4.5 decision tree separately for expert detec-\\ntion. Zhou et al. [66] also use SVM but they deﬁne both\\nlocal and global features on questions, user history, and\\nquestion-user relationship and additional consider KL-\\ndivergence as a new feature. Ji et al. [67] additionally\\nuse text similarities as features to train SVM and one\\nof its variant, RankingSVM.\\n\\nBesides, more methods such as random forests\\n(RF) [48] and Naive Bayes [68] are used by existing stud-\\nies. Some typical work includes: Le et al. [69] con-\\nsider more new features such as community features\\n(e.g., average score of posts, average number of com-\\nments, average favorites marked), temporal features\\n(e.g., time gaps between posts), and consistent fea-\\ntures (e.g., scores of the posts, time gap between re-\\ncent posts). They also try some new methods like lo-\\ngistic regression and adaptive boosting in addition to\\ndecision trees and random forest for the classiﬁcation.\\nAs an enhancement to decision trees, Dror et al. [70]\\npropose a representation model based on multi-channel\\nvector space model, where users and questions are rep-\\nresented as vectors consisting of multi-dimensional fea-\\ntures. Then, the matching degree between a user and\\na question is learned from their respective features us-\\ning a binary classiﬁer called Gradient Boosted Decision\\nTrees (GBDT).\\n\\nInstead of the conventional features used for iden-\\ntifying experts, Pal et al. [64] use a diﬀerent crite-\\nrion, question selection bias, for recommending experts,\\nbased on the assumption that experts prefer answering\\nquestions to which they bear a higher chance of mak-\\ning a valuable contribution. o They use the probability\\nof answering questions of diﬀerent value as the feature\\nvector and employ two methods, logistic regression and\\nGaussian Mixture Model, to solve the binary classiﬁca-\\ntion problem. In a later version, Pal et al. [71] use diﬀer-\\n\\nent equations to estimate the value of existing questions\\nand to model the selection probabilities of questions by\\nusers. The method shows better performance of the\\nBagging metaclassiﬁer over several single-version clas-\\nsiﬁcation algorithms The work also partially conﬁrms\\nthat experts have some bias on question selection based\\non the existing value of answers to the questions.\\n\\nGiven the advantages of ranked recommendation re-\\nsults over unranked results, Ji et al. [67] propose Rank-\\ningSVM, a ranking model based on SVM, for the ex-\\npert recommendation. Burel et al. [72] extract pat-\\nterns from the question-selection behaviors of users in\\na Q&A community and then use Learning to Rank\\n(LTR) models to identify the most relevant question\\nto a user at any given time. They further employ Ran-\\ndom Forests, LambdaRank [73], and ListNet [74] to de-\\nrive a pointwise method, a pairwise method, and a list-\\nwise method, respectively, to gain ranked expert list\\nalong with the classiﬁcation process. Similarly, Cheng\\net al. [75] also formalize expert ﬁnding as a learning-to-\\nrank task. However, they leverage users’ voting infor-\\nmation on answers as the “relevance” labels and utilize\\nLambdaMART to learn ranking models which directly\\noptimizes a rank-based evaluation metric, normalized\\ndiscounted cumulative gain (nDCG). Logistic regres-\\nsion [76] has also been used recently to facilitate both\\nranking and classiﬁcation.\\n\\n4.6 Expertise Probabilistic Models\\n\\nDom et al. [77] propose the only probabilistic model\\nthat focuses on user expertise for the expert recom-\\nmendation in CQA. They use a Bayesian probabilis-\\ntic model to obtain a posterior estimate of user credi-\\nbility thereby recommending experts for a given ques-\\ntion. This work assumes user expertise conforms to the\\nBernoulli distribution (or the mixture of two beta distri-\\nbutions) and uses Maximum A Posteriori (MAP) esti-\\nmation to make predictions. It then ranks users accord-\\ning to their probabilities of providing the best answer to\\nthe given question, characterized by the probability of\\neach user to be awarded the best answer on a question\\ngiven the user’s question-answering history. The work\\nalso discovered that Bayesian smoothing performs bet-\\nter than several other smoothing methods such as max-\\nimum a priori estimation, maximum likelihood (ML)\\nestimation, and Laplace smoothing.\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n11\\n\\n4.7 Collaborative Filtering Methods\\n\\nGiven the advantages such as ﬂexibility and scala-\\nbility of collaborative ﬁltering (CF) methods, esp., the\\nmatrix factorization techniques [78] in the recommenda-\\ntion domain, some researchers seek to use CF for the\\nexpert recommendation in CQA. For example, Cho et\\nal. [79] consider that case that only one expert will be\\ndesignated to answer each question. They then cap-\\nture users’ behavioral features as potential answerers\\nby matrix factorization [80]. Regularization terms are\\nincorporated to represent user interest, user similarity,\\nand users’ probability to answer for better performance.\\nInstead of the basic matrix factorization model,\\nYang et al. [81] employ probabilistic matrix factorization\\n(PMF), which combines generative probabilistic model\\nand matrix factorization, to address the expert recom-\\nmendation problem. In particular, PMF learns the la-\\ntent feature space of both users and tags to build a\\nuser-tag matrix [82], which is then used to recommend\\nexperts given a new question.\\n\\n4.8 Hybrid Methods\\n\\nTo comprehensively take into account multiple as-\\npects of clues, some researchers propose hybrid methods\\nthat combine diﬀerent aspects of concerns techniques\\nand diﬀerent techniques for better recommendation re-\\nsults. Here, we review the typical hybrid methods as\\nfollows.\\n\\n4.8.1 Language Model + Topic Model\\n\\nLiu et al. [30] combine QLL and LDA and show the\\nhybrid approach outperforms either of the original mod-\\nels.\\n\\n4.8.2 Topic Model + Network-based Method\\n\\nZhou et al. [83] identify authoritative users by con-\\nsidering both the link structure and topic information\\nabout users. They ﬁrst apply LDA to obtain user-topic\\nmatrix and topic-word matrix, and then use PageR-\\nank and Topical PageRank for the expert recommen-\\ndation. Liu et al. [84] propose a topic-sensitive proba-\\nbilistic model to estimate the user authority ranking\\nfor each question. The model is based on PageRank\\nincorporate with topical similarities between users and\\nquestions. A very similar method named topic-sensitive\\nlink analysis is proposed by Yang et al. [85]. Recently,\\nRao et al. [86] propose a similar approach that recom-\\nmends experts based on users’ topical relevance and\\nauthoritativeness given a new question. They also use\\n\\nLDA to discover topics but measure users’ authorita-\\ntiveness for each topic based on the ‘like’ relationship\\namong users in a social network.\\n\\nZhao et al. [87] use the TEL model to generate topic\\ninformation, based on which to model experts over top-\\nics. TEL is based on LDA and is a uniﬁed model\\ncombining both graph-based link analysis and content-\\nbased semantic analysis for expert modeling in CQA.\\nInstead of using a ﬁxed user-answering graph to inﬂu-\\nence the prior of expert modeling, TEL highlights the\\ncausal relationship between topics and experts by using\\nboth user-user matrix and question-user matrix to rep-\\nresent a user’s contribution to another user or a ques-\\ntion, with best answers given higher weights. It is com-\\npared with two baseline topic modeling methods, one\\nrecommending experts based on requester-answerer in-\\nteractions and the other recommending experts based\\non question-answerer interactions, which show its bet-\\nter performance.\\n\\nZhou et al. [88] extend PageRank with the topic-\\nsensitive probabilistic model by considering topical\\nsimilarity.\\nIn particular, the method improves the\\nPageRank-based expert recommendation methods by\\nrunning PageRank for each topic separately, with each\\ntopic-speciﬁc PageRank prefers those users with high\\nrelevance to the corresponding topic. As a further\\nstep, Yang et al. [89] jointly model topics and exper-\\ntise to ﬁnd experts with both similar topical preference\\nand superior topical expertise on the given question.\\nThe method integrates textual content model (GMM)\\nand link structure analysis and leverages both tagging\\nand voting information.\\nIt linearly incorporates the\\nestimated user topical expertise score into the recur-\\nsive PageRank score computation formula and extends\\nPageRank to make the ﬁnal recommendation.\\n\\n4.8.3 Language+Topic+Network-based Model\\n\\nLiu et al. [30] assume that more authoritative an-\\nswerers may give more accurate answers, and more ac-\\ntive answerers may be more willing to answer new ques-\\ntions. They linearly combine QLL and LDA models to\\ncompute relevance, and additionally consider both user\\nactivity and authority information for the recommen-\\ndation.\\n\\n4.8.4 Topic Model + Classiﬁcation Method\\n\\nRankingSVM [67] employs LDA to calculate text\\nsimilarity and use this similarity as a feature in a\\nclassiﬁcation method for the expert recommendation.\\n\\n\\x0c12\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\nThe experimental results show the resulting method\\nachieves better performance than SVM.\\n\\n4.8.5 Topic Model +Collaborative Filtering\\n\\nYan et al. [90] combine topic model and tensor fac-\\ntorization for the expert recommendation. They train\\nan LDA via Gibbs Sampling with a manually deﬁned\\ntopic number, followed by performing tensor factoriza-\\ntion (TF) based on “requester-topic-answerer ” triples\\nvia gradient descent to compute the recommendation\\nscores of users.\\n\\n4.8.6 Network-based Method + Clustering\\n\\nFollowing the similar idea of geo-social community\\ndiscovery [91] in Point of Interest (POI) recommenda-\\ntion, Bouguessa et al. [55] incorporate clustering meth-\\nods with network-based measures for the expert recom-\\nmendation. In particular, they consider the number of\\nbest answers as an indicator of authoritativeness of a\\nuser in a user-user network, where users are connected\\nvia directed edge from requesters to best answerer, with\\nthe edges weighted by the number of best answers in-\\nbetween. In particular, they model the authority scores\\nof users as a mixture of gamma distribution and use the\\nFuzzy C-Means algorithm to partition users into diﬀer-\\nent numbers of clusters. They further use Bayesian\\nInformation Criteria (BIC) to estimate the appropri-\\nate number of mixtures. Finally, the users are classi-\\nﬁed into to classes, one representing authoritative users\\nwith high in-degrees and the other non-authoritative\\nusers with low in-degrees. In this way, the method can\\nautomatically surface the number of experts in a com-\\nmunity rather than producing a ranked list of users.\\n\\n5 Comparison and Discussion\\n\\nTo gain a better understanding of state of the art,\\nwe ﬁrst summarize the existing expert recommendation\\nmethods concerning the used dataset, the required in-\\nput & output, and the evaluation metric. We further\\ncompare and discuss the methods from three perspec-\\ntives: the covered aspects of concern, reliance on suﬃ-\\ncient data, and complexity, to identify their strengths\\nand pitfalls. The three perspectives reﬂect the methods’\\ncapability in the recommendation power, applicability\\n(robustness to cold start or sparse data), and easiness\\nof usage (implementation diﬃculty), respectively.\\n\\n5.1 Datasets\\n\\nIn this section, we list the most used datasets by ex-\\nisting expert recommendation research. These datasets\\ninclude both the real-world and synthetic ones, as well\\nas those that do not belong to but are readily applicable\\nto evaluating the methods for the expert recommenda-\\ntion in CQA. Among the real-world datasets, only the\\nﬁrst two represent the dominant datasets used by most\\nexisting research while all the others are less used.\\n\\n5.1.1 Yahoo! Answers\\n\\nYahoo! Answers [3;6;27;35;45;66;83;87;90;92] is perhaps\\nthe most popular and most studied datasets in Q&A\\nrelated research. The characteristics of Yahoo! An-\\nswers, such as the diversity of questions and answers,\\nthe breadth of answering, and the quality of those an-\\nswers, are ﬁrst investigated by Adamic et al. [11] in 2008.\\nIn particular, they use user entropy to indicate a user’s\\nconcentration or focus on the diﬀerent categories of top-\\nics. They further cluster questions and answers based\\non the content to understand users’ activity on diﬀerent\\ntopics in CQA. The results showed that the majority of\\nusers participated in a small number of topics. These\\nfeatures set the practical foundation for predicting an-\\nswer quality by the amount of work and activities of\\nusers. Since each question has at most one best answer,\\nthe amount of ground truth might be sparse when only\\na part of the entire dataset is used in experiments. For\\nthis reason, some researchers set up their own criteria\\nto determine whether an answer is a “good” answers or\\nnot, to expand the training and test set for their meth-\\nods. For example, Li et al. [6] label an answer a “good”\\nanswer either when it is selected as the best answer or\\nwhen it obtains more than 50% of up-votes for all the\\nanswers of the question. Meanwhile, one answer is la-\\nbeled as a “bad” answer if it receives more than 50% of\\nrate-downs for all answers of the question.\\n\\n5.1.2 Stack Overﬂow\\n\\nStack Overﬂow [31;37;39;48;64;69;71;75;93;94]\\n\\ninvolves\\nover ﬁve million users and content about 11,053,469\\nquestions, among which only 73% have received answers\\nand closed and 55%, i.e., over six million questions,\\nhave accepted best answers (as of 10 March 2016). Like\\nthe Yahoo! Answers dataset, the records in the Stack\\nOverﬂow dataset is massive, and most existing research\\nsample a subset of the entire dataset for study. For ex-\\nample, Pal et al. [71] sample a small dataset of 100 users\\nand employ two expert coders to label the 100 users\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n13\\n\\nSogou Wenwen [90]:\\n\\nformerly known as Tencent\\nWenwen or Soso Wenwen, is similar to Quora and also\\nrun with credit points and reputation points. Users can\\nobtain points by asking or answering questions and use\\nthem as bounty.\\n\\nIask 13 [30]: a leading web 2.0 site in China. The\\nworking mechanism is similar to Baidu Knows, while\\nin Iask, a requester can increase bounty to extend 15\\ndays before question closed due to a previously accepted\\nanswer.\\n\\nOther datasets on Stack Exchange: such as com-\\nputer science 14 , ﬁtness 15 [53], and cooking 16 . There are\\ntotal 133 communities for knowledge sharing and ques-\\ntion answering, covering enormous topics on Stack Ex-\\nchange.\\n\\nEstonian Nature forum [53]: a Q&A website popular\\n\\nin Estonia.\\n\\nMedHelp 17 [79]: a website which partners with doc-\\ntors from hospitals and research facilities to provide on-\\nline discussion and to satisfy users’ medical information\\nneeds.\\n\\n5.1.4 Synthetic Dataset\\n\\nGenerally, no single method outperforms all the oth-\\ners on all the datasets for two main reasons: ﬁrst, online\\ncommunities usually have diﬀerent structural charac-\\nteristics and lead to diﬀerences in the performance of\\nmethods [41]; second, the same users may behave diﬀer-\\nently in diﬀerent communities due to various reasons\\nsuch as the subjectivity and rewarding mechanism of a\\nQ&A system. Given the lack of benchmarks to evaluate\\nthe diﬀerent methods, it has become a common prac-\\ntice to conduct controlled experiments with simulated\\ndatasets to test how a method performs under diﬀer-\\nent scenarios. We will not give more introduction to\\nthe synthetic datasets due to the signiﬁcant variances\\nin the assumptions and conditions to generating these\\ndatasets.\\n\\n5.1.5 Non-CQA Datasets\\n\\nThere are plenty of datasets do not belong to the\\nQ&A domain but are readily applicable to or have been\\n\\nas either experts or non-experts. It turns out that the\\ninter-rater agreement between the expert coders is 0.72\\n(Fleiss kappa with 95%CI, p ∼ 0), indicating the high\\nagreement between the raters is not accidental. Out\\nof the 100 users, 22 are labeled as experts and rest as\\nnon-experts.\\n\\n5.1.3 Other CQA Datasets\\n\\nTurboTax Live Community (TurboTax) 10 [64;65;71]:\\nthis is a Q&A service related to preparation of tax re-\\nturns. TurboTax has employees that manually evaluate\\nan expert candidate on factors, such as correctness and\\ncompleteness of answers, politeness in responses, lan-\\nguage and choice of words used. They also have some\\nlabeled experts.\\n\\nQuara [95;96]: a general and probably the world’\\n\\nlargest Q& A website that covers various topics.\\n\\nJava Developer Forum [41]: an online community\\nwhere people come to ask questions about Java. It has\\n87 sub-forums that focus on various topics concerning\\nJava programming. There is a broad diversity of users,\\nranging from students learning Java to the top Java ex-\\nperts. A typical sub-forum, e.g., “Java Forum”, a place\\nfor people to ask general Java programming questions,\\nhas a total of 333,314 messages in 49,888 threads as of\\nas early as 2007.\\n\\nthe\\n\\nlargest\\n\\nNaver KnowledgeCiN :\\n\\nquestion-\\nanswering online community in South Korea. Nam\\net al. [97] analyze the characteristics of knowledge gen-\\neration and user participation behavior in this website\\nand ﬁnds that altruism, learning, and competency are\\noften the motivations for top answerers to participate.\\nBaidu Knows 11 : a Chinese language CQA service,\\nwhere a member can put questions with bounty to pro-\\nmote others answering it. Once the answer is accepted,\\nit turns into search result of relevant questions.\\n\\nTripadvisor forums 12 [14]: a travel-related websites\\nwith user-generated content focusing on accommoda-\\ntion bookings. The service is free to users, who provide\\nfeedback and reviews to hotels, accommodation facili-\\nties, and other traveling related issues.\\n\\n10 http://ttlc.intuit.com/, May 2018.\\n11 http://zhidao.baidu.com/, May 2018.\\n12 http://www.tripadvisor.com/, May 2018.\\n13 http://iask.sina.com.cn/, May 2018.\\n14 http://cs.stackexchange.com/, May 2018.\\n15 http://ﬁtness.stackexchange.com/, May 2018.\\n16 http://cooking.stackexchange.com/, May 2018.\\n17 http://www.medhelp.org/, May 2018.\\n\\n\\x0c14\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\nused for the study of expert recommendation methods\\nfor the CQA. A slight diﬀerence of the methods devel-\\noped based on studying these datasets is that they most\\naim to rank and ﬁnd the most best-skilled or authorita-\\ntive users given an existing domain or topic instead of\\na new question. These datasets include co-authorship\\nnetwork [52;98;99] such as DBLP [100–102], social net-\\nworks [16;103;104], microblogs [105–107]\\nsuch as Twit-\\nter [51], Email network [108–110],\\nInternet forums [41],\\nlog data [111], e-Learning platform [112], Usenet news-\\ngroups [7;8], Google Groups [9], general documents [113],\\nand enterprise documents [20;26;114] such as Enterprise\\ntrack of TREC [115–117].\\n\\n5.2\\n\\nInput and Output\\n\\nTo ease illustration, we ﬁrst summarize the typical\\ninputs and outputs of existing expert recommendation\\nmethods in Table 2. Here, we list ﬁve categories of com-\\nmonly used inputs for expert recommendation methods.\\nThese inputs are either textual, numerical, or relational\\ninformation, while the outputs, i.e., the recommended\\nexperts, are either ranked or unranked, depending on\\nthe methods adopted.\\n\\nBased on the input/output list, we further present a\\ncomparison of the representative methods with respect\\nto their inputs and outputs in Table 3. Some methods\\nmay use derived features from the original inputs as\\nadditional inputs. For example, a classiﬁcation method\\nmay use the length of questions (implied by question\\ncontent), total question number of users (implied by\\nusers’ question history), and total answer number of\\nusers (implied by users’ answer history) as additional\\nfeatures to train their models.\\n\\n5.3 Evaluation Metrics\\n\\nWe summarize three categories of metrics used to\\nevaluate expert recommendation methods for CQA,\\nnamely the basic, rank-based, and human-judgment-\\nbased metrics. The following subsections introduce the\\nmetrics of each category, respectively, where each met-\\nric is computed as (the mean of) the average of the\\nmetric values over a set of query questions or top-\\nics [14;27;53;79;83;90].\\n\\n5.3.1 Basic Metrics\\n\\nrecommended by a method.\\n\\nRecall [53;64–66;118]: the fraction of users who are rec-\\nommended by a method and meanwhile turn out to be\\nthe real experts, among all the real experts to the given\\nquestions.\\n\\nF1-score [64–66;68;69;118]: the harmonious average of\\n\\nthe Precision and Recall.\\n\\nAccuracy [66;69;70;118]: the fraction of users who are\\ncorrectly identiﬁed as either an expert or an non-expert\\nby a method. The metric integrates the precision of the\\nmethod in identifying the experts and non-experts.\\n\\n5.3.2 Rank-based Metrics\\n\\nPrecision at top n (P@n) [14;27;79;83;87;90;92;93;119]:\\nthe percentage of the top-N candidate answers retrieved\\nthat are correct. It is also known as Precision at top\\nn (P@n) [87;90;93;119] or Success at top N (S@N) [37]. A\\nspecial case is Precision@1 [95;96] when n = 1.\\n\\nRecall at top N (R@N) [90;92;93;96], a natural expan-\\nsion of the basic recall to rank-based scenario, similar\\nto P@n.\\n\\nAccuracy by Rank [96]: the ranking percentage of the\\nbest answerer among all answers. A similar metric us-\\ning the best answerer’s rank is proposed in [15] and [35].\\nMean Reciprocal Rank (MRR) [6;14;27;53;72;83;84;90;94]:\\nthe mean of the reciprocal ranks of the ﬁrst correct ex-\\nperts over a set of questions, measuring gives us an idea\\nof how far down we must look in a ranked list in order\\nto ﬁnd a correct answer.\\n\\nMatching Set Count (MSC) @n [93;94]: the average\\nnumber of the questions that were replied by any user\\nranked within top n recommended users.\\n\\nNormalized\\n\\nDiscounted\\n\\nCumulative\\n\\nGain\\n(nDCG) [53;95]: a number between 0 and 1, measuring\\nthe performance of a recommendation system based\\non the graded relevance of the recommended items. A\\nvariant is nDCG@k, the division of the raw DCG by\\nthe ideal DCG, where k is the maximum number of\\nitems to be recommended.\\n\\nPearson Correlation Coeﬃcient [45;120;121]: the cor-\\nrelation degree between the estimated ranking with the\\nranks of users according to the scores derived from the\\nuser feedback.\\n\\nArea Under ROC Curve (AUC) [70]: the probability\\n\\nthat an expert is scored higher than a non-expert.\\n\\nThere are four set-based metrics to evaluate an ex-\\n\\n5.3.3 Human Judgment-based Metrics\\n\\npert recommendation method:\\n\\nPrecision [64–66;118]: the fraction of users who are\\ntrue experts to the given questions, among all the users\\n\\nCorrectness percentage: human judgment is nec-\\nessary in the case where the ground truth is unavail-\\nable or hard to be determined automatically. In such\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n15\\n\\nTable 2. Typical Inputs and Outputs of Expert Recommendation Methods\\n\\nType\\n\\nCategory\\n\\nQuestion proﬁle\\n\\nUser proﬁle\\n\\nInput\\n\\nHistorical\\n\\nquestions & answers\\n\\nSocial proﬁle\\n\\nNetwork proﬁle\\n\\nRecommended\\n\\nexperts\\n\\nOutput\\n\\nId\\n\\nI0\\n\\nI1\\n\\nI2\\n\\nI3\\n\\nI4\\n\\nI5\\n\\nI6\\n\\nI7\\n\\nI8\\n\\nI9\\n\\nIA\\n\\nIB\\n\\nIC\\n\\nO1\\n\\nO2\\n\\nInput/output name\\n\\nInput/output type\\n\\ncontent (and category) of the given question\\n\\ntextual\\n\\nusers’ question history\\n\\nusers’ answer history\\n\\nuser-question mapping\\n\\nuser-answer mapping\\n\\nusers’ historical viewing and answering activity\\n\\nmultiple user-question mapping\\n\\ntimestamps of users’ answering activity\\n\\nnumerical\\n\\nquestion content\\n\\nquestion category info\\n\\nquestion tags\\n\\nanswer content\\n\\nbest answer info\\n\\nvoting info\\n\\nuser reputation\\n\\ntextual\\n\\ntextual\\n\\ntextual\\n\\ntextual\\nanswer–{0,1} mapping\\nnumerical\\n\\nnumerical\\n\\nquestion-answer relations among users\\n\\ndirected user-user mapping\\n\\nan unranked group of experts\\n\\na ranked list of experts\\n\\nset\\n\\nlist\\n\\nTable 3. A Comparison of Inputs and Outputs of Representative Expert Recommendation Methods\\n\\n√\\n\\n√\\n√\\n√ √\\n√\\n√\\n√\\n\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√ √ √\\n√\\n√\\n\\nI0 I1 I2 I3 I4 I5 I6 I7 I8 I9 IA IB IC O1 O2\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n\\n√\\n√\\n√ √\\n√\\n√\\n\\n√\\n\\n√\\n\\n√\\n\\n√ √\\n\\n√\\n\\n√\\n√ √ √\\n√\\n√\\n\\n√\\n\\n√\\n√\\n\\n√\\n\\n√\\n√\\n√\\n\\nCategory\\n\\nSimple\\nmethods\\n\\nLanguage\\n\\nmodels\\n\\nTopic\\nmodels\\n\\nNetwork-based\\n\\nmethods\\n\\nClassiﬁcation\\n\\nmethods\\n\\nExpertise probability\\n\\nmodel\\n\\nCollaborative\\n\\nFiltering\\n\\nHybrid\\nmethods\\n\\nRepresentative method\\n\\nVotes\\n\\nBest answer proportion\\n\\nConsine similarity based on TF-IDF [19]\\n\\nQLL [23–25]\\n\\nCategory-sensitive QLL [27;27]\\n\\nExpertise-aware QLL [6;28]\\n\\nPLSA [15;34], LDA [36], STM [37], UQA [3]\\n\\nDRM [35]\\n\\nTagLDA [39]\\n\\nIndegree [41], PageRank [47;48], HITS [46;53]\\n\\nz-score [41], Expertise-aware methods [14;41;45;55;56]\\n\\nReputation-aware methods [60;61]\\nCategory-sensitive methods [57;58]\\n\\nGraph embedding method [63]\\n\\nSVM [65;66], C4.5 [65], RF [48], GBDT [70]\\n\\nLTR [72]\\n\\nBernoulli MAP model [77]\\n\\nMF [79]\\n\\nTag-based PMF [81]\\n\\nQLL+LDA [30], Topical PageRank [83],\\n\\nTEL [87],LDA+TF [90]\\n\\nTopical PageRank+Expertise [89]\\n\\nQLL+LDA+userActivity+Indegree [30]\\n\\nIndegree+Clustering [55]\\n\\n√ √\\n√ √\\n√\\n√ √\\n√ √\\n√\\n√\\n√\\n√\\n\\n√\\n√\\n√\\n√\\n√\\n√\\n\\n√ √ √ √ √\\n√ √ √ √\\n√\\n\\n√\\n\\n√\\n√\\n√ √\\n√\\n\\n√\\n\\n√\\n\\n√\\n√\\n√\\n\\n√\\n√ √\\n\\n√\\n√\\n√\\n√\\n√\\n√\\n√\\n\\ncases, humans usually give either Yes/No answers [3]\\nor ratings [41] to the recommended users. Then, the\\n\\nsystem calculates the percentage of correctly recom-\\n\\nmended users by investigating the agreement between\\nthe judgments made by diﬀerent people [55;83;118].\\n\\n5.4 Covered Aspects of Concern\\n\\nTo study the covered aspects of concern of diﬀer-\\nent methods, we summarize the main aspects of con-\\ncern and their indicators in an expert recommendation\\nproblem in Table 4. The inputs taken by each method\\n\\n\\x0c16\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\ndirectly reﬂect the method’s covered aspects of con-\\ncern. For example, to take user expertise into account,\\na method needs to consider at least one of the three as-\\npects: user reputation, voting information to answers,\\nand best answer ﬂags of answers. An indicator either\\nbelongs to or originates from the inputs. It falls into\\nat least one of the two aspects: answer probability and\\nexpertise level of users.\\n\\nThe inputs and outputs only give some intuitive\\nclues of how powerful each method might be. In fact, it\\nis not only the inputs but also the ways of using these\\ninputs and the underlying techniques that determine\\na method’s capability in adequately addressing the ex-\\npert recommendation problem.\\nIn the following, we\\nelaborate each aspect of concern and make a compar-\\native discussion of the investigated methods according\\nto their covered aspects of concern.\\n\\n5.4.1 Answer Probability\\n\\nA large body of the research on the expert recom-\\nmendation in CQA focuses merely on ranking the rel-\\nevance of the given question with users’ previously an-\\nswered questions. The underlying assumption is that\\nusers are more likely to answer those questions that are\\nsimilar to their previously answered ones. This type\\ncovers all the methods that consider users’ answer prob-\\nability yet not users’ expertise level in Table 4 and range\\nfrom the simple Cosine similarity method to QLL, LDA,\\nMF, and further to hybrid methods that combine the\\nabove techniques like TEL.\\n\\nSimilar to the general recommendation approach,\\nit is reasonable to assume a user prefers to answer the\\nquestions that are similar to her already-answered ques-\\ntions. On the other hand, there is no evidence to show\\nthat the stronger relevance of a user to a given ques-\\ntion also indicates a higher expertise level of the user\\nin answering that question. Therefore, such methods\\nmay not be able to distinguish users’ diﬀerent levels of\\nexpertise in either a question or a topic, and the rec-\\nommended experts may not provide quality answers to\\nthe given question.\\n\\nOther issues with this type of methods are related\\nto the consideration of categories or topics. While con-\\nsidering the category or topic information enables a\\nmethod to provide personalized recommendations cus-\\ntomized to the given question, it raises additional issues\\nto the method. First, the category-sensitive methods\\nhighly rely on the availability and proper deﬁnition of\\ncategories. For example, suppose a user has answered\\na lot of questions about ‘c++’ covered by the category\\n\\nof ‘Programming,’ and is deemed a potential answerer\\nfor questions of this category. Given a question related\\nto another programming language like ‘Python,’ which\\nis also covered by the category of ‘Programming,’ rec-\\nommending this user as an expert may not be appro-\\npriate as the user may not be familiar with ‘Python’ as\\nwell. The topic-sensitive approach is more reasonable as\\ntopics are usually not predeﬁned but dynamically con-\\nstructed by algorithms, and therefore they can adapt\\nto the ever increasing questions and answers in a Q&A\\ncommunity.\\n\\nSecond, an inevitable issue with considering cate-\\ngories or topics is that a user may have an expertise\\nin multiple categories or topics. For category-sensitive\\nmethods, although the correlation among categories\\ncan be incorporated explicitly, it could be diﬃcult to\\ndesignate a question to a single category when the ques-\\ntion is related to multiple categories. For the topic-\\nsensitive methods, they mostly discover topics based on\\nprobabilistic models such as LDA. Since the probabilis-\\ntic models distribute the total probability of 1 among all\\nthe topics for each user, having a higher probability on\\none topic will discount the probability on other topics.\\nHowever, the fact is, a user could be more relevant to\\nmultiple topics than another user simultaneously. This\\nsituation has not been suﬃciently taken into account\\nby the existing research.\\n\\n5.4.2 User Expertise\\n\\nThere are a few methods that take into account\\nuser expertise while neglecting to consider the answer\\nprobability of users in the expert recommendation in\\nCQA. These methods typically include simple tech-\\nniques (e.g., votes, best answer proportion) and the ex-\\npertise probabilistic model in Table 4. A limitation of\\nthese methods is that they only consider the probabil-\\nity of a user giving the best answer under the condition\\nthat the user has decided to answer the given question.\\nThe fact is, a user with the appropriate expertise may\\nnot answer the question in the ﬁrst place due to var-\\nious reasons such as lack of interest or unavailability.\\nTherefore, as far as answer probability is concerned,\\nthe recommended experts may not have a good chance\\nof giving a quality answer.\\n\\nAnother issue with the methods of this type is that\\nthey commonly compute a global expertise score for\\neach user while neglecting the fact that user expertise\\nmay also be topic-sensitive, similar to answer proba-\\nbility. Consequently, the recommendation results inde-\\npendent of to the speciﬁc problem scenario: given a new\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n17\\n\\nTable 4. Aspects of Concern and Their Indicators Covered by Representative Expert Recommendation Methods\\n\\nRepresentative method\\n\\nAnswer probability\\n\\nExpertise level\\n\\nVotes\\n\\nBest answer proportion\\n\\nConsine similarity of TF-IDF [19]\\n\\nQLL [23–25]\\n\\nCategory-sensitive QLL [27;27]\\n\\nExpertise-aware QLL [6;28]\\n\\nPLSA [15;34], LDA [36], STM [37], UQA [3]\\n\\nDRM [35]\\n\\nTagLDA [39]\\nIndegree [41]\\n\\nPageRank [47;48], HITS [46;53]\\n\\nz-score [41]\\n\\ntextual relevance\\n\\ntextual relevance\\n\\nquestion category\\ntextual relevance\\n\\ntextual relevance\\n\\ntopical relevance\\n\\ntopical relevance\\n\\ntopical relevance of tags\\n\\na# of users\\n\\na# & q# of users\\n\\na# & q# of users\\n\\nExpertise-aware methods [14;41;45;55;56]\\n\\na# & q# of users\\n\\nCategory\\n\\nSimple\\nmethods\\n\\nLanguage\\n\\nmodels\\n\\nTopic\\nmodels\\n\\nNetwork-based\\n\\nmethods\\n\\nClassiﬁcation\\n\\nmethods\\n\\nExpertise prob.\\n\\nmodel\\n\\nCollaborative\\n\\nFiltering\\n\\nHybrid\\nmethods\\n\\nvote counts of answers\\n\\nbest answer ratio\\n\\nbest answer ratio\\n\\na# & q# of users\\n\\na# & q# of users,\\nbest answer number\\n\\na# & q# of users,\\nbest answer number\\n\\na# & q# of users,\\n\\nuser reputation\\n\\na# & q# of users\\n\\na# & q# of users,\\nbest answer number\\n\\nbest answer number\\n\\nbest answer ratio\\n\\nbest answer number\\n\\na# & q# of users\\n\\na# & q# of users,\\nbest answer number\\n\\nbest answer number\\n\\nReputation-aware methods [60;61]\\n\\nCategory-sensitive methods [57;58]\\n\\nGraph embedding method [63]\\n\\nSVM [65;66], C4.5 [65], RF [48],\\n\\nGBDT [70], LTR [72]\\n\\nBernoulli MAP model [77]\\n\\nMF [79]\\n\\nTag-based PMF [81]\\n\\nQLL+LDA [30], TEL [87]\\n\\nLDA+TF [90]\\n\\nIndegree+Clustering [55]\\n\\nTopical PageRank [83]\\n\\nTopical PageRank+Expertise [89]\\n\\na# & q# of users\\n\\na# & q# of users,\\ncategory relevance\\n\\na# & q# of users,\\ntextual relevance\\n\\ntextual relevance,\\nquestion features,\\n\\nuser features (e.g., a#),\\n\\nmetrics (e.g., z-score)\\n\\ntextual & topical relevance\\n\\ntextual & topical relevance\\n\\na# & q# of users\\n\\ntopical relevance,\\na# & q# of users\\n\\ntopical relevance,\\na# & q# of users\\n\\ntextual relevance\\n\\ntextual relevance of tags\\n\\nbest answer ratio\\n\\nQLL+LDA+userActivity+Indegree [30]\\n\\ntextual/topical relevance,\\n\\na#, q#, active time of users\\n\\nNote: q# and a# denote the number of questions asked and answered by a user, respectively.\\n\\nquestion, the recommended experts may perform gener-\\nally well but unfortunately perform poorly on the given\\nquestion. The global expertise model is most suitable\\nfor scenarios where the same topic covers all questions.\\n\\n5.4.3 Both Aspects\\n\\nGiven the importance of both aspects of concern,\\nmany existing methods, especially the latest ones, com-\\nbine the two above aspects for the better expert recom-\\nmendation. These methods typically include expertise-\\naware QLL models, all variants of PageRank/HITS,\\nclassiﬁcation methods, collaborative ﬁltering methods,\\n\\nand hybrid methods that combine two or more of the\\nabove methods. The straightforward way of integrat-\\ning the two aspects is to compute a score for each as-\\npect separately and then combine the two scores into a\\nweighted sum, which would be used as the criterion for\\nranking users and deriving the recommendation results.\\nThe other methods, including network-based methods,\\nclassiﬁcation methods, and collaborative ﬁltering meth-\\nods, combine the two aspects of consideration more nat-\\nurally.\\n\\nFor example, the network-based methods natu-\\nrally incorporate the two aspects to compute a sin-\\n\\n\\x0c18\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\ngle criterion, user authoritativeness,\\nfor the expert\\nrecommendation—the users who have provided many\\nquestions yet asked few questions are considered au-\\nthoritative; such users are generally believed to have\\nboth higher probabilities to answer and better exper-\\ntise in a user-user network. An alternative is to use the\\nrelated user number to replace question number in the\\nabove computation. This replacement slight changes\\nthe computation method but does not aﬀect the author-\\nitativeness deﬁnition. Instead of using a single metric\\nsuch as authoritativeness to recommend experts, the\\nclassiﬁcation methods directly take various factors as\\nfeatures, without explicitly distinguishing the two as-\\npects, to train a classiﬁcation model. A limitation with\\nclassiﬁcation methods is that they generally deliver a\\nset of users as experts without further diﬀerentiating\\nthem. Therefore, they lack the ﬂexibility to decide how\\nmany users to recommend as experts on the ﬂy.\\n\\nTo explicitly utilize the best answer information in\\na network-based method, a simple approach is to re-\\nplace the ‘requester-answerer’ relationship in a user-\\nuser network into the ‘requester-best answerer’ relation-\\nship among users. In this case, a link is drawn from one\\nuser to another user only when the second user has pro-\\nvided the best answer to the ﬁrst users’ questions. The\\nindegrees and other metrics (e.g., authoritativeness) of\\nusers derived from the modiﬁed model can directly be\\nused to recommend users who are both active and have\\nthe right expertise. In this way, the recommended ex-\\nperts are those who have provided best answers to the\\nlargest numbers of other users and have been answered\\nby the fewest other users on their raised questions.\\n\\nCurrently, almost all the hybrid methods that cover\\nboth aspects involves network-based methods as a com-\\nponent. These methods therefore still share some draw-\\nbacks of the basic network-based methods. First, the\\nexperts recommended by such methods are speciﬁc to\\na user-user network rather than a particular topic or a\\nquestion. Intuitively, both the transitivity of users’ au-\\nthoritativeness and the eﬀectiveness of network-based\\nmethods depend on the condition that the interactions\\nbetween users concern only one topic. Second, although\\nthe link structure can, to some extent, implies the corre-\\nlation among users and questions, the user-user network\\nis not directly related to a user’s topical preference. To\\nrecommended experts for a given problem, they still\\nneed some approach to connect the question to users or\\ntheir historical questions to make a personalized recom-\\nmendation. The more recent expertise-aware network-\\nbased methods often hybridize with relevance models\\n\\n(e.g., language models and topic models) to overcome\\nthe above deﬁciencies.\\n\\nAnother possible issue with the hybridization of\\nnetwork-based methods with other methods is that au-\\nthoritativeness is a vague concept, which already, to\\nsome extent, implies the interest and expertise of users.\\nTherefore, the combination of techniques may cause the\\nhybrid methods to consider multiple times of the same\\naspects. The rationale and eﬀect of such hybridization\\nare yet to be examined.\\n\\n5.5 Reliance on Suﬃcient Data\\n\\nThe cold start or data sparsity problem concerns\\nboth the ground truth or numbers of users’ activity\\nrecords, and it turns out to be a common challenge for\\nall the investigated expert recommendation methods.\\nFor the amount of ground truth, the rule of thumb is\\nthat the more straightforward methods tend to be less\\naﬀected by the small ground truth size, as the more\\ncomplicated methods usually require a larger train set.\\nFor example, the classiﬁcation methods generally per-\\nform better under high-dimensional features given suﬃ-\\ncient training data. When the training data is limited,\\nthese methods need to restrain the dimensionality to\\navoid over-ﬁtting.\\nIn contrast, the voting-base tech-\\nniques require no training and thus unaﬀected by the\\nsize of training data.\\n\\nThe eﬀect of the historical record numbers of users\\non the recommendation methods is closely related to\\nthe early detection of experts, i.e., promoting the par-\\nticipation rate of new experts or rising stars, i.e., the\\nlow proﬁle users who have strong potential to con-\\ntribute to the community later after short observations\\nin CQA [69]. The lack of suﬃcient information in the\\nuser proﬁle is, in fact, the primary obstacle towards\\nidentifying such early-career experts. Previous stud-\\nies [22] show that only 15.67% of all users in Yahoo! An-\\nswers answered more than four questions. This obser-\\nvation indicates that all these approaches involve only\\na small portion of highly active users and therefore can-\\nnot recommend new questions to the rest of the com-\\nmunity. If the recommendation method can also involve\\nthe good users with few activity records, these users can\\nbecome motivated to take more intensive participation\\nin a community or even develop into highly active ex-\\nperts.\\n\\nDespite the signiﬁcance of early expert detection is-\\nsue, the markers that reﬂect the expertise of an or-\\ndinary user (e.g., number of answers and number of\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n19\\n\\nbest answers) are not that strong for a newly joined\\nuser. Therefore, not much prior work has researched on\\nﬁnding potential experts in early-stage in CQA [64;65;71].\\nMany existing methods bypass the cold start and data\\nsparsity issues due to their reliance on suﬃcient data\\nfrom CQA systems. For example, some approaches con-\\nsider only those users who previously provided more\\nthan 5 [40], 10 [3] or even 20 answers [122]. Other meth-\\nods take only users with a signiﬁcant number of best\\nanswers into consideration (e.g., more than 10 [30] or 20\\nbest answers [31]).\\n\\nAmong the existing methods, we identify two\\npromising categories of methods that can potentially\\nbetter detect experts early. One is semi-supervised\\nLearning methods (e.g., [68]), which regard users who\\nprovide above average-best-answers on a topic tag as\\ntopical experts. They apply a data-driven approach to\\npredict whether a user will become an expert in the\\nlong term. The other is expertise propagation meth-\\nods (e.g., [123]), which infer or consolidate the expertise\\nof low-proﬁle users by propagating the expertise of old\\nusers through their shared activities in a community.\\n\\n5.6 Method Complexity\\n\\nGenerally, the more aspects considered, the better a\\nmethod can potentially perform, and the more compli-\\ncated the method could be. The expertise-aware tech-\\nniques based on QLL usually combine the two aspects\\nlinearly using the simple weight sum method. The pri-\\nmary issue with these methods is the diﬃculty in allo-\\ncating the weights wisely among the two aspects. Usu-\\nally, they need to resort to human experience or re-\\npeated trials in real applications to determine the opti-\\nmal weights.\\n\\nThough applicable to the expert recommendation\\nproblem, recommendation techniques face severe chal-\\nlenges besides the fundamental issues like the cold start\\nproblem. For example, considering multiple aspects of\\nconcerns could make a recommendation technique com-\\nplex and challenging to optimize. More recently recom-\\nmendation methods such as factorization machines may\\nhelp resolve the problem but have not yet been applied\\nto the expert recommendation in CQA.\\n\\nDespite the ability to incorporate multiple aspects\\nof concern, there is a lack of universal principle regard-\\ning which features to use for the classiﬁcation methods.\\nConsequently, the performance of classiﬁcation meth-\\nods largely depends on the features used and whether\\nthe technique and features ﬁt the size of the labeled\\ndata.\\n\\n6 Future Directions\\n\\nAfter reviewing the state of the art methods, we\\nidentify several challenging yet promising issues for\\nthe future research. We summarize them as realistic\\nuser modeling, recommending experts as a collabora-\\ntive group, coping with dynamicity, utilization of ex-\\nternal data, and comprehensive expert recommenda-\\ntion solutions.\\nIn the following, we review the lim-\\nited related studies to the above challenges, highlight\\nthe signiﬁcance of and new opportunities for address-\\ning these challenges, and ﬁnally, outlook the promising\\ndirections for future research. We hope this discussion\\ncould provide novel viewpoints to the existing studies\\nand encourage more future contributions to this promis-\\ning ﬁeld of research.\\n\\n6.1 Realistic User Modeling\\n\\nExpert recommendation relies on eﬀective user\\nmodeling. Intuitively, there exist three aspects of con-\\ncerns that aﬀect whether a user gives a high-quality\\nanswer to a question in a real Q&A scenario as follows:\\nThe chance of a user noticing the question. Since\\na user may not have an opportunity to see a question,\\nthe user may not be an answerer to this question even\\nthough the user is an expert. The expert recommen-\\ndation problem in CQA, however, is based on a dif-\\nferent assumption from the real-world scenarios, i.e.,\\nhow likely a user would answer a question and mean-\\nwhile provide a high-quality answer to the question if\\nthe user is invited to answer the question. Due to the\\nabove diﬀerence, when using the real-world labeled data\\nto train the recommendation models, the recommenda-\\ntion methods should better take into account the pos-\\nsibility that a user may not have answered a question\\njust because the user does not have the chance to no-\\ntice the question. The likelihood that a user would see\\na question in real-world scenarios depends on various\\nfactors such as user availability (e.g., how often a user\\nis online and available to answer questions), user be-\\nhaviors (e.g., whether the user looks for new questions\\nto answer actively), and other users’ activities related\\nto the question (e.g., how widespread the question is\\namong users).\\n\\nUser’s willingness to answer the question. Even if\\na user has noticed a question, the user may choose not\\nto answer it. A user’s willingness to answer a question\\nalso depends on various factors such as how well the\\nquestion ﬁts the user’s interest, user’s self-conﬁdence\\n\\n\\x0c20\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\non the quality of answers, and user’s expected gains\\nfrom answering the question.\\n\\nUser’s expertise level on the question. Even if a user\\nhas noticed a question and is willing to answer it, the\\nuser may not have the adequate knowledge to give a\\nhigh-quality answer. That is the ﬁrst and foremost rea-\\nson that we need an expert recommendation approach\\nin CQA.\\n\\nBesides identifying the diﬀerent aspects, we need to\\nﬁnd a reasonable way to combine them to recommend\\nreal experts more comprehensively given a new ques-\\ntion. Unfortunately, the existing expert recommenda-\\ntion methods usually consider only the second, the last,\\nor both the above aspects. For example, most language\\nmodels and topic models focus on recommending users\\nwho are most likely to answer the given question. How-\\never, a high possibility of a user answering a question\\ndoes not necessarily mean the user would be able to pro-\\nvide a high-quality answer. Many link analysis meth-\\nods identify experts as the most authoritative users in\\na user-user network, where authoritativeness is a dif-\\nferent concept from either relevance and user expertise.\\nTherefore, the most authoritative users are not guar-\\nanteed to be willing to answer a question nor being\\nable to give a high-quality answer. Besides, some clas-\\nsiﬁcation methods merely rely on the previous answer\\nquality and some metadata features without consider-\\ning users’ topical distributions. For this reason, a rec-\\nommended expert by such methods may not want to\\nanswer a question even if the user is a good answerer in\\ngeneral. Worse still, to the best of our knowledge, the\\nﬁrst aspect has not been considered by any previous\\nresearch eﬀorts. A promising research direction is to\\nincorporate expert recommendation method with mod-\\nels that could eﬀectively predict user behaviors, just\\nlike the prediction of check-ins in a Point of Interest\\nrecommendation problem [124].\\n\\n6.2 Coping with Dynamicity\\n\\nCurrently, the vast majority of research eﬀorts con-\\nsider the expert recommendation problem in a static\\ncontext, where they use a snapshot of users’ previously\\nasked or answered questions for the expert recommen-\\ndation. However, the real-world question answering\\nwebsites are dynamic, with new users joining and leav-\\ning, users’ interest changing, users’ roles transforming,\\nusers’ mutual interactions evolving, and the content on\\nthe website never stopping updating [125]. Therefore, it\\nis especially promising to develop methods that lever-\\n\\nage the temporal information to make the expert rec-\\nommendation methods adaptive in a dynamic context\\nin a real-time fashion.\\n\\nCurrently, user availability is the most commonly\\nconsider dynamic aspect for the expert recommenda-\\ntion problem. Several studies used temporal features to\\nestimate the availability of users for a given day [6;93;123]\\nor for a speciﬁc time of the day [93;126]. For example,\\nSung et al. [123] use all replies of users to train a sigmoid\\nfunction and Chang et al. [93] build binary classiﬁers us-\\ning all responses of users within a ﬁxed time frame (pre-\\nvious day). Diﬀers from the above work, Yeniterzi et\\nal. [94] use only the particular question-related replies to\\nestimate availability.\\n\\nBesides user availability, we identify two promising\\n\\ndirections to cope with the dynamicity in CQA:\\n\\nUser interest drifts. Similar to general recommen-\\ndation systems, the expert recommendation problem\\nfor CQA also faces the user interest drift issue [127]. A\\nstraightforward solution is to include a decaying fac-\\ntor to suppress questions answered in remote history\\nand focus on users’ recent interest (reﬂected by their\\nshifting answering behavior) [128]. Although the topic\\ndrift issue has been studied in multiple areas such as\\nsocial networks and mobile crowdsourcing [129], it is al-\\nmost an unexplored topic in the CQA context. More\\nfactors such as ﬂuctuations in user behaviors and more\\nsophisticated time series prediction methods could be\\nemployed to gain better results.\\n\\nDynamic user expertise. Generally, users’ expertise\\nmay not be consistent as well, as users’ skills may im-\\nprove over time and the quality of their answers may\\ndepend on various factors such as the users’ status and\\nother users’ behaviors on a given question, not men-\\ntioning the impact from the evolution of the Q&A com-\\nmunity. Pal et al. [130] analyze the evaluation of experts\\nover time and show that estimating expertise using tem-\\nporal data outperforms using static snapshots of the\\ndata. In a very recent work [94], Yeniterzi et al. incor-\\nporate temporal information to model dynamic user ex-\\npertise and apply two models, namely exponential and\\nhyperbolic discounting models, to discount the eﬀect\\nof older records in calculating z-scores. This method\\nis still rather straightforward being equivalent to us-\\ning a decaying factor.\\nIn particular, the z-scores are\\ncalculated for each time interval and then discounted\\naccording to its temporal distance from the question’s\\nhosting interval. In the ﬁeld of answer quality predic-\\ntion, Szpektor [131] use a more advanced set of temporal\\nfeatures calculated between the time at which a ques-\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n21\\n\\ntion and its replies are posted to improve prediction\\nresults. The similar method applies o the expert rec-\\nommendation problem.\\n\\nIn summary, all the above dynamic aspects are sug-\\ngesting an expert recommendation method suitable to\\nself-evolve in an online fashion [132]. However, none of\\nthe above methods is designed to be online-friendly, and\\nit could take tremendous time to retrain the new model\\nwhen new information becomes available, which is un-\\nacceptable in practice as most Q&A systems in the\\nreal-world involves a massive amount of data overall.\\nTherefore, a promising research direction is to intro-\\nduce novel methods that are capable of incrementally\\nlearning about users and continuously adapting their\\nrecommendation behaviors over time eﬀectively and ef-\\nﬁciently. Besides the short of related work, we believe\\nthe dynamicity-related research for CQA is still at a\\npreliminary stage, as most of the methods used are rel-\\natively simple and predict diﬀerent aspects of considera-\\ntion, such as user availability, user interest, and user ex-\\npertise, separately. Moreover, they have not considered\\nthe possible correlations among these aspects. There-\\nfore, another potential point of research is to predict\\ndiﬀerent aspects of features simultaneous using a single,\\ncomprehensive model for better results. As an exam-\\nple, Tensor Factorization (TF) [133] may model the cor-\\nrelations among high-dimensional features better than\\nMatrix Factorization (MF).\\n\\n6.3 Recommending Experts as a Collaborative\\n\\nGroup\\n\\nSince a single user may not be able to well or fully\\naddress a given question, most methods would recom-\\nmend either a ranked list or an unranked group of users\\ninstead of one user. The recommended user group is\\nexpected to address the question better than a single\\nuser, and their answers are supposed to be better than\\nmost, or ideally all the other possible user groups that\\ncontain the same number of members when considered\\nas a whole. An ideal expert group should satisfy the\\nfollowing conditions. First, the question must appeal\\nto all group members so that they are likely to answer\\nthe question. Second, the group members should be\\ncompatible with one another, so that the existence of\\none user in the group would not discourage another\\nuser to answer the question. Third, it is desirable for\\nthe group members to complement one another in the\\nknowledge domains required to address the question,\\ngiven that users may have diﬀerent sets of skills and\\n\\ndiﬀered level of expertise on diﬀerent skill aspects [134].\\nAnother beneﬁt of group recommendation is the poten-\\ntial to make the recommending technique adaptive to\\nspeciﬁc scenarios and reduce the generation of redun-\\ndant information in Q&A communities. For example,\\nby capturing a global insight into an expert group, a\\nmethod can automatically adjust the number of experts\\nto recommend. In this way, the diﬃcult questions may\\nget more answers than easier ones.\\n\\nTo better answer a question, it is necessary to eval-\\nuate and select a competitive combination of poten-\\ntial answerers as a collaborative group. Unfortunately,\\nthere is rarely any studies on this topic, and the group\\nrecommendation methods for traditional recommender\\nsystem assume known user groups before making a rec-\\nommendation [135–137]. For example, Pal et al. propose\\nan expert group recommendation for the CQA [138],\\naiming to ﬁnd the experts from predeﬁned communi-\\nties to provide an answer. Given a new question, the\\nauthors compute its similarity with the three aspects of\\nfeatures of each community, namely question features,\\nuser features, and community features. Then, they use\\nthe two k-NN algorithms over the similarity metrics to\\nbuild a vector of community scores for each community.\\nFinally, they use linear regression, Borda Count, SVM\\nRanking, as well as the combinations of the above three\\nmethods to train a binary classiﬁer for distinguishing\\nthe desired from the non-desired communities for the\\ngiven question. The issue with this method, as well\\nas the traditional group recommendation methods, is\\nthat the users are evaluated separately and later put\\ntogether to form a group. Consequently, the workers’\\nanswers may not collectively better address the ques-\\ntion from the requester’s perspective as the second and\\nthird conditions above may not be well met.\\n\\nIntuitively, the users who have frequently answers\\nthe similar question are likely to be compatible with\\none another [139]. A possible solution following this in-\\nsight is to propose an expert recommendation scheme\\nthat aims at selecting the best subset (e.g. of a size of k )\\nof collaborative users by learning their co-occurrence in\\nthe same thread and topical expertise simultaneously.\\nThe selection of a group of collaborative users could also\\nborrow ideas from two closely related topics, namely\\noptimal task decomposition [140] and user group evalu-\\nation. Task decomposition is the opposite approach\\nof group formation, which aims to break the knowl-\\nedge requirement into sub-requirements and ﬁnd a user\\nfor every sub-requirement to compose the ﬁnal group.\\nUser group evaluation aims to set better heuristics to\\n\\n\\x0c22\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\npromote better recommendation results and answers to\\nthe given question. On this aspect, Chang et al. [93]\\nhypothesize that valuable question-answer threads are\\nthose where several people collaborate. A natural ap-\\nplication of this hypothesis in group expert recommen-\\ndation is that, instead of aiming to maximize the re-\\nquester’s satisfaction on the given question, we could\\nselect the group of collaborative users in such a way\\nthat maximizes the long-term value to a broader audi-\\nence of the thread.\\n\\n6.4 Leveraging External Information\\n\\nTo address the cold start problem and the sparsity\\nof data, especially, users with the low level of activ-\\nity, it is crucial to leverage external data to facilitate\\nthe better expert recommendation in CQA. The types\\nof non-CQA data may vary depending on the exter-\\nnal services and platforms. Typically, they include the\\n“about me” description, homepage, blogs, micro-blogs,\\nor social networking sites. For example, many users\\nmake their GitHub homepages public in Stack Over-\\nﬂow, which could be an external source of information\\nto estimate the users’ expertise.\\n\\nUntil now, existing expert recommendation research\\ninformation in a nar-\\nfor CQA only uses external\\nrow scope in a relatively simplistic manner. They\\nmostly focus on users’ social attributes including inter-\\nrelationship in social networks (either within or out-\\nside the Q&A system) [141], and they either obtain user\\nattributes through heuristic statistics outside of the\\nmodel or combine users’ social attributes with the orig-\\ninal expert recommendation model by linear interpola-\\ntion. The limited related work includes: Srba et al. [119]\\nuse non-CQA sources of data in topic-model-based ap-\\nproaches as a supplement for Q&A activities in exper-\\ntise estimation; Zhao et al. [96] consider both topical in-\\nterests and the “following relations” between the users\\nto build a user-to-user graph. The graph is then used in\\ncombination with past question-answering activities of\\nusers to evaluate and rank users. Instead of using social\\nattributes as heuristics to estimate user expertise, both\\nLiu et al. [142] and Luo et al. [143] directly use users’ so-\\ncial characteristics as additional features in addition to\\nuser expertise for the expert recommendation in CQA;\\nZhao et al. [95] combine heuristics from two diﬀerent so-\\ncial networks, i.e., social following and social friendship\\non Twitter and Quora for ranking answerers.\\n\\nBesides the explicit links to external information\\nsources for the users in a Q&A system, we identify\\n\\ntwo promising ﬁelds of research that could avail the\\ndetection and use of external information by an expert\\nrecommendation method. The ﬁrst is account linkage\\ntechniques, which aim to identify and link to accounts\\nof the same users on diﬀerent systems such as web-\\nsites. By automatically detecting the linked account of\\na user in CQA, the external information for this user\\ncould be eﬃciently extracted and utilized. The second\\nis cross-domain learning, represented by transfer learn-\\ning techniques, which aims to utilize the information in\\nthe related or similar domains to help learn user models\\nfor a targeted domain. Though great potentials in the\\nQ&A domain, both techniques have not yet currently\\nintroduced to the CQA.\\n\\n6.5 More Comprehensive Solutions\\n\\nDespite hybrid methods have considered multiple\\naspects of concern comprehensively, the research in this\\narea is still at a preliminary stage as many of those\\nmethods simple combine the calculation results on dif-\\nferent aspects as a weighted sum. Considering this de-\\nﬁciency, it is beneﬁcial to develop more comprehensive\\nmethods. To this end, we advocate several approaches\\nbeyond the existing techniques for the expert recom-\\nmendation in CQA: factorization machines, ensemble\\nlearning, graph embedding, and deep learning models.\\nWe will brieﬂy discuss them in the following.\\n\\nFactorization machines (FM) [144] is a matrix factor-\\nization based machine learning models similar to linear\\nregression models. It represents a generic approach that\\ncombines the generality of feature engineering with the\\nsuperiority of factorization models in estimating inter-\\nactions between the massive variables in a vast domain.\\nFM model has the advantages of embedded variable\\ninteractions, reliable estimation of a linear number of\\nparameters under high sparsity, and applicability to a\\nvariety of prediction tasks including regression, binary\\nclassiﬁcation, and ranking. All these advantages make\\nFM a better replacement of traditional recommenda-\\ntion methods such as matrix factorization and tensor\\nfactorization for the expert recommendation in CQA.\\nEnsemble learning [145] is a method of using multiple\\nlearning algorithms to obtain better performance than\\nthat obtainable by any of individual learning algorithm\\nalone.\\nIt generally includes parallel and the sequen-\\ntial ensemble learning and applies to various problems\\nsuch as classiﬁcation, regression, feature selection, and\\nanomaly detection. Therefore, it could be potentially\\nused to recommend experts in CQA. Following the se-\\nquential or parallel ensemble paradigms, the candidate\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n23\\n\\nexperts are either ﬁltered by one learning algorithm af-\\nter another or obtained by merging the recommended\\nlists of experts by diﬀerent algorithms. Gradient tree\\nboosting [146], represented by XGBoost [147], is another\\nclass of ensemble models that shines in many applica-\\ntions in recent years. It is also promising yet unexplored\\nin the context of CQA.\\n\\nGraph embedding [148]\\n\\nis an eﬀective and eﬃcient\\nway to solve the various graph analytics problems such\\nas node classiﬁcation, node recommendation, and link\\nprediction while well overcoming the high computa-\\ntion and space cost issues of traditional graph analytics\\nmethods.\\nIt converts the graph data into a low di-\\nmensional space which maximally preserves the graph’s\\nproperties and structural information. In fact, graphs\\nis an ideal form to represent the complicated interac-\\ntions among various aspects of users, questions, and\\nanswers in CQA, especially when considering multiple\\naspects of concern and numerous information sources.\\nA beneﬁt of applying the graph embedding approach is\\nthat various approximation algorithms and probabilis-\\ntic solutions are readily available to address complex\\nproblems.\\n\\nDeep learning [149] has proven successful in many ap-\\nplications, and various deep learning models such as\\nthose based on autoencoders and neural autoregressive\\nmodels have been applied to recommender systems [150].\\nDeep learning models have the advantage of utilizing\\nmultimodal heterogeneous features and thus has the po-\\ntential of solving complex problems such as the expert\\nrecommendation problem on a large scale. Convolu-\\ntional neural network (CNN) is the only a deep learn-\\ning model we are aware of that combines user feature\\nrepresentations with question feature representations to\\nrecommend experts for a given question in CQA [151].\\n\\nA closely related topic to the expert recommen-\\ndation in CQA is question answering, which aims to\\nﬁnd or generate answers to a given question auto-\\nmatically. This topic is more classic and also heavily\\nresearched in the Q&A research domain. Other re-\\nlated research topics include question retrieval, answer\\nquality/probability prediction, and expert ﬁnding in\\nbroader contexts. In fact, though rare adoption for the\\nexpert recommendation problem, deep learning models\\nhave been widely applied for question answering in the\\ndomain of CQA. Therefore, it could be a good idea to\\nborrow and adapt the various sophisticated methods in\\nthese related domains to address the expert recommen-\\ndation problem in CQA.\\n\\n7 Conclusions\\n\\nIn this survey, we focus on the expert recommen-\\ndation problem, one of the most signiﬁcant issues in\\nCommunity question answering (CQA), and review the\\nmain techniques and state-of-the-art eﬀorts on address-\\ning the problem. We have summarized and compared\\nthe existing methods in various aspects, including the\\ndatasets, input and output, evaluation metric, the cov-\\nered aspects of concern, robustness over data distribu-\\ntions, and complexity, followed by discussing the advan-\\ntages and shortcomings of these methods and pointing\\nout the open issues and promising future research di-\\nrections. We hope this survey can help readers gain a\\nquick and comprehensive understanding of the state of\\nthe art research in the expert recommendation in CQA\\nand inspire more future research in this area.\\n\\nReferences\\n\\n[1] Srba I, Bielikova M. A comprehensive survey and classi-\\nﬁcation of approaches for community question answering.\\nACM Transactions on the Web, 2016, 10(3): Article No.\\n18.\\n\\n[2] Liu Q, Agichtein E, Dror G, Maarek Y, Szpektor I. When\\nweb search fails, searchers become askers: Understanding\\nthe transition. In Proc. the 35th International ACM SIGIR\\nConference on Research and Development in Information\\nRetrieval, Aug. 2012, pp. 801–810.\\n\\n[3] Guo J, Xu S, Bao S, Yu Y. Tapping on the potential of q&a\\ncommunity by recommending answer providers. In Proc.\\nthe 17th ACM International Conference on Information\\nand Knowledge Management, Oct. 2008, pp. 921–930.\\n\\n[4] Su Q, Pavlov D, Chow J H, Baker W C.\\n\\nInternet-scale\\ncollection of human-reviewed data. In Proc. the 16th In-\\nternational Conference on World Wide Web, May 2007,\\npp. 231–240.\\n\\n[5] Agichtein E, Castillo C, Donato D, Gionis A, Mishne G.\\nFinding high-quality content in social media. In Proc. In-\\nternational Conference on Web Search and Data Mining,\\nMay 2008, pp. 183–194.\\n\\n[6] Li B, King I. Routing questions to appropriate answerers\\nin community question answering services.\\nIn Proc. the\\n19th ACM International Conference on Information and\\nKnowledge Management, Oct. 2010, pp. 1585–1588.\\n\\n[7] Fisher D, Smith M, Welser H T. You are who you talk to:\\nDetecting roles in usenet newsgroups. In Proc. the 39th An-\\nnual Hawaii International Conference on System Sciences,\\nvolume 3, Jan. 2006, pp. 59b–59b.\\n\\n[8] Vi´egas F B, Smith M. Newsgroup crowds and authorlines:\\nVisualizing the activity of individuals in conversational cy-\\nberspaces. In Proc. the 37th Annual Hawaii International\\nConference on System Sciences, Jan. 2004, pp. 10–pp.\\n\\n[9] Welser H T, Gleave E, Fisher D, Smith M. Visualizing\\nthe signatures of social roles in online discussion groups.\\nJournal of Social Structure, 2007, 8(2):1–32.\\n\\n\\x0c24\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\n[10] Anderson A, Huttenlocher D, Kleinberg J, Leskovec J. Dis-\\ncovering value from community activity on focused ques-\\ntion answering sites: A case study of stack overﬂow.\\nIn\\nProc. the 18th ACM SIGKDD International Conference\\non Knowledge Discovery and Data Mining, Aug. 2012, pp.\\n850–858.\\n\\n[11] Adamic L A, Zhang J, Bakshy E, Ackerman M S. Knowl-\\nedge sharing and yahoo answers: Everyone knows some-\\nthing. In Proc. the 17th International Conference on World\\nWide Web, May 2008, pp. 665–674.\\n\\n[12] Movshovitz-Attias D, Movshovitz-Attias Y, Steenkiste P,\\nFaloutsos C. Analysis of the reputation system and user\\ncontributions on a question answering website: Stackover-\\nﬂow.\\nIn Proc. IEEE/ACM International Conference on\\nAdvances in Social Networks Analysis and Mining, Aug.\\n2013, pp. 886–893.\\n\\n[13] Yimam-Seid D, Kobsa A. Expert-ﬁnding systems for or-\\nganizations: Problem and domain analysis and the demoir\\napproach. Journal of Organizational Computing and Elec-\\ntronic Commerce, 2003, 13(1):1–24.\\n\\n[14] Zhou Y, Cong G, Cui B, Jensen C S, Yao J. Routing ques-\\ntions to the right users in online communities. In Proc. the\\nIEEE 25th International Conference on Data Engineering,\\nApr. 2009, pp. 700–711.\\n\\n[15] Qu M, Qiu G, He X, Zhang C, Wu H, Bu J, Chen C. Prob-\\nabilistic question recommendation for question answering\\ncommunities. In Proc. the 18th International Conference\\non World Wide Web, May 2009, pp. 1229–1230.\\n\\n[16] Horowitz D, Kamvar S D. The anatomy of a large-scale\\nsocial search engine. In Proc. the 19th International Con-\\nference on World wide web, Apr. 2010, pp. 431–440.\\n\\n[17] Bayati S. Security expert recommender in software engi-\\nneering.\\nIn Proc. the 38th International Conference on\\nSoftware Engineering Companion, May 2016, pp. 719–721.\\n[18] Rjab A B, Kharoune M, Miklos Z, Martin A. Character-\\nization of experts in crowdsourcing platforms.\\nIn Proc.\\nInternational Conference on Belief Functions, Sept. 2016,\\npp. 97–104.\\n\\n[19] Baeza-Yates R, Ribeiro-Neto B et al. Modern Information\\nRetrieval, volume 463. ACM press, New York, 1st edition,\\n1999.\\n\\n[20] Balog K, Azzopardi L, De Rijke M. Formal models for\\nexpert ﬁnding in enterprise corpora. In Proc. the 29th An-\\nnual International ACM SIGIR Conference on Research\\nand Development in Information Retrieval, Jul. 2006, pp.\\n43–50.\\n\\n[21] Miller D R, Leek T, Schwartz R M. A hidden markov\\nmodel information retrieval system. In Proc. the 22nd An-\\nnual International ACM SIGIR Conference on Research\\nand Development in Information Retrieval, Aug. 1999, pp.\\n214–221.\\n\\n[22] Zhou G, Liu K, Zhao J. Joint relevance and answer quality\\nIn Proc.\\nlearning for question routing in community qa.\\nthe 21st ACM International Conference on Information\\nand Knowledge Management, Oct. 2012, pp. 1492–1496.\\n\\n[23] Liu X, Croft W B, Koll M. Finding experts in community-\\nbased question-answering services. In Proc. the 14th ACM\\nInternational Conference on Information and Knowledge\\nManagement, Oct. 2005, pp. 315–316.\\n\\n[24] Lavrenko V, Croft W B. Relevance based language mod-\\nels. In Proc. the 24th Annual International ACM SIGIR\\nConference on Research and Development in Information\\nRetrieval, Aug. 2001, pp. 120–127.\\n\\n[25] Liu X, Croft W B. Cluster-based retrieval using language\\nmodels. In Proc. the 27th Annual International ACM SI-\\nGIR Conference on Research and Development in Infor-\\nmation Retrieval, Aug. 2004, pp. 186–193.\\n\\n[26] Petkova D, Croft W B. Hierarchical language models for\\nexpert ﬁnding in enterprise corpora. International Journal\\non Artiﬁcial Intelligence Tools, 2008, 17(01):5–18.\\n\\n[27] Li B, King I, Lyu M R. Question routing in community\\nquestion answering: Putting category in its place. In Proc.\\nthe 20th ACM International Conference on Information\\nand Knowledge Management, Oct. 2011, pp. 2041–2044.\\n\\n[28] Zheng X, Hu Z, Xu A, Chen D, Liu K, Li B. Algorithm\\nfor recommending answer providers in community-based\\nquestion answering. Journal of Information Science, 2012,\\n38(1):3–14.\\n\\n[29] Zhai C, Laﬀerty J. A study of smoothing methods for lan-\\nguage models applied to information retrieval. ACM Trans-\\nactions on Information Systems, 2004, 22(2):179–214.\\n\\n[30] Liu M, Liu Y, Yang Q. Predicting best answerers for new\\nquestions in community question answering. In Proc. In-\\nternational Conference on Web-Age Information Manage-\\nment, Jun. 2010, pp. 127–138.\\n\\n[31] Riahi F, Zolaktaf Z, Shaﬁei M, Milios E. Finding expert\\nusers in community question answering. In Proc. the 21st\\nInternational Conference on World Wide Web, May 2012,\\npp. 791–798.\\n\\n[32] Hofmann T. Probabilistic latent semantic indexing. In roc.\\nthe 22nd Annual International ACM SIGIR Conference on\\nResearch and Development in Information Retrieval, Apr.\\n1999, pp. 50–57.\\n\\n[33] Deerwester S, Dumais S T, Furnas G W, Landauer T K,\\nHarshman R. Indexing by latent semantic analysis. Jour-\\nnal of the American Society for Information Science, 1990,\\n41(6):391–407.\\n\\n[34] Wu H, Wang Y, Cheng X. Incremental probabilistic latent\\nsemantic analysis for automatic question recommendation.\\nIn Proc. ACM Conference on Recommender Systems, Oct.\\n2008, pp. 99–106.\\n\\n[35] Xu F, Ji Z, Wang B. Dual role model for question recom-\\nmendation in community question answering. In Proc. the\\n35th International ACM SIGIR Conference on Research\\nand Development in Information Retrieval, Apr. 2012, pp.\\n771–780.\\n\\n[36] Blei D M, Ng A Y, Jordan M I. Latent dirichlet allocation.\\nJournal of Machine Learning Research, 2003, 3(Jan):993–\\n1022.\\n\\n[37] Du L, Buntine W, Jin H. A segmented topic model based\\non the two-parameter poisson-dirichlet process. Machine\\nLearning, 2010, 81(1):5–19.\\n\\n[38] Pitman J, Yor M. The two-parameter poisson-dirichlet dis-\\ntribution derived from a stable subordinator. The Annals\\nof Probability, 1997, pp. 855–900.\\n\\n[39] Sahu T P, Nagwani N K, Verma S. Taglda based user\\npersona model to identify topical experts for newly posted\\nquestions in community question answering sites.\\nInter-\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n25\\n\\nnational Journal of Applied Engineering Research, 2016,\\n11(10):7072–7078.\\n\\nInternational Conference on World Wide Web, May 2015,\\npp. 1369–1374.\\n\\n[40] Tian Y, Kochhar P S, Lim E P, Zhu F, Lo D. Predicting\\nbest answerers for new questions: An approach leveraging\\ntopic modeling and collaborative voting. In Workshops at\\nthe International Conference on Social Informatics, Sept.\\n2013, pp. 55–68.\\n\\n[41] Zhang J, Ackerman M S, Adamic L. Expertise networks\\nin online communities: Structure and algorithms. In Proc.\\nthe 16th International Conference on World Wide Web,\\nMay 2007, pp. 221–230.\\n\\n[42] Jeon J, Croft W B, Lee J H, Park S. A framework to predict\\nthe quality of answers with non-textual features. In Proc.\\nthe 29th annual International ACM SIGIR Conference on\\nResearch anDevelopment in Information Retrieval, Apr.\\n2006, pp. 228–235.\\n\\n[43] Borodin A, Roberts G O, Rosenthal J S, Tsaparas P.\\nLink analysis ranking: Algorithms, theory, and experi-\\nments. ACM Transactions on Internet Technology, 2005,\\n5(1):231–297.\\n\\n[44] Kleinberg J M. Authoritative sources in a hyperlinked en-\\n\\nvironment. Journal of the ACM, 1999, 46(5):604–632.\\n\\n[45] Jurczyk P, Agichtein E. Discovering authorities in ques-\\ntion answer communities by using link analysis. In Proc.\\nthe 16th ACM Conference on Information and Knowledge\\nManagement, Oct. 2007, pp. 919–922.\\n\\n[46] Jurczyk P, Agichtein E. Hits on question answer portals:\\nExploration of link analysis for author ranking. In Proc.\\nthe 30th Annual International ACM SIGIR Conference on\\nResearch and Development in Information Retrieval, Apr.\\n2007, pp. 845–846.\\n\\n[47] Haveliwala T H. Topic-sensitive pagerank.\\n\\nIn Proc. the\\n11th International Conference on World Wide Web, Apr.\\n2002, pp. 517–526.\\n\\n[48] Choetkiertikul M, Avery D, Dam H K, Tran T, Ghose A.\\nWho will answer my question on stack overﬂow? In Proc.\\n24th Australasian Software Engineering Conference, Sept.\\n2015, pp. 155–164.\\n\\n[49] Lempel R, Moran S. Salsa: The stochastic approach for\\nlink-structure analysis. ACM Transactions on Information\\nSystems, 2001, 19(2):131–160.\\n\\n[50] Cheng T, Yan X, Chang K C C. Entityrank: Searching\\nentities directly and holistically. In Proc. the 33rd Interna-\\ntional Conference on Very Large Data Bases, Sept. 2007,\\npp. 387–398.\\n\\n[51] Weng J, Lim E P, Jiang J, He Q. Twitterrank: Finding\\ntopic-sensitive inﬂuential twitterers. In Proc. the 3rd ACM\\nInternational Conference on Web Search and Data Min-\\ning, Feb. 2010, pp. 261–270.\\n\\n[52] Liu X, Bollen J, Nelson M L, Sompel H. Co-authorship\\nnetworks in the digital library research community. Infor-\\nmation Processing & Management, 2005, 41(6):1462–1480.\\n[53] Shahriari M, Parekodi S, Klamma R. Community-aware\\nranking algorithms for expert identiﬁcation in question-\\nanswer forums.\\nIn Proc. the 15th International Confer-\\nence on Knowledge Technologies and Data-driven Busi-\\nness, Oct. 2015, p. 8.\\n\\n[54] Shahriari M, Krott S, Klamma R. Disassortative degree\\nmixing and information diﬀusion for overlapping commu-\\nnity detection in social networks (dmid). In Proc. the 24th\\n\\n[55] Bouguessa M, Dumoulin B, Wang S. Identifying author-\\nitative actors in question-answering forums: The case of\\nyahoo! answers.\\nIn Proc. the 14th ACM SIGKDD In-\\nternational Conference on Knowledge Discovery and Data\\nMining, Aug. 2008, pp. 866–874.\\n\\n[56] Fagin R, Lotem A, Naor M. Optimal aggregation algo-\\nrithms for middleware. Journal of Computer and System\\nSciences, 2003, 66(4):614–656.\\n\\n[57] Zhu H, Cao H, Xiong H, Chen E, Tian J. Towards expert\\nﬁnding by leveraging relevant categories in authority rank-\\ning. In Proc. the 20th ACM International Conference on\\nInformation and Knowledge Management, Oct. 2011, pp.\\n2221–2224.\\n\\n[58] Zhu H, Chen E, Xiong H, Cao H, Tian J. Ranking user au-\\nthority with relevant knowledge categories for expert ﬁnd-\\ning. World Wide Web, 2014, 17(5):1081–1107.\\n\\n[59] Liu J, Song Y I, Lin C Y. Competition-based user ex-\\npertise score estimation.\\nIn Proc. the 34th International\\nACM SIGIR Conference on Research and Development in\\nInformation Retrieval, Apr. 2011, pp. 425–434.\\n\\n[60] Lai L C, Kao H Y. Question routing by modeling user\\nexpertise and activity in cqa services.\\nIn Proc. the 26th\\nAnnual Conference of the Japanese Society for Artiﬁcial\\nIntelligence, Jun. 2012, pp. 1–10.\\n\\n[61] Lin Y, Shen H.\\nsystem for\\n\\nSmartq:\\n\\nswer\\nworthy answers.\\ndoi:10.1109/TBDATA.2017.2735442. (preprint).\\n\\nA question and an-\\nsupplying high-quality and trust-\\nIEEE Transactions on Big Data.\\n\\n[62] Liu D R, Chen Y H, Kao W C, Wang H W. Integrating ex-\\npert proﬁle, reputation and link analysis for expert ﬁnding\\nin question-answering websites. Information Processing &\\nManagement, 2013, 49(1):312–329.\\n\\n[63] Liu Z, Li K, Qu D. Knowledge graph based question routing\\nfor community question answering. In Proc. International\\nConference on Neural Information Processing, Nov. 2017,\\npp. 721–730.\\n\\n[64] Pal A, Konstan J A. Expert identiﬁcation in community\\nquestion answering: Exploring question selection bias. In\\nProc. the 19th ACM International Conference on Informa-\\ntion and Knowledge Management, 2010, pp. 1505–1508.\\n\\n[65] Pal A, Farzan R, Konstan J A, Kraut R E. Early detection\\nof potential experts in question answering communities. In\\nProc. International Conference on User Modeling, Adap-\\ntation, and Personalization, Jul. 2011, pp. 231–242.\\n\\n[66] Zhou T C, Lyu M R, King I. A classiﬁcation-based ap-\\nproach to question routing in community question answer-\\ning. In Proc. the 21st International Conference on World\\nWide Web, May 2012, pp. 783–790.\\n\\n[67] Ji Z, Wang B. Learning to rank for question routing in com-\\nmunity question answering. In Proc. the 22nd ACM Inter-\\nnational Conference on Information & Knowledge Man-\\nagement, Oct. 2013, pp. 2363–2368.\\n\\n[68] Dijk D, Tsagkias M, Rijke M. Early detection of topical\\nexpertise in community question answering. In Proc. the\\n38th International ACM SIGIR Conference on Research\\nand Development in Information Retrieval, Apr. 2015, pp.\\n995–998.\\n\\n\\x0c26\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\n[69] Le L T, Shah C. Retrieving rising stars in focused com-\\nmunity question-answering. In Proc. Asian Conference on\\nIntelligent Information and Database Systems, Mar. 2016,\\npp. 25–36.\\n\\n[70] Dror G, Koren Y, Maarek Y, Szpektor I. I want to answer,\\nwho has a question? yahoo! answers recommender system.\\nIn Proc. the 17th ACM SIGKDD International Conference\\non Knowledge Discovery and Data Mining, Aug. 2011, pp.\\n1109–1117.\\n\\n[71] Pal A, Harper F M, Konstan J A. Exploring question se-\\nlection bias to identify experts and potential experts in\\ncommunity question answering. ACM Transactions on In-\\nformation Systems, 2012, 30(2): Artical No. 10.\\n\\n[72] Burel G, Mulholland P, He Y, Alani H. Predicting answer-\\ning behaviour in online question answering communities.\\nIn Proc. the 26th ACM Conference on Hypertext & Social\\nMedia, Sept. 2015, pp. 201–210.\\n\\n[73] Burges C J, Ragno R, Le Q V. Learning to rank with\\nnonsmooth cost functions.\\nIn Proc. Advances in Neural\\nInformation Processing Systems, Dec. 2007, pp. 193–200.\\n[74] Cao Z, Qin T, Liu T Y, Tsai M F, Li H. Learning to rank:\\nFrom pairwise approach to listwise approach. In Proc. the\\n24th International Conference on Machine Learning, Jun.\\n2007, pp. 129–136.\\n\\n[75] Cheng X, Zhu S, Chen G, Su S. Exploiting user feedback for\\nexpert ﬁnding in community question answering. In IEEE\\nInternational Conference on Data Mining Workshop, Nov.\\n2015, pp. 295–302.\\n\\n[76] Wang N, Abel M H, Barth`es J P, Negre E. An answerer\\nrecommender system exploiting collaboration in cqa ser-\\nvices.\\nIn Proc. IEEE 20th International Conference on\\nComputer Supported Cooperative Work in Design, May\\n2016, pp. 198–203.\\n\\n[77] Dom B, Paranjpe D. A bayesian technique for estimat-\\ning the credibility of question answerers. In Proc. SIAM\\nInternational Conference on Data Mining, May 2008, pp.\\n399–409.\\n\\n[78] Koren Y, Bell R, Volinsky C. Matrix factorization\\ntechniques for recommender systems. Computer, 2009,\\n42(8):42–49.\\n\\n[79] Cho J H, Li Y, Girju R, Zhai C. Recommending forum\\nposts to designated experts. In Proc. IEEE International\\nConference on Big Data, Oct. 2015, pp. 659–666.\\n\\n[80] Singh A P, Gordon G J. Relational learning via collective\\nmatrix factorization. In Proc. the 14th ACM SIGKDD In-\\nternationalConference on Knowledge Discovery and Data\\nMining, Aug. 2008, pp. 650–658.\\n\\n[81] Yang B, Manandhar S. Tag-based expert recommendation\\nin community question answering.\\nIn Proc. IEEE/ACM\\nInternational Conference on Advances in Social Networks\\nAnalysis and Mining, Aug. 2014, pp. 960–963.\\n\\n[82] Mnih A, Salakhutdinov R R. Probabilistic matrix factoriza-\\ntion. In Proc. Advances in Neural Information Processing\\nSystems, Dec. 2008, pp. 1257–1264.\\n\\n[83] Zhou G, Liu K, Zhao J. Topical authority identiﬁcation in\\ncommunity question answering. In Proc. Chinese Confer-\\nence on Pattern Recognition, Nov. 2012, pp. 622–629.\\n\\nanswering websites. In Proc. International Conference on\\nWeb-Based Learning, Aug. 2015, pp. 165–173.\\n\\n[85] Yang J, Peng S, Wang L, Wu B. Finding experts in commu-\\nnity question answering based on topic-sensitive link anal-\\nysis. In Proc. IEEE International Conference on Data Sci-\\nence in Cyberspace, Jun. 2016, pp. 54–60.\\n\\n[86] Rao Y, Xie H, Liu X, Li Q, Wang F L, Wong T L. User au-\\nthority ranking models for community question answering.\\nJournal of Intelligent & Fuzzy Systems, 2016, 31(5):2533–\\n2542.\\n\\n[87] Zhao T, Bian N, Li C, Li M. Topic-level expert modeling\\nin community question answering. In Proc. SIAM Interna-\\ntional Conference on Data Mining, volume 13, May 2013,\\npp. 776–784.\\n\\n[88] Zhou G, Lai S, Liu K, Zhao J. Topic-sensitive probabilis-\\ntic model for expert ﬁnding in question answer communi-\\nties. In Proc. the 21st ACM International Conference on\\nInformation and Knowledge Management, Oct. 2012, pp.\\n1662–1666.\\n\\n[89] Yang L, Qiu M, Gottipati S, Zhu F, Jiang J, Sun H, Chen\\nZ. Cqarank: Jointly model topics and expertise in commu-\\nnity question answering. In Proc. the 22nd ACM Interna-\\ntional Conference on Information & Knowledge Manage-\\nment, Oct. 2013, pp. 99–108.\\n\\n[90] Yan Z, Zhou J. A new approach to answerer recommen-\\ndation in community question answering services. In Proc.\\nEuropean Conference on Information Retrieval, Apr. 2012,\\npp. 121–132.\\n\\n[91] Yin H, Hu Z, Zhou X, Wang H, Zheng K, Nguyen Q V H,\\nSadiq S. Discovering interpretable geo-social communities\\nfor user behavior prediction. In Proc. IEEE 32nd Inter-\\nnational Conference on Data Engineering, May 2016, pp.\\n942–953.\\n\\n[92] Suryanto M A, Lim E P, Sun A, Chiang R H. Quality-aware\\ncollaborative question answering: Methods and evaluation.\\nIn Proc. the 2nd ACM International Conference on Web\\nSearch and Data Mining, Feb. 2009, pp. 142–151.\\n\\n[93] Chang S, Pal A. Routing questions for collaborative\\nanswering in community question answering.\\nIn Proc.\\nIEEE/ACM International Conference on Advances in So-\\ncial Networks Analysis and Mining, Aug. 2013, pp. 494–\\n501.\\n\\n[94] Yeniterzi R, Callan J. Moving from static to dynamic mod-\\neling of expertise for question routing in cqa sites. In Proc.\\n9th International AAAI Conference on Web and Social\\nMedia, Jun. 2015, pp. 702–705.\\n\\n[95] Zhao Z, Zhang L, He X, Ng W. Expert ﬁnding for question\\nanswering via graph regularized matrix completion. IEEE\\nTransactions on Knowledge and Data Engineering, 2015,\\n27(4):993–1004.\\n\\n[96] Zhao Z, Wei F, Zhou M, Ng W. Cold-start expert ﬁnding\\nin community question answering via graph regularization.\\nIn Proc. International Conference on Database Systems for\\nAdvanced Applications, May 2015, pp. 21–38.\\n\\n[97] Nam K K, Ackerman M S, Adamic L A. Questions in,\\nknowledge in?: A study of naver’s question answering com-\\nmunity. In Proc. SIGCHI Conference on Human Factors\\nin Computing Systems, Apr. 2009, pp. 779–788.\\n\\n[84] Liu X, Ye S, Li X, Luo Y, Rao Y. Zhihurank: A topic-\\nsensitive expert ﬁnding algorithm in community question\\n\\n[98] Li X L, Foo C S, Tew K L, Ng S K. Searching for rising stars\\nin bibliography networks. In Proc. International Confer-\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n27\\n\\nence on Database Systems for Advanced Applications, Apr.\\n2009, pp. 288–292.\\n\\n[99] Daud A, Abbasi R, Muhammad F. Finding rising stars\\nin social networks. In Proc. International Conference on\\nDatabase Systems for Advanced Applications, Apr. 2013,\\npp. 13–24.\\n\\n[100] Deng H, King I, Lyu M R. Formal models for expert ﬁnding\\non dblp bibliography data. In Proc. 8th IEEE International\\nConference on Data Mining, Nov. 2008, pp. 163–172.\\n\\n[101] Hashemi S H, Neshati M, Beigy H. Expertise retrieval\\nin bibliographic network: A topic dominance learning ap-\\nproach. In Proc. the 22nd ACM International Conference\\non Information & Knowledge Management, Oct. 2013, pp.\\n1117–1126.\\n\\n[102] Mimno D, McCallum A. Expertise modeling for matching\\npapers with reviewers. In Proc. the 13th ACM SIGKDD In-\\nternational Conference on Knowledge Discovery and Data\\nMining, Aug. 2007, pp. 500–509.\\n\\n[103] Bagdouri M. Cross-platform question routing for better\\nquestion answering. In Proc. the 38th International ACM\\nSIGIR Conference on Research and Development in Infor-\\nmation Retrieval, Feb. 2015, pp. 1053–1053.\\n\\n[104] Richardson M, White R W. Supporting synchronous social\\nq&a throughout the question lifecycle. In Proc. the 20th\\ninternational conference on World wide web, Apr. 2011,\\npp. 755–764.\\n\\n[105] Java A, Kolari P, Finin T, Oates T. Modeling the spread\\nof inﬂuence on the blogosphere. In Proc. the 15th Interna-\\ntional World Wide Web Conference, Oct. 2006, pp. 22–26.\\n[106] Kempe D, Kleinberg J, Tardos ´E. Maximizing the spread of\\ninﬂuence through a social network. In Proc. the 9th ACM\\nSIGKDD International Conference on Knowledge Discov-\\nery and Data Mining, May 2003, pp. 137–146.\\n\\n[107] Pal A, Counts S.\\n\\nIdentifying topical authorities in mi-\\ncroblogs. In Proc. the 4th ACM international Conference\\non Web Search and Data Mining, Oct. 2011, pp. 45–54.\\n\\n[108] Campbell C S, Maglio P P, Cozzi A, Dom B. Expertise\\nidentiﬁcation using email communications.\\nIn Proc. the\\n12th International Conference on Information and Knowl-\\nedge Management, Oct. 2003, pp. 528–531.\\n\\n[109] Dom B, Eiron I, Cozzi A, Zhang Y. Graph-based rank-\\ning algorithms for e-mail expertise analysis. In Proc. the\\n8th ACM SIGMOD Workshop on Research Issues in Data\\nMining and Knowledge Discovery, Jun. 2003, pp. 42–48.\\n\\n[110] Shetty J, Adibi J. Discovering important nodes through\\ngraph entropy the case of enron email database. In Proc.\\nthe 3rd International Workshop on Link Discovery, Aug.\\n2005, pp. 74–81.\\n\\n[111] Mockus A, Herbsleb J D. Expertise browser: A quantita-\\ntive approach to identifying expertise.\\nIn Proc. the 24th\\nInternational Conference on Software Engineering, Jun.\\n2002, pp. 503–512.\\n\\n[112] Wei W, Lee J, King I. Measuring credibility of users in an e-\\nlearning environment. In Proc. the 16th International Con-\\nference on World Wide Web, May 2007, pp. 1279–1280.\\n\\n[113] Fu Y, Xiang R, Liu Y, Zhang M, Ma S. A cdd-based formal\\nmodel for expert ﬁnding. In Proc. the 16th ACM Confer-\\nence on Conference on Information and Knowledge Man-\\nagement, Oct. 2007, pp. 881–884.\\n\\n[114] Balog K, Bogers T, Azzopardi L, De Rijke M, Van\\nDen Bosch A. Broad expertise retrieval in sparse data en-\\nvironments. In Proc. the 30th annual International ACM\\nSIGIR Conference on Research and Development in Infor-\\nmation Retrieval, Aug. 2007, pp. 551–558.\\n\\n[115] Pasca M A, Harabagiu S M. High performance ques-\\ntion/answering.\\nIn roc. the 24th Annual International\\nACM SIGIR Conference on Research and Development in\\nInformation Retrieval, Apr. 2001, pp. 366–374.\\n\\n[116] Fang H, Zhai C. Probabilistic models for expert ﬁnding.\\nIn Proc. European Conference on Information Retrieval,\\nApr. 2007, pp. 418–430.\\n\\n[117] Macdonald C, Ounis I. Voting for candidates: Adapting\\ndata fusion techniques for an expert search task. In Proc.\\nthe 15th ACM International Conference on Information\\nand Knowledge Management, Oct. 2006, pp. 387–396.\\n\\n[118] Liu Y, Bian J, Agichtein E. Predicting information seeker\\nsatisfaction in community question answering. In Proc. the\\n31st International ACM SIGIR Conference on Research\\nand Development in Information Retrieval, Apr. 2008, pp.\\n483–490.\\n\\n[119] Srba I, Grznar M, Bielikova M. Utilizing non-qa data to\\nimprove questions routing for users with low qa activity in\\ncqa. In Proc. the IEEE/ACM International Conference on\\nAdvances in Social Networks Analysis and Mining, Aug.\\n2015, pp. 129–136.\\n\\n[120] Fagin R, Kumar R, Sivakumar D. Comparing top k lists.\\nSIAM Journal on Discrete Mathematics, 2003, 17(1):134–\\n160.\\n\\n[121] Herlocker J L, Konstan J A, Terveen L G, Riedl J T. Eval-\\nuating collaborative ﬁltering recommender systems. ACM\\nTransactions on Information Systems, 2004, 22(1):5–53.\\n\\n[122] Fang L, Huang M, Zhu X. Question routing in community\\nbased qa: Incorporating answer quality and answer con-\\ntent.\\nIn Proc. the ACM SIGKDD Workshop on Mining\\nData Semantics, Aug. 2012, p. 5.\\n\\n[123] Sung J, Lee J G, Lee U. Booming up the long tails: Dis-\\ncovering potentially contributive users in community-based\\nquestion answering services. In Proc. International AAAI\\nConference on Weblogs and Social Media, Jul. 2013, pp.\\n602–610.\\n\\n[124] Yin H, Zhou X, Shao Y, Wang H, Sadiq S. Joint modeling of\\nuser check-in behaviors for point-of-interest recommenda-\\ntion. In Proc. the 24th ACM International on Conference\\non Information and Knowledge Management, Oct. 2015,\\npp. 1631–1640.\\n\\n[125] Yin H, Cui B. Spatio-temporal Recommendation in Social\\n\\nMedia. Springer, Berlin, 1st edition, 2016.\\n\\n[126] Liu Q, Agichtein E. Modeling answerer behavior in col-\\nlaborative question answering systems. In Proc. European\\nConference on Information Retrieval, Apr. 2011, pp. 67–\\n79.\\n\\n[127] Yin H, Zhou X, Cui B, Wang H, Zheng K, Nguyen Q V H.\\nAdapting to user interest drift for poi recommendation.\\nIEEE Transactions on Knowledge and Data Engineering,\\n2016, 28(10):2566–2581.\\n\\n[128] Szpektor I, Maarek Y, Pelleg D. When relevance is not\\nenough: Promoting diversity and freshness in personal-\\nized question recommendation.\\nIn Proc. the 22nd Inter-\\n\\n\\x0c28\\n\\nJ. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n\\nnational Conference on World Wide Web, May 2013, pp.\\n1249–1260.\\n\\nConference on Intelligent User Interfaces, Oct. 2014, pp.\\n7–16.\\n\\n[129] Tong Y, Cao C C, Chen L. Tcs: Eﬃcient topic discovery\\nover crowd-oriented service data. In Proc. the 20th ACM\\nSIGKDD International Conference on Knowledge Discov-\\nery and Data Mining, Aug. 2014, pp. 861–870.\\n\\n[130] Pal A, Chang S, Konstan J A. Evolution of experts in\\nquestion answering communities. In Proc. the 6th Inter-\\nnational AAAI Conference on Weblogs and Social Media,\\nJun. 2012, pp. 274–281.\\n\\n[131] Cai Y, Chakravarthy S. Improving answer quality predic-\\ntion in q/a social networks by leveraging temporal feature.\\nProc. International Journal of Next-Generation Comput-\\ning, 2013, 4(1):1–27.\\n\\n[132] Tong Y, She J, Ding B, Wang L, Chen L. Online mobile\\nmicro-task allocation in spatial crowdsourcing.\\nIn Proc.\\nIEEE 32nd International Conference on Data Engineer-\\ning, Apr. 2016, pp. 49–60.\\n\\n[133] Yin H, Chen H, Sun X, Wang H, Wang Y, Nguyen Q V H.\\nSptf: A scalable probabilistic tensor factorization model\\nfor semantic-aware behavior prediction. In Proc. IEEE In-\\nternational Conference on Data Mining, Nov. 2017, pp.\\n585–594.\\n\\n[134] Yin H, Cui B, Huang Y. Finding a wise group of experts\\nin social networks. In Proc. International Conference on\\nAdvanced Data Mining and Applications, Nov. 2011, pp.\\n381–394.\\n\\n[135] O’connor M, Cosley D, Konstan J A, Riedl J. Polylens:\\nA recommender system for groups of users.\\nIn Proc.\\nEuropean Conference on Computer-Supported Cooperative\\nWork, Sept. 2001, pp. 199–218.\\n\\n[136] Ye M, Liu X, Lee W C. Exploring social inﬂuence for rec-\\nommendation: A generative model approach. In Proc. the\\n35th International ACM SIGIR Conference on Research\\nand Development in Information Retrieval, Aug. 2012, pp.\\n671–680.\\n\\n[137] Gorla J, Lathia N, Robertson S, Wang J. Probabilistic\\ngroup recommendation via information matching. In Proc.\\nthe 22nd International Conference on World Wide Web,\\nMay 2013, pp. 495–504.\\n\\n[138] Pal A. Metrics and algorithms for routing questions to user\\ncommunities. ACM Transactions on Information Systems,\\n2015, 33(3):14.\\n\\n[139] Feng W, Zhu Q, Zhuang J, Yu S.\\n\\nAn expert\\nrecommendation algorithm based on pearson correla-\\ntion coeﬃcient and fp-growth.\\nCluster Computing.\\ndoi:https://doi.org/10.1007/s10586-017-1576-y. (preprint).\\n[140] Tong Y, Chen L, Zhou Z, Jagadish H V, Shou L, Lv W.\\nSlade: A smart large-scale task decomposer in crowdsourc-\\ning. IEEE Transactions on Knowledge and Data Engineer-\\ning. doi:10.1109/TKDE.2018.2797962. (preprint).\\n\\n[141] Atkinson J, Maurelia A. Redundancy-based trust in\\nquestion-answering systems. Computer, 2017, 50(1):58–65.\\n[142] Liu Z, Jansen B J. Predicting potential responders in social\\nq&a based on non-qa features. In Proc. ACM CHI Confer-\\nence on Human Factors in Computing Systems, Apr. 2014,\\npp. 2131–2136.\\n\\n[143] Luo L, Wang F, Zhou M X, Pan Y, Chen H. Who have\\ngot answers?: Growing the pool of answerers in a smart en-\\nterprise social qa system. In Proc. the 19th International\\n\\n[144] Rendle S. Factorization machines. In Proc. the 10th IEEE\\nInternational Conference on Data Mining, Dec. 2010, pp.\\n995–1000.\\n\\n[145] Zhou Z H. Ensemble Methods: Foundations and Algo-\\n\\nrithms. CRC press, Boca Raton, 1st edition, 2012.\\n\\n[146] Friedman J H. Greedy function approximation: A gradient\\nboosting machine. Annals of Statistics, 2001, 29(5):1189–\\n1232.\\n\\n[147] Chen T, Guestrin C. Xgboost: A scalable tree boosting sys-\\ntem. In Proc. the 22nd ACM SIGKDD International Con-\\nference on Knowledge Discovery and Data Mining, Aug.\\nAug. 2016, pp. 785–794.\\n\\n[148] Yan S, Xu D, Zhang B, Zhang H J, Yang Q, Lin S. Graph\\nembedding and extensions: A general framework for dimen-\\nsionality reduction. IEEE transactions on Pattern Analysis\\nand Machine Intelligence, 2007, 29(1):40–51.\\n\\n[149] Yin H, Wang W, Wang H, Chen L, Zhou X. Spatial-aware\\nhierarchical collaborative deep learning for poi recommen-\\ndation. IEEE Transactions on Knowledge and Data Engi-\\nneering, 2017, 29(11):2537–2551.\\n\\n[150] Lin S, Hong W, Wang D, Li T. A survey on expert ﬁnding\\ntechniques. Journal of Intelligent Information Systems,\\n2017, 49(2):255–279.\\n\\n[151] Zheng C, Zhai S, Zhang Z.\\n\\nexpert\\n\\nfor\\ncommunities.\\n\\nproach\\nswering\\nhttps://arxiv.org/abs/1711.05350, Jun. 2018.\\n\\nidentiﬁcation\\n\\nA deep learning ap-\\nan-\\n2017.\\n\\nquestion\\n\\nin\\n\\narXiv:1711.05350,\\n\\nXianzhi Wang is a research fellow\\nwith School of Information Systems,\\nSingapore Management University,\\nSingapore.\\nHe received his B.E.\\ndegree from Xi’an Jiaotong Univer-\\nsity, Xi’an, M.E. and Ph.D. degrees\\nfrom Harbin Institute of Technology,\\nHarbin, all\\nin computer science in\\n2007, 2009, and 2014. His research interests include\\nInternet of Things, data management, machine learning,\\nand services computing. He received ARC Discovery Early\\nCareer Researcher Award (DECRA) in 2017 and IBM\\nPh.D. Fellowship Award in 2013.\\n\\nChaoran Huang is\\n\\ncurrently\\na Ph.D.\\ncandidate at School of\\nComputer Science and Engineering,\\nUniversity of New South Wales,\\nSydney. He received his B.E. degree\\nfrom Tianjin Polytechnic University,\\nTianjin, in 2014. His research inter-\\nests include data mining, Internet of\\n\\nThings, and service-oriented computing.\\n\\n\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n\\n29\\n\\nShe received her Ph.D.\\n\\nLina Yao is a lecturer at School of\\nComputer Science and Engineering,\\nUniversity of New South Wales,\\nSydney.\\nin\\ncomputer science from University of\\nAdelaide, Adelaide,\\nHer\\nresearch interests include data mining\\nlearning applications\\nand machine\\nwith the focuses on Internet of Things, recommender\\nsystems, human activity recognition, and Brain Computer\\nInterface. She is the recipient of ARC Discovery Early\\nCareer Researcher Award (DECRA) and Inaugural Vice\\nChancellor’s Women’s Research Excellence Award in 2015.\\n\\nin 2014.\\n\\nBoualem Benatallah is a sci-\\nentia professor and research group\\nleader at University of New South\\nHe received his\\nWales, Sydney.\\nPh.D.\\nfrom\\nGrenoble University, Grenoble. His\\nresearch interests include Web ser-\\nvices composition, quality control in\\ncrowdsourcing services, crowdsourcing for vulnerability\\ndiscovery, data curation, cognitive services engineering,\\nand cloud services orchestration.\\n\\nin computer\\n\\nscience\\n\\nis\\n\\nManqing Dong\\n\\ncurrently\\na Ph.D.\\ncandidate at School of\\nComputer Science and Engineering,\\nUniversity of New South Wales, Syd-\\nney. She received her BE degree from\\nJilin University, Jilin, and her MSc\\nin the City University of Hong Kong,\\nHer research interests\\nHongkong.\\ninclude anomaly detection, data mining, deep learning,\\nstatistical\\nlearning, and probabilistic graphical models.\\nShe is a student member of IEEE and ACM.\\n\\n\\x0c'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8\\n',\n",
       " '1\\n',\n",
       " '0\\n',\n",
       " '2\\n',\n",
       " '\\n',\n",
       " ' \\n',\n",
       " 'l\\n',\n",
       " 'u\\n',\n",
       " 'J\\n',\n",
       " ' \\n',\n",
       " '\\n',\n",
       " '5\\n',\n",
       " '1\\n',\n",
       " '\\n',\n",
       " ' \\n',\n",
       " ' \\n',\n",
       " ']\\n',\n",
       " 'I\\n',\n",
       " 'S\\n',\n",
       " '.\\n',\n",
       " 's\\n',\n",
       " 'c\\n',\n",
       " '[\\n',\n",
       " ' \\n',\n",
       " ' \\n',\n",
       " '\\n',\n",
       " '1\\n',\n",
       " 'v\\n',\n",
       " '0\\n',\n",
       " '4\\n',\n",
       " '5\\n',\n",
       " '5\\n',\n",
       " '0\\n',\n",
       " '\\n',\n",
       " '.\\n',\n",
       " '\\n',\n",
       " '7\\n',\n",
       " '0\\n',\n",
       " '8\\n',\n",
       " '1\\n',\n",
       " ':\\n',\n",
       " 'v\\n',\n",
       " 'i\\n',\n",
       " 'X\\n',\n",
       " 'r\\n',\n",
       " 'a\\n',\n",
       " '\\n',\n",
       " 'Wang X, Huang C, Yao L et al. A survey on expert recommendation in community question answering. JOURNAL OF\\n',\n",
       " 'COMPUTER SCIENCE AND TECHNOLOGY 33(1): 1–29 January 2018. DOI 10.1007/s11390-015-0000-0\\n',\n",
       " '\\n',\n",
       " 'A Survey on Expert Recommendation in Community Question\\n',\n",
       " 'Answering\\n',\n",
       " '\\n',\n",
       " 'Xianzhi Wang1, Member, ACM, IEEE, Chaoran Huang2, Lina Yao2, Member, ACM, IEEE,\\n',\n",
       " 'Boualem Benatallah2, Member, IEEE, and Manqing Dong2, Student Member, ACM, IEEE\\n',\n",
       " '\\n',\n",
       " '1 School of Software, University of Technology Sydney, NSW 2007, Australia\\n',\n",
       " '2 School of Computer Science and Engineering, University of New South Wales, Sydney, 2052 NSW, Australia\\n',\n",
       " 'E-mail: xzwang@smu.edu.sg, {chaoran.huang, lina.yao, b.benatallah, manqing.dong}@unsw.edu.au\\n',\n",
       " '\\n',\n",
       " 'Received July 15, 2018; revised October 14, 2018.\\n',\n",
       " '\\n',\n",
       " 'Abstract\\n',\n",
       " 'Community question answering (CQA) represents the type of Web applications where people can exchange\\n',\n",
       " 'knowledge via asking and answering questions. One signiﬁcant challenge of most real-world CQA systems is the lack of\\n',\n",
       " 'eﬀective matching between questions and the potential good answerers, which adversely aﬀects the eﬃcient knowledge\\n',\n",
       " 'acquisition and circulation. On the one hand, a requester might experience many low-quality answers without receiving a\\n',\n",
       " 'quality response in a brief time; on the other hand, an answerer might face numerous new questions without being able to\\n',\n",
       " 'identify their questions of interest quickly. Under this situation, expert recommendation emerges as a promising technique\\n',\n",
       " 'to address the above issues. Instead of passively waiting for users to browse and ﬁnd their questions of interest, an expert\\n',\n",
       " 'recommendation method raises the attention of users to the appropriate questions actively and promptly. The past few\\n',\n",
       " 'years have witnessed considerable eﬀorts that address the expert recommendation problem from diﬀerent perspectives.\\n',\n",
       " 'These methods all have their issues that need to be resolved before the advantages of expert recommendation can be\\n',\n",
       " 'fully embraced. In this survey, we ﬁrst present an overview of the research eﬀorts and state-of-the-art techniques for the\\n',\n",
       " 'expert recommendation in CQA. We next summarize and compare the existing methods concerning their advantages and\\n',\n",
       " 'shortcomings, followed by discussing the open issues and future research directions.\\n',\n",
       " '\\n',\n",
       " 'Keywords\\n',\n",
       " '\\n',\n",
       " 'community question answering, expert recommendation, challenges, solutions, future directions\\n',\n",
       " '\\n',\n",
       " '1 Introduction\\n',\n",
       " '\\n',\n",
       " 'The prosperity of crowdsourcing and web 2.0 has\\n',\n",
       " 'fostered numerous online communities featuring ques-\\n',\n",
       " 'tion answering (Q&A) activities. Such communities ex-\\n',\n",
       " 'ist in various forms such as dedicated websites, online\\n',\n",
       " 'forums, and discussion boards. They provide a venue\\n',\n",
       " 'for people to share and obtain knowledge by asking\\n',\n",
       " 'and answering questions, known as community ques-\\n',\n",
       " 'tion answering (CQA) [1]. While traditional online in-\\n',\n",
       " 'formation seeking approaches (e.g., search engines) re-\\n',\n",
       " 'trieve information from existing information reposito-\\n',\n",
       " 'ries based on keywords, they face several challenges.\\n',\n",
       " 'First, answers to some questions may not exist in the\\n',\n",
       " 'previously answered questions [2] and thus cannot be re-\\n',\n",
       " 'trieved from existing repositories directly. Second, most\\n',\n",
       " 'real-world questions are written in complicated natu-\\n',\n",
       " '\\n',\n",
       " 'ral languages that require certain human intelligence\\n',\n",
       " 'to be understood. Third, some questions inherently\\n',\n",
       " 'seek people’s opinions and can only be answered by hu-\\n',\n",
       " 'mans. While machines ﬁnd diﬃcult to handle the above\\n',\n",
       " 'cases, CQA can leverage the “wisdom of crowds” and\\n',\n",
       " 'obtain answers from multiple people simultaneously.\\n',\n",
       " 'Typical Q&A websites include Yahoo! Answers (an-\\n',\n",
       " 'swers.yahoo.com), Quora (www.quora.com), and Stack\\n',\n",
       " 'Overﬂow (stackoverﬂow.com). The ﬁrst two websites\\n',\n",
       " 'cover a wide range of topics, while the last only focuses\\n',\n",
       " 'on the topic of computer programming.\\n',\n",
       " '\\n',\n",
       " 'Though advantages over the traditional information\\n',\n",
       " 'seeking approaches, CQA faces several unique chal-\\n',\n",
       " 'lenges. First, a CQA website may have tens of thou-\\n',\n",
       " 'sands of questions posed every day, let alone the mil-\\n',\n",
       " 'lions of questions that already exist on the website. The\\n',\n",
       " 'huge volume of questions makes it diﬃcult for a gen-\\n',\n",
       " '\\n',\n",
       " 'Survey\\n',\n",
       " '©2018 Springer Science + Business Media, LLC & Science Press, China\\n',\n",
       " '\\n',\n",
       " '\\x0c2\\n',\n",
       " '\\n',\n",
       " 'J. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n',\n",
       " '\\n',\n",
       " 'eral answerer to ﬁnd the appropriate questions to an-\\n',\n",
       " 'swer [3]. Second, answerers usually have varying inter-\\n',\n",
       " 'est and expertise in diﬀerent topics and knowledge do-\\n',\n",
       " 'mains. Thus, they may give answers of varying quality\\n',\n",
       " 'to diﬀerent questions. The time required for preparing\\n',\n",
       " 'answers [4] and the intention of answering also aﬀect the\\n',\n",
       " 'quality of their responses. An extreme case is that an-\\n',\n",
       " 'swerers may give irrelevant answers that distract other\\n',\n",
       " 'users [5] without serious thinking. All the above situa-\\n',\n",
       " 'tions cause additional eﬀorts of an information seeker\\n',\n",
       " 'in obtaining good answers. Third, instead of receiving\\n',\n",
       " 'an answer instantly, users in CQA may need to wait a\\n',\n",
       " 'long time until a satisfactory answer appears. Previ-\\n',\n",
       " 'ous studies [6] show that many questions on real-world\\n',\n",
       " 'CQA websites cannot be resolved adequately, meaning\\n',\n",
       " 'the requesters recognize no best answers to their ques-\\n',\n",
       " 'tions within 24 hours.\\n',\n",
       " '\\n',\n",
       " 'Fortunately, several studies [7–9] have shown that\\n',\n",
       " 'some core answerers are the primary drivers of answer\\n',\n",
       " 'production in the many communities. Recent work\\n',\n",
       " 'on Stack Overﬂow and Quora [10] further indicates that\\n',\n",
       " 'these sites consist of a set of highly dedicated domain\\n',\n",
       " 'experts who aim at satisfying requesters’ query but\\n',\n",
       " 'more importantly at providing answers with high last-\\n',\n",
       " 'ing value to a broader audience. All these studies sug-\\n',\n",
       " 'gest the needs for recommending a small group of most\\n',\n",
       " 'competent answerers, or experts to answer the new\\n',\n",
       " 'questions.\\n',\n",
       " 'In fact, the long-tail phenomena in many\\n',\n",
       " 'real-world communities, from the statistic perspective,\\n',\n",
       " 'lays the ground of the rationale of expert recommenda-\\n',\n",
       " 'tion in CQA [11], as most answers and knowledge in the\\n',\n",
       " 'communities come from only a minority of users [11;12].\\n',\n",
       " 'As an eﬀective means of addressing the practical chal-\\n',\n",
       " 'lenges of traditional information seeking approaches,\\n',\n",
       " 'expert recommendation methods bring up the attention\\n',\n",
       " 'of only a small number of experts, i.e., the users who\\n',\n",
       " 'are most likely to provide high-quality answers, to an-\\n',\n",
       " 'swer a given question [13]. Since expert recommendation\\n',\n",
       " 'inherently encourages fast acquisition of higher-quality\\n',\n",
       " 'answers, it potentially increases the participation rates\\n',\n",
       " 'of users, improves the visibility of experts, as well as\\n',\n",
       " 'fosters stronger communities in CQA.\\n',\n",
       " '\\n',\n",
       " 'Given the advantages of expert recommendation\\n',\n",
       " 'and related topics such as question routing [6;14] and\\n',\n",
       " 'question recommendation [15] in the domains of Natu-\\n',\n",
       " 'ral Language Processing (NLP) and Information Re-\\n',\n",
       " 'trieval (IR), we aim to present a comprehensive survey\\n',\n",
       " 'on the expert recommendation in CQA. On the one\\n',\n",
       " 'hand, considerable eﬀorts have been conducted on the\\n',\n",
       " 'expert recommendation and have delivered fruitful re-\\n',\n",
       " '\\n',\n",
       " 'sults. Therefore, it is necessary to review the related\\n',\n",
       " 'methods and techniques to gain a timely and better\\n',\n",
       " 'understanding of state of the art. On the other hand,\\n',\n",
       " 'despite the active research in CQA, expert recommen-\\n',\n",
       " 'dation remains a challenging task. For example, the\\n',\n",
       " 'sparsity of historical question and answer records, low\\n',\n",
       " 'participation rates of users, lack of personalization in\\n',\n",
       " 'recommendation results, the migration of users in or\\n',\n",
       " 'out of communities, and lack of comprehensive consid-\\n',\n",
       " 'eration of diﬀerent clues in modeling users expertise are\\n',\n",
       " 'all regarded as challenging issues in literature. Given\\n',\n",
       " 'the diverse existing methods, it is crucial to develop a\\n',\n",
       " 'general framework to evaluate these methods and ana-\\n',\n",
       " 'lyze their shortcomings, as well as to point out promis-\\n',\n",
       " 'ing future research directions.\\n',\n",
       " '\\n',\n",
       " 'To the best of our knowledge, this is the ﬁrst com-\\n',\n",
       " 'prehensive survey that focuses on the expert recommen-\\n',\n",
       " 'dation issue in CQA. The remainder of the article is or-\\n',\n",
       " 'ganized as follows. We overview the expert recommen-\\n',\n",
       " 'dation problem in Section 2 and its current applications\\n',\n",
       " 'in CQA in Section 3. In Section 4, we present the clas-\\n',\n",
       " 'siﬁcation and introduction of state of the art expert rec-\\n',\n",
       " 'ommendation methods. In Section 5, we compare the\\n',\n",
       " 'investigated expert recommendation methods on vari-\\n',\n",
       " 'ous aspects and discuss their advantages and pitfalls.\\n',\n",
       " 'In Section 6, we highlight several promising research\\n',\n",
       " 'directions. Finally, we oﬀer some concluding remarks\\n',\n",
       " 'in Section 7.\\n',\n",
       " '\\n',\n",
       " '2 Expert Recommendation Problem\\n',\n",
       " '\\n',\n",
       " 'The expert recommendation issue is also known as\\n',\n",
       " 'the question routing or expert ﬁnding problem. The\\n',\n",
       " 'basic inputs of an expert recommendation problem in-\\n',\n",
       " 'clude users (i.e., requesters and answerers) and user-\\n',\n",
       " 'generated content (i.e., the questions raised by re-\\n',\n",
       " 'questers and the answers provided by answerers). More\\n',\n",
       " 'inputs might be available depending on the applica-\\n',\n",
       " 'tion scenarios. Typically, they include user proﬁles\\n',\n",
       " '(e.g., badges, reputation scores, and links to external\\n',\n",
       " 'resources such as Web pages), users’ feedback on ques-\\n',\n",
       " 'tions and answers (e.g., textual comments and votings),\\n',\n",
       " 'and question details (e.g., the categories of questions\\n',\n",
       " 'and duplication relations among questions). The rela-\\n',\n",
       " 'tionship among the diﬀerent types of inputs of an ex-\\n',\n",
       " 'pert recommendation problem is described in the class\\n',\n",
       " 'diagram shown in Fig. 1.\\n',\n",
       " '\\n',\n",
       " 'Question answering websites usually organize infor-\\n',\n",
       " 'mation in the form of threads. Each thread is led by a\\n',\n",
       " 'single question, which is replied to with none, one, or\\n',\n",
       " '\\n',\n",
       " '\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n',\n",
       " '\\n',\n",
       " '3\\n',\n",
       " '\\n',\n",
       " 'Fig.1. Elements of expert recommendation in CQA.\\n',\n",
       " '\\n',\n",
       " 'multiple answers. Each question or answer is provided\\n',\n",
       " 'by a single user, called a requester or an answerer, re-\\n',\n",
       " 'spectively. A requester may ask multiple questions, and\\n',\n",
       " 'each answerer may answer various questions. A user\\n',\n",
       " 'can be either a requester or an answerer, or both at the\\n',\n",
       " 'same time in the same CQA website, and all users are\\n',\n",
       " 'free to provide diﬀerent types of feedback on the posted\\n',\n",
       " 'questions and answers. For example, in Stack Overﬂow,\\n',\n",
       " 'any registered user can comment and vote (by giving\\n',\n",
       " 'a thumb up or thumb down) on an answer posted for\\n',\n",
       " 'any question, and the requester has the authority to\\n',\n",
       " 'mark one from the posted answers as the best answer.\\n',\n",
       " 'In case that the requester has not designated the best\\n',\n",
       " 'answer within a speciﬁed period, the system will auto-\\n',\n",
       " 'matically mark the response that received the highest\\n',\n",
       " 'voting score as the best answer.\\n',\n",
       " '\\n',\n",
       " 'The objective of the expert recommendation prob-\\n',\n",
       " 'lem is to raise the attention of experts, i.e., a small num-\\n',\n",
       " 'ber of users who are most likely to provide high-quality\\n',\n",
       " 'answers, to the given question based on the above prob-\\n',\n",
       " 'lem inputs. Despite the various possible types of inputs,\\n',\n",
       " 'only a subset of them might be available in a speciﬁc\\n',\n",
       " 'application scenario. Therefore, researchers may deﬁne\\n',\n",
       " 'the expert recommendation problem diﬀerently accord-\\n',\n",
       " 'ing to the inputs. Besides, researchers may take into\\n',\n",
       " 'account diﬀerent concerns and expect diﬀerent types\\n',\n",
       " 'of outputs from their methods. Generally, topical rel-\\n',\n",
       " 'evance and expertise are the two most considered as-\\n',\n",
       " 'pects of concerns by the existing research. While some\\n',\n",
       " 'researchers develop methods to ﬁnd a group of high-\\n',\n",
       " 'quality answerers, other researchers aim to deliver a\\n',\n",
       " 'ranked list, where the users are ranked according to\\n',\n",
       " 'their potential to provide the best answer. We will\\n',\n",
       " 'elaborate the variations in the problem deﬁnition in\\n',\n",
       " 'Section 5.\\n',\n",
       " '\\n',\n",
       " 'Generally, it is only necessary to recommend experts\\n',\n",
       " 'when the new question is signiﬁcantly diﬀerent from\\n',\n",
       " 'any previous questions with best answers, meaning that\\n',\n",
       " '\\n',\n",
       " 'no satisfactory answers are readily available within the\\n',\n",
       " 'archive of best answers to the earlier questions. Expert\\n',\n",
       " 'recommendation generally brings about the following\\n',\n",
       " 'advantages to CQA: i) users usually prefer answers from\\n',\n",
       " 'experts, who are supposed to have suﬃcient motiva-\\n',\n",
       " 'tion and knowledge to answer the given questions and\\n',\n",
       " 'therefore more likely to provide high-quality answers\\n',\n",
       " 'promptly; ii) expert recommendations can potentially\\n',\n",
       " 'reduce the waiting time of requesters in ﬁnding satis-\\n',\n",
       " 'factory answers as well as the time of experts in ﬁnd-\\n',\n",
       " 'ing their questions of interests; iii) by bridging the gap\\n',\n",
       " 'between requesters and answerers, expert recommenda-\\n',\n",
       " 'tions can potentially promote their participation rates\\n',\n",
       " 'and thus foster stronger communities. Since experts\\n',\n",
       " 'are recommended with questions that ﬁt their exper-\\n',\n",
       " 'tise, their visibility is expected to be improved as well.\\n',\n",
       " '\\n',\n",
       " '3 Current Applications in CQA\\n',\n",
       " '\\n',\n",
       " 'Currently, there exist various Q&A websites where\\n',\n",
       " 'expert recommendation techniques are applied or can\\n',\n",
       " 'be potentially applied. Due to the large number of\\n',\n",
       " 'Q&A websites that exist nowadays, we selectively list\\n',\n",
       " 'some typical Q&A websites by launch year in Table 1.\\n',\n",
       " 'In the following subsections, we will categorize and give\\n',\n",
       " 'further illustrations of several typical websites of each\\n',\n",
       " 'category.\\n',\n",
       " '\\n',\n",
       " '3.1 Early CQA Services\\n',\n",
       " '\\n',\n",
       " 'Most early-stage Q&A services (e.g., the ﬁrst four\\n',\n",
       " 'websites in Table 1) meet a requesters’ information\\n',\n",
       " 'needs by resorting to the opinions of experts rather than\\n',\n",
       " 'the crowd. These experts are acknowledged by either\\n',\n",
       " 'the websites or third-party authorities and are often\\n',\n",
       " 'limited in number. They usually have rich knowledge\\n',\n",
       " 'and experience in some domains but require a payment\\n',\n",
       " 'for the answers they provide. We introduce two of these\\n',\n",
       " 'websites as examples as follows:\\n',\n",
       " '\\n',\n",
       " '\\x0c4\\n',\n",
       " '\\n',\n",
       " 'J. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n',\n",
       " '\\n',\n",
       " 'Community\\n',\n",
       " '\\n',\n",
       " 'MedHelp\\n',\n",
       " '\\n',\n",
       " 'Mad Scientist Netwok\\n',\n",
       " '\\n',\n",
       " 'WebMD\\n',\n",
       " '\\n',\n",
       " 'Google Answers\\n',\n",
       " '\\n',\n",
       " 'Naver KiN\\n',\n",
       " '\\n',\n",
       " 'WikiAnswers\\n',\n",
       " '\\n',\n",
       " 'Answerbag\\n',\n",
       " '\\n',\n",
       " 'IAsk\\n',\n",
       " '\\n',\n",
       " 'Baidu Knows\\n',\n",
       " '\\n',\n",
       " 'Live QnA\\n',\n",
       " '\\n',\n",
       " 'TurboTax Live Community\\n',\n",
       " '\\n',\n",
       " 'Sogou Wenwen\\n',\n",
       " '\\n',\n",
       " 'Stack Overﬂow\\n',\n",
       " '\\n',\n",
       " 'Quora\\n',\n",
       " '\\n',\n",
       " 'Seasoned Advice\\n',\n",
       " '\\n',\n",
       " 'Table 1. Some Popular Question Answering Communities\\n',\n",
       " '\\n',\n",
       " 'Language\\n',\n",
       " '\\n',\n",
       " 'Specialized Domain\\n',\n",
       " '\\n',\n",
       " 'Launch Year\\n',\n",
       " '\\n',\n",
       " 'Still Active\\n',\n",
       " '\\n',\n",
       " 'Quality Guarantee\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'Multiple\\n',\n",
       " '\\n',\n",
       " 'Korean\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'Chinses\\n',\n",
       " '\\n',\n",
       " 'Chinese\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'Chinese\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'English\\n',\n",
       " '\\n',\n",
       " 'Medical\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Medical\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Tax\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Programming\\n',\n",
       " '\\n',\n",
       " 'Various\\n',\n",
       " '\\n',\n",
       " 'Cooking\\n',\n",
       " '\\n',\n",
       " '1994\\n',\n",
       " '\\n',\n",
       " '1995\\n',\n",
       " '\\n',\n",
       " '1996\\n',\n",
       " '\\n',\n",
       " '2002\\n',\n",
       " '\\n',\n",
       " '2002\\n',\n",
       " '\\n',\n",
       " '2002\\n',\n",
       " '\\n',\n",
       " '2003\\n',\n",
       " '\\n',\n",
       " '2005\\n',\n",
       " '\\n',\n",
       " '2005\\n',\n",
       " '\\n',\n",
       " '2006\\n',\n",
       " '\\n',\n",
       " '2007\\n',\n",
       " '\\n',\n",
       " '2007\\n',\n",
       " '\\n',\n",
       " '2008\\n',\n",
       " '\\n',\n",
       " '2010\\n',\n",
       " '\\n',\n",
       " '2010\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'Y\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'N\\n',\n",
       " '\\n',\n",
       " 'Mad Scientist Network 1 : a famous ask-a-scientist\\n',\n",
       " 'web service where people ask questions by ﬁlling forms\\n',\n",
       " 'and moderators are responsible for reviewing the ques-\\n',\n",
       " 'tions and sending them to the appropriate members for\\n',\n",
       " 'answers. The moderators will also review the answers\\n',\n",
       " 'before making them public.\\n',\n",
       " '\\n',\n",
       " 'Google Answers 2 : a knowledge market service de-\\n',\n",
       " 'signed as an extension to Google’s search service. There\\n',\n",
       " 'were a group of answerers called Google Answers Re-\\n',\n",
       " 'searchers who are oﬃcially approved to answer ques-\\n',\n",
       " 'tions through an application process. Instead of pas-\\n',\n",
       " 'sively waiting for other people to moderate or answer\\n',\n",
       " 'their questions, people can actively ﬁnd the potential\\n',\n",
       " 'answerers by themselves and pay the answerers.\\n',\n",
       " '\\n',\n",
       " '3.2 General-purpose CQA Websites\\n',\n",
       " '\\n',\n",
       " 'The Q&A services that emerge in the past two\\n',\n",
       " 'decades are increasingly leveraging the “wisdom of the\\n',\n",
       " 'crowd” rather than a small number of experts to give\\n',\n",
       " 'answers. Websites following this philosophy allow any\\n',\n",
       " 'users to voluntarily answer any questions on their free\\n',\n",
       " 'will and most of them serve as general purpose plat-\\n',\n",
       " 'forms for knowledge sharing rather then domain fo-\\n',\n",
       " 'cused ones. We overview some typical general purpose\\n',\n",
       " 'websites as follows:\\n',\n",
       " '\\n',\n",
       " 'Quora: one of the largest existing Q&A website\\n',\n",
       " 'where users can ask and answer questions, rate and\\n',\n",
       " 'edit the answers posted by others.\\n',\n",
       " '\\n',\n",
       " 'Zhihu 3 : a Chinese Q&A website similar to Quora.\\n',\n",
       " 'It allows users to create and edit questions and answers,\\n',\n",
       " 'rate system, and tag questions. Also, users may also\\n',\n",
       " 'post blogs in Zhihu for sharing while others can view\\n',\n",
       " 'and comment on such posts.\\n',\n",
       " '\\n',\n",
       " 'Naver KiN 4 : a Korean CQA community, one of\\n',\n",
       " 'the earlier cases of expansion of search service using\\n',\n",
       " 'user-generated content.\\n',\n",
       " '\\n',\n",
       " 'WikiAnswers 5 : a wiki service that allows people\\n',\n",
       " 'to raise and answer questions, as well as edit existing\\n',\n",
       " 'answers to questions. It uses a so-called “alternates sys-\\n',\n",
       " 'tem” to automatically merge similar questions. Since\\n',\n",
       " 'an answer may be associated with multiple questions,\\n',\n",
       " 'duplicated entries can be avoided to some extent.\\n',\n",
       " '\\n',\n",
       " 'Answerbag 6 : a CQA community where users can\\n',\n",
       " 'ask and answer questions, give comments to answers,\\n',\n",
       " 'rate questions, rate answers, and suggest new cate-\\n',\n",
       " 'gories.\\n',\n",
       " '\\n',\n",
       " 'Live QnA 7 : also known as MSN QnA, was part of\\n',\n",
       " 'Microsoft MSN group services.\\n',\n",
       " 'In this system, users\\n',\n",
       " 'can ask and answer questions, tag them to speciﬁc top-\\n',\n",
       " 'ics, and gain points and reputations by answering ques-\\n',\n",
       " '\\n',\n",
       " '1 http://www.madsci.org/, May 2018.\\n',\n",
       " '2 http://answers.google.com/, May 2018.\\n',\n",
       " '3 http://www.zhihu.com/, May 2018.\\n',\n",
       " '4 http://kin.naver.com/, May 2018.\\n',\n",
       " '5 http://www.wikianswers.com/, May 2018.\\n',\n",
       " '6 http://www.answerbag.com/, May 2018.\\n',\n",
       " '7 http://qna.live.com/, May 2018.\\n',\n",
       " '\\n',\n",
       " '\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n',\n",
       " '\\n',\n",
       " '5\\n',\n",
       " '\\n',\n",
       " 'tions.\\n',\n",
       " '\\n',\n",
       " '4 Expert Recommendation Methods\\n',\n",
       " '\\n',\n",
       " '3.3 Domain-focused CQA Websites\\n',\n",
       " '\\n',\n",
       " 'Compared with those general purpose websites,\\n',\n",
       " 'each domain-focused Q&A website only covers limited\\n',\n",
       " 'topics or knowledge domains. The Stack Exchange net-\\n',\n",
       " 'works are probably the largest host of domain-focused\\n',\n",
       " 'Q&A websites nowadays. Some typical websites hosted\\n',\n",
       " 'by it include the following:\\n',\n",
       " '\\n',\n",
       " 'MathOverﬂow 8 : a Q&A website focused on math-\\n',\n",
       " '\\n',\n",
       " 'ematical problems.\\n',\n",
       " '\\n',\n",
       " 'AskUbuntu 9 : a website supporting Q&A activities\\n',\n",
       " '\\n',\n",
       " 'related to Ubuntu operation Systems.\\n',\n",
       " '\\n',\n",
       " 'StackOverﬂow : a Q&A website focused on com-\\n',\n",
       " '\\n',\n",
       " 'puter programming.\\n',\n",
       " '\\n',\n",
       " 'All these websites follow similar sets of styles and\\n',\n",
       " 'functions. Apart from the basic question answering\\n',\n",
       " 'features, they commonly use badges to recognize the\\n',\n",
       " 'achievement of answerers and grant badges to users\\n',\n",
       " 'based on their reputation points. Users can also un-\\n',\n",
       " 'lock more privileges with higher reputation points.\\n',\n",
       " '\\n',\n",
       " '3.4 Summary\\n',\n",
       " '\\n',\n",
       " 'In summary, despite the prevalence of diverse types\\n',\n",
       " 'of Q&A websites, few of them have incorporated any\\n',\n",
       " 'eﬀective expert recommendation techniques to bridge\\n',\n",
       " 'requesters and answers. To the best of our knowledge,\\n',\n",
       " 'currently, the only implementation of the idea of rout-\\n',\n",
       " 'ing questions to the appropriate users in Q&A is called\\n',\n",
       " '“Aardvark” [16]. However, the primary purpose of this\\n',\n",
       " 'system is to serve as an enhanced search engine, and\\n',\n",
       " 'the expert recommendation techniques it employs are\\n',\n",
       " 'still at a preliminary stage. Recently, Bayati et al. [17]\\n',\n",
       " 'design a framework for recommending security experts\\n',\n",
       " 'for software engineering projects. This framework oﬀers\\n',\n",
       " 'more strength to facilitate expert recommendation by\\n',\n",
       " 'considering multiple aspects of users such as program-\\n',\n",
       " 'ming language, location, and social proﬁles on domi-\\n',\n",
       " 'nant programming Q&A websites like StackOverﬂow.\\n',\n",
       " 'Since the Q&A systems can be regarded as a type of\\n',\n",
       " 'crowdsourcing systems [18], the expert recommendation\\n',\n",
       " 'methods for a Q&A system can potentially be gener-\\n',\n",
       " 'alized and applied to general crowdsourcing systems as\\n',\n",
       " 'well.\\n',\n",
       " '\\n',\n",
       " '8 http://mathoverﬂow.net/, May 2018.\\n',\n",
       " '9 http://askubuntu.com/, May 2018.\\n',\n",
       " '\\n',\n",
       " 'As the major technique to facilitate eﬀective CQA,\\n',\n",
       " 'considerable eﬀorts have been contributed to the ex-\\n',\n",
       " 'pert recommendation research from the information re-\\n',\n",
       " 'trieval (IR), machine learning, and social computing\\n',\n",
       " 'perspectives, and have delivered fruitful results. We\\n',\n",
       " 'classify the state of the art expert recommendation\\n',\n",
       " 'methods into eight categories and review the methods\\n',\n",
       " 'by category in the following subsections.\\n',\n",
       " '\\n',\n",
       " '4.1 Simple Methods\\n',\n",
       " '\\n',\n",
       " 'One of the most critical tasks of expert recommen-\\n',\n",
       " 'dation is to evaluate users. Given a new question to\\n',\n",
       " 'be answered, some methods use simple metrics such\\n',\n",
       " 'as counts of positive/negative votes, proportions of\\n',\n",
       " 'best answers, and the similarity between the new ques-\\n',\n",
       " 'tion and users’ previous answered questions to evaluate\\n',\n",
       " 'users’ ﬁtness to answer the questions. In the following,\\n',\n",
       " 'we introduce the methods that use the three metrics,\\n',\n",
       " 'respectively. For any of these methods, a higher score\\n',\n",
       " 'indicates a better answerer.\\n',\n",
       " '\\n',\n",
       " 'Votes: the method evaluates a user by the number\\n',\n",
       " 'of aﬃrmative votes minus the number of negative votes,\\n',\n",
       " 'combined with the total percentage of aﬃrmative votes\\n',\n",
       " 'that the user receives from other users averaged over\\n',\n",
       " 'all the answers the user have attempted.\\n',\n",
       " '\\n',\n",
       " 'Best answer proportion: this method ranks users by\\n',\n",
       " 'the fraction of best answers among all the answers at-\\n',\n",
       " 'tempted by an answerer. The best answers are either\\n',\n",
       " 'awarded by the requester of questions or by the ques-\\n',\n",
       " 'tion answering platform when requesters designate no\\n',\n",
       " 'best answers.\\n',\n",
       " '\\n',\n",
       " 'Textual similarity:\\n',\n",
       " '\\n',\n",
       " 'the most famous method for\\n',\n",
       " 'measuring textual similarity is to compute the cosine\\n',\n",
       " 'similarity based on the term frequency-inverse docu-\\n',\n",
       " 'ment frequency (TF-IDF) model, a classic vector space\\n',\n",
       " 'model (VSM) [19] borrowed from the information re-\\n',\n",
       " 'trieval domain. VSM is readily applicable to computing\\n',\n",
       " 'the similarity of an answerer’s proﬁle to a given ques-\\n',\n",
       " 'tion. Therefore, it can be directly used for the expert\\n',\n",
       " 'recommendation by relating a new question to the an-\\n',\n",
       " 'swerers who have previously answered the most relevant\\n',\n",
       " 'questions to the given question.\\n',\n",
       " '\\n',\n",
       " '\\x0c6\\n',\n",
       " '\\n',\n",
       " 'J. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n',\n",
       " '\\n',\n",
       " '4.2 Language Models\\n',\n",
       " '\\n',\n",
       " 'Despite the simplicity, VSM adopts the “bag-of-\\n',\n",
       " 'words” assumption and thus brings the high-dimension\\n',\n",
       " 'document representation issue.\\n',\n",
       " 'In contrast, language\\n',\n",
       " 'models use a generative approach to compute the word-\\n',\n",
       " 'based relevance of a user’s previous activities to the\\n',\n",
       " 'given question, and in turn, to predict the possibility\\n',\n",
       " 'of a user answering the question. Such models can,\\n',\n",
       " 'to some extent alleviate the high dimension issue. In a\\n',\n",
       " 'language model, the users whose proﬁles are most likely\\n',\n",
       " 'to generate the given question are believed to have to\\n',\n",
       " 'highest probability to answer the given question. The\\n',\n",
       " 'model ﬁnally returns a ranked list of users according to\\n',\n",
       " 'their likelihood of answering the given question.\\n',\n",
       " '\\n',\n",
       " 'The language model-based methods include proﬁle-\\n',\n",
       " 'based methods and document-based methods. The for-\\n',\n",
       " 'mer [20] models the knowledge of each user with the as-\\n',\n",
       " 'sociated documents and ranks the candidate experts\\n',\n",
       " 'for a given topic based on the relevance scores between\\n',\n",
       " 'their proﬁles and the given question. The latter [20]\\n',\n",
       " 'ﬁnds related documents for a given topic and ranks\\n',\n",
       " 'candidates based on mentions of the candidates in the\\n',\n",
       " 'related documents.\\n',\n",
       " '\\n',\n",
       " '4.2.1 QLL and Basic Variants\\n',\n",
       " '\\n',\n",
       " 'Among the methods of this category, query likeli-\\n',\n",
       " 'hood language (QLL) model [21] is the most popular\\n',\n",
       " 'technique. QLL calculates a probability that user pro-\\n',\n",
       " 'ﬁles will generate terms of the routed question. The\\n',\n",
       " 'traditional language models often suﬀer the mismatch\\n',\n",
       " 'between the question and user proﬁles caused by the\\n',\n",
       " 'co-occurrence of random words in user proﬁles or ques-\\n',\n",
       " 'tions resulting from data sparseness. Translation mod-\\n',\n",
       " 'els [22] overcomes data sparseness by employing statis-\\n',\n",
       " 'tical machine translation and can diﬀerentiate between\\n',\n",
       " 'exact matched words and translated semantically re-\\n',\n",
       " 'lated ones. A typical work [23] using this method views\\n',\n",
       " 'the problem as an IR problem.\\n',\n",
       " 'It considers the new\\n',\n",
       " 'question as a query and the expert proﬁles as docu-\\n',\n",
       " 'ments.\\n',\n",
       " 'It next estimates an answerer’s expertise by\\n',\n",
       " 'combining its previously answered questions, and re-\\n',\n",
       " 'gards experts as the users who have answered the most\\n',\n",
       " 'similar questions in the past.\\n',\n",
       " '\\n',\n",
       " 'Besides the basic models, many variants of QLL\\n',\n",
       " 'have also emerged as alternatives or enhancements. For\\n',\n",
       " 'example, Liu et al. propose two variants of the ba-\\n',\n",
       " 'sic language model, namely relevance-based language\\n',\n",
       " 'model [24] and cluster-based language model [25] to rank\\n',\n",
       " 'user proﬁles. Petkova and Croft [26] propose a hierarchi-\\n',\n",
       " 'cal language model which uses a ﬁner-grained approach\\n',\n",
       " '\\n',\n",
       " 'with a linear combination of the language models built\\n',\n",
       " 'on subcollections of documents.\\n',\n",
       " '\\n',\n",
       " '4.2.2 Category-sensitive QLL\\n',\n",
       " '\\n',\n",
       " 'Considering the availability of categories in many\\n',\n",
       " 'Q&A websites, Li et al. [27] propose a category-sensitive\\n',\n",
       " 'QLL model to exploit the hierarchical category infor-\\n',\n",
       " 'mation presented with questions in Yahoo! Answers.\\n',\n",
       " 'Once a question gets categorized, the task is to ﬁnd the\\n',\n",
       " 'users who are most likely to answer that question within\\n',\n",
       " 'its category. Their experiments over the Yahoo! An-\\n',\n",
       " 'swers dataset show that taking categories into account\\n',\n",
       " 'improves the recommendation performance. A limita-\\n',\n",
       " 'tion of the category-sensitive model is that categories\\n',\n",
       " 'need to be well predeﬁned and some questions might\\n',\n",
       " 'be closely related to multiple categories due to the ex-\\n',\n",
       " 'istence of similar categories that share the same con-\\n',\n",
       " 'texts. A possible solution to address this limitation is\\n',\n",
       " 'the transferred category-sensitive QLL model [27], which\\n',\n",
       " 'additionally builds and considers the relevance between\\n',\n",
       " 'categories.\\n',\n",
       " '\\n',\n",
       " '4.2.3 Expertise-aware QLL\\n',\n",
       " '\\n',\n",
       " 'Zheng et al. [28] linearly combine two aspects, user\\n',\n",
       " 'relevance (computed based on the QLL) and answer\\n',\n",
       " 'quality (estimated using a maximum entropy model),\\n',\n",
       " 'using the simple weighted sum method to represent\\n',\n",
       " 'user expertise on a given question. Besides the rele-\\n',\n",
       " 'vance and quality aspects, Li et al. [6] further consider\\n',\n",
       " 'the availability of users and use the weighted sum of\\n',\n",
       " 'the three aspects to represent user expertise on a given\\n',\n",
       " 'question. In particular, the relevance is estimated us-\\n',\n",
       " 'ing the QLL model, the answer quality is estimated as\\n',\n",
       " 'the weighted average of previous answer quality incor-\\n',\n",
       " 'porated with the Jelinek-Mercer smoothing [29] method,\\n',\n",
       " 'and users’ availability to answer a given question during\\n',\n",
       " 'a given period is predicted by an autoregressive model.\\n',\n",
       " 'Compared with most existing methods, this method ex-\\n',\n",
       " 'ploits not only time series availability information of\\n',\n",
       " 'users but also multiple metadata features such as an-\\n',\n",
       " 'swer length, question-answer length, number of answers\\n',\n",
       " 'for this question, the answerer’s total points, and the\\n',\n",
       " 'answerer’s best answer ratio. These features have rarely\\n',\n",
       " 'been used by the existing research.\\n',\n",
       " '\\n',\n",
       " '4.3 Topic Models\\n',\n",
       " '\\n',\n",
       " 'Since language models are based on exact word\\n',\n",
       " 'matching, they are most eﬀective when they are used\\n',\n",
       " 'within the same topic. Besides, they are not able to\\n',\n",
       " '\\n',\n",
       " '\\x0cXianzhi Wang et al.: A Survey on Expert Recommendation in CQA\\n',\n",
       " '\\n',\n",
       " '7\\n',\n",
       " '\\n',\n",
       " 'capture more advanced semantics and solve the prob-\\n',\n",
       " 'lem of the lexical gap between a question and user pro-\\n',\n",
       " 'ﬁles. In contrast, topic models do not require the word\\n',\n",
       " 'to appear in the user proﬁle, as it measures their re-\\n',\n",
       " 'lationship in the topic space rather than in the word\\n',\n",
       " 'space. It can, therefore, alleviate the lexical gap prob-\\n',\n",
       " 'lem and previous experimental evaluations have con-\\n',\n",
       " 'ﬁrmed the better performance of many topic models\\n',\n",
       " 'over language models [30;31]. Here, we focus on review-\\n',\n",
       " 'ing two most widely used topic models, Probabilistic\\n',\n",
       " 'Latent Semantic Analysis (PLSA) and Latent Dirichlet\\n',\n",
       " 'Allocation (LDA), as well as their variants and a few\\n',\n",
       " 'other models.\\n',\n",
       " '\\n',\n",
       " '4.3.1 PLSA and Its Variants\\n',\n",
       " '\\n',\n",
       " 'Probabilistic Latent Semantic\\n',\n",
       " '\\n',\n",
       " 'Probabilistic Latent Semantic Analysis (PLSA)\\n',\n",
       " 'a.k.a.\\n',\n",
       " 'Indexing\\n',\n",
       " '(PLSI) [32] is developed based on Latent Semantic In-\\n',\n",
       " 'dexing (LSI) [33], which uses Singular Value Decomposi-\\n',\n",
       " 'tion to represent a document in a low-dimension space.\\n',\n",
       " 'Compared with LSI, which lacks semantic explanation,\\n',\n",
       " 'PLSA uses latent topics to represent documents and\\n',\n",
       " 'model the data generation process as a Bayesian net-\\n',\n",
       " 'work. In this way, it can leverage the semantic between\\n',\n",
       " 'words in documents to reduce the document representa-\\n',\n",
       " 'tion space dimension. There are generally two classes of\\n',\n",
       " 'PLSA-based methods that model users directly and in-\\n',\n",
       " 'directly, respectively. We brieﬂy review the two classes\\n',\n",
       " 'of methods as follows:\\n',\n",
       " '\\n',\n",
       " 'Direct User Model by PLSA. Methods of this class\\n',\n",
       " 'treat all the questions that a user accesses as one docu-\\n',\n",
       " 'ment. Then, PLSA is used directly to derive the topic\\n',\n",
       " 'information of the user using word distributions. A typ-\\n',\n",
       " 'ical method of this class [15] would identify the under-\\n',\n",
       " 'lying topics of questions to match users’ interest and\\n',\n",
       " 'thereby help the capable users locate the right ques-\\n',\n",
       " 'tions to answer. The Expectation Maximization (EM)\\n',\n",
       " 'algorithm is generally used to ﬁnd a local maximum of\\n',\n",
       " 'the log-likelihood of the question collection and to learn\\n',\n",
       " 'model parameters.\\n',\n",
       " '\\n',\n",
       " 'Indirect User Model by PLSA. A typical method of\\n',\n",
       " 'this class is proposed in [34]. This work presents an\\n',\n",
       " 'incremental automatic expert recommendation frame-\\n',\n",
       " 'work based on PLSA. It considers both users’ interests\\n',\n",
       " 'and feedback and takes questions as documents. It fur-\\n',\n",
       " 'ther uses PLSA to model the question to gain its distri-\\n',\n",
       " 'bution on topics, followed by representing users as the\\n',\n",
       " 'average of topic distributions of all the questions that\\n',\n",
       " 'he accesses to facilitate recommendation.\\n',\n",
       " '\\n',\n",
       " 'A most important variant of PLSA is probably the\\n',\n",
       " 'Dual Role Model (DRM) proposed by Xu et al. [35].\\n',\n",
       " 'Instead of combining the consideration of a user as\\n',\n",
       " 'a requester and an answerer, DRM separately mod-\\n',\n",
       " 'els users’ roles as requesters and as answerers and de-\\n',\n",
       " 'rive the corresponding probabilistic models based on\\n',\n",
       " 'PLSA. Depending on the modeling approach of user’s\\n',\n",
       " 'role, DRM diverges into independent DRM, a type of\\n',\n",
       " 'method modeling user role indirectly, and dependent\\n',\n",
       " 'DRM, a method which learns the role model directly.\\n',\n",
       " 'In particular, the independent DRM assumes all users\\n',\n",
       " 'are independent of each other and models each user\\n',\n",
       " 'individually.\\n',\n",
       " 'In contrast, dependent DRM considers\\n',\n",
       " 'the dependence between users. Besides modeling users’\\n',\n",
       " 'topic distribution as requesters and answerers, it addi-\\n',\n",
       " 'tionally models the relationship between answerers and\\n',\n",
       " 'requesters for better performance.\\n',\n",
       " '\\n',\n",
       " '4.3.2 LDA and Its Variants\\n',\n",
       " '\\n',\n",
       " 'The Latent Dirichlet Allocation (LDA) model [36] is\\n',\n",
       " 'probably the most widely used topic model among all\\n',\n",
       " 'existing topic models developed.\\n',\n",
       " 'In LDA, the topic\\n',\n",
       " 'mixture is drawn from a conjugate Dirichlet prior that\\n',\n",
       " 'remains the same for all users. More speciﬁcally, LDA\\n',\n",
       " 'assumes a certain generative process for data. To gener-\\n',\n",
       " 'ate a user proﬁle, LDA assumes that for each user pro-\\n',\n",
       " 'ﬁle a distribution over topics is sampled from a Dirich-\\n',\n",
       " 'let distribution. In the next step, for each word in the\\n',\n",
       " 'user proﬁle, a single topic is chosen according to this\\n',\n",
       " 'topic distribution. Finally, each word is sampled from\\n',\n",
       " 'a multinomial distribution over words speciﬁc to the\\n',\n",
       " 'sampled topic. Here, we brieﬂy review two important\\n',\n",
       " 'classes of LDA variants that have been applied for the\\n',\n",
       " 'expert recommendation in CQA:\\n',\n",
       " '\\n',\n",
       " 'Segmented Topic Model (STM) [37]. This is a topic\\n',\n",
       " 'model that discovers the hierarchical structure of top-\\n',\n",
       " 'ics by using the two-parameter Poisson Dirichlet pro-\\n',\n",
       " 'cess [38]. As a four-level probabilistic model, STM con-\\n',\n",
       " 'tains two levels of topic proportions and shows supe-\\n',\n",
       " 'riority over traditional models. Instead of grouping all\\n',\n",
       " 'the questions of a user under a single topic distribution,\\n',\n",
       " 'it allows each question to have a diﬀerent and separate\\n',\n",
       " 'distribution over the topics. A user proﬁle is considered\\n',\n",
       " 'a document that contains questions (segments). The\\n',\n",
       " 'above distributions cover the expertise set of a user,\\n',\n",
       " 'the topics of each question in the proﬁle, as well as the\\n',\n",
       " 'correlation between each proﬁle and its questions.\\n',\n",
       " '\\n',\n",
       " 'TagLDA [39]. This method uses only tag informa-\\n',\n",
       " 'tion to infer users’ topical interest. It is more eﬃciently,\\n',\n",
       " '\\n',\n",
       " '\\x0c8\\n',\n",
       " '\\n',\n",
       " 'J. Comput. Sci. & Technol., January 2018, Vol.33, No.1\\n',\n",
       " '\\n',\n",
       " 'but the eﬀectiveness is dependent on the accuracy and\\n',\n",
       " 'availability of tags.\\n',\n",
       " '\\n',\n",
       " '4.3.3 Expertise-aware LDA\\n',\n",
       " '\\n',\n",
       " 'The work in [40] considers both the topical interest\\n',\n",
       " 'and expertise of a user relevant to the topics of the\\n',\n",
       " 'given question. It also uses LDA to identify topical in-\\n',\n",
       " 'terest from previous answers of the user, but additional\\n',\n",
       " 'compute the expertise level of users using collaborative\\n',\n",
       " 'voting mechanism. Sahu et al. [39] incorporate question\\n',\n",
       " 'tags and related voting information in LDA to compute\\n',\n",
       " 'user expertise, where user expertise is computed based\\n',\n",
       " 'on both the topical distribution of users and voting in-\\n',\n",
       " 'formation under the same question tags.\\n',\n",
       " '\\n',\n",
       " '4.3.4 Other Topic Models\\n',\n",
       " '\\n',\n",
       " 'Besides the famous QLL and LDA models, Zhou\\n',\n",
       " 'et al. [14] propose a method that groups threads (i.e.,\\n',\n",
       " 'a question and related answers) of similar content into\\n',\n",
       " 'clusters to build a cluster-based thread for each user.\\n',\n",
       " 'Each cluster represents a coherent topic and is associ-\\n',\n",
       " 'ated with users to indicate the relevance relationship.\\n',\n",
       " 'The ranking score for a user is then computed based\\n',\n",
       " 'on the aggregation of the relevance of the user to all\\n',\n",
       " 'clusters given a new question. Guo [3] proposes a user-\\n',\n",
       " 'centric and category-sensitive generative model for dis-\\n',\n",
       " 'covering topics, named User-Question-Answer (UQA).\\n',\n",
       " 'The work incorporates topics discovered by UQA model\\n',\n",
       " 'with term-level matching methods to recommend ex-\\n',\n",
       " 'perts and increase the participation rate of users in\\n',\n",
       " 'CQA. In this model, each user is considered as a pseudo-\\n',\n",
       " 'document which is a combination of all the questions\\n',\n",
       " 'the user has asked and all the answers the user has pro-\\n',\n",
       " 'vided in reply to other users’ questions. More methods\\n',\n",
       " 'can be derived based on this model as well as the com-\\n',\n",
       " 'binations of these methods.\\n',\n",
       " '\\n',\n",
       " '4.4 Network-based Methods\\n',\n",
       " '\\n',\n",
       " 'The network-based methods evaluate users’ author-\\n',\n",
       " 'itativeness in a user-user network formed by their\\n',\n",
       " 'asking-answering relations and recommend the most\\n',\n",
       " 'authoritative users as experts for a new question. The\\n',\n",
       " 'simplest network-based method uses Indegree [41] to\\n',\n",
       " 'rank and recommend users.\\n',\n",
       " 'In particular, an inde-\\n',\n",
       " 'gree score equals the number of other users a user has\\n',\n",
       " 'helped by answering their questions, represented by an\\n',\n",
       " 'arrow from the requester to the answerer in the user-\\n',\n",
       " 'user network. Since frequent posters tend to have a\\n',\n",
       " 'signiﬁcant interest in the topic and a larger degree of a\\n',\n",
       " '\\n',\n",
       " 'node usually correlates with answer quality [41;42], this\\n',\n",
       " 'method regards the users with higher degrees as better\\n',\n",
       " 'answerers for the recommendation. The mainstream of\\n',\n",
       " 'this category include three families of methods based\\n',\n",
       " 'on PageRank [43], HITS [44], and ExpertiseRank [41], re-\\n',\n",
       " 'spectively. We will also brieﬂy introduce several other\\n',\n",
       " 'network-based methods to gain a comprehensive view\\n',\n",
       " 'of the related techniques.\\n',\n",
       " '\\n',\n",
       " '4.4.1 PageRank and Its Variants\\n',\n",
       " '\\n',\n",
       " 'PageRank [45;46] uses nodes to represent users, and a\\n',\n",
       " 'directed edge to indicate one user (i.e., the source node)\\n',\n",
       " 'answers the questions of another user (i.e., the destina-\\n',\n",
       " 'tion node). It estimates the likelihood that a random\\n',\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_python_linux)",
   "language": "python",
   "name": "ml_python_linux"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
